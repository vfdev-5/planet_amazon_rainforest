{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GT 750M (CNMeM is enabled with initial size: 50.0% of memory, cuDNN 5110)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import time: 12.321996927261353\n",
      "Import time: 0.00017595291137695312\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import local_utils; importlib.reload(local_utils)\n",
    "from local_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_start = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y (40479, 17)\n",
      "Train 36431; Valid 4048;\n",
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA_DIR + '/train_v2.csv')\n",
    "test_df = pd.read_csv(DATA_DIR + '/sample_submission_v2.csv')\n",
    "\n",
    "label_map, inv_label_map, Y = process_labels(train_df)\n",
    "print(\"Shape of Y {}\".format(Y.shape))\n",
    "\n",
    "train_inx, valid_inx = stratified_sampling(Y=Y, random_state=1000)\n",
    "print(\"Train {}; Valid {};\".format(len(train_inx), len(valid_inx)))\n",
    "\n",
    "w_size = 128\n",
    "h_size = 128\n",
    "input_shape = (w_size, h_size, 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 128, 128, 3)\n",
      "325.311439037323\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "X = load_images(train_df['image_name'].values, DATA_DIR + '/train/jpg', True, w_size, h_size)\n",
    "print(X.shape)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array(DATA_DIR + \"/train_image_\" + str(\"128\")+'.dat', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"main_model\"\n",
    "batch_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class F2History(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.f2_scores = []\n",
    "    def on_epoch_end(self, epoch, logs ={}):\n",
    "        p_valid = self.model.predict(self.validation_data[0])\n",
    "        y_val = self.validation_data[1]\n",
    "        f2 = fbeta_score(y_val, np.array(p_valid) >= 0.2, beta=2, average='samples')\n",
    "        self.f2_scores.append(f2)\n",
    "        return\n",
    "\n",
    "f2_history = F2History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "                DATA_DIR + '/models/' + model_name + '.h5', \n",
    "                monitor='val_loss', \n",
    "                verbose=1, \n",
    "                save_best_only=True, \n",
    "                save_weights_only=False, \n",
    "                mode='min',\n",
    "                period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "model_layers = [\n",
    "    BatchNormalization(input_shape=input_shape),\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    BatchNormalization(),\n",
    "#     Dropout(p/2),\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "\n",
    "    BatchNormalization(),\n",
    "#     Dropout(p/2),\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "\n",
    "    BatchNormalization(),\n",
    "#     Dropout(p/2),\n",
    "    Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "\n",
    "    BatchNormalization(),\n",
    "#     Dropout(p/2),\n",
    "    Conv2D(17, (3, 3), padding='same'),\n",
    "#     Dropout(p),\n",
    "    GlobalMaxPooling2D(),\n",
    "    Activation('sigmoid')\n",
    "    \n",
    "#     Flatten(),\n",
    "#     Dense(512, activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.25),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.25),\n",
    "#     Dense(17, activation='sigmoid')\n",
    "]\n",
    "model = Sequential(model_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = load_model(DATA_DIR + '/models/' + model_name + '1.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 63, 63, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 6, 6, 17)          39185     \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17)                0         \n",
      "=================================================================\n",
      "Total params: 1,213,373\n",
      "Trainable params: 1,212,407\n",
      "Non-trainable params: 966\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(lr=1e-3, decay=75e-5)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36431 samples, validate on 4048 samples\n",
      "Epoch 1/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.8829Epoch 00000: val_loss improved from inf to 0.19348, saving model to /src/DL/planet_understanding_the_amazon_from_space/data/models/main_model.h5\n",
      "36431/36431 [==============================] - 167s - loss: 0.2871 - acc: 0.8829 - val_loss: 0.1935 - val_acc: 0.9256\n",
      "Epoch 2/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9395Epoch 00001: val_loss improved from 0.19348 to 0.14898, saving model to /src/DL/planet_understanding_the_amazon_from_space/data/models/main_model.h5\n",
      "36431/36431 [==============================] - 164s - loss: 0.1538 - acc: 0.9395 - val_loss: 0.1490 - val_acc: 0.9410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9467Epoch 00002: val_loss improved from 0.14898 to 0.13181, saving model to /src/DL/planet_understanding_the_amazon_from_space/data/models/main_model.h5\n",
      "36431/36431 [==============================] - 164s - loss: 0.1359 - acc: 0.9467 - val_loss: 0.1318 - val_acc: 0.9470\n",
      "Epoch 4/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9512Epoch 00003: val_loss improved from 0.13181 to 0.12314, saving model to /src/DL/planet_understanding_the_amazon_from_space/data/models/main_model.h5\n",
      "36431/36431 [==============================] - 164s - loss: 0.1248 - acc: 0.9512 - val_loss: 0.1231 - val_acc: 0.9523\n",
      "Epoch 5/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9543Epoch 00004: val_loss improved from 0.12314 to 0.12184, saving model to /src/DL/planet_understanding_the_amazon_from_space/data/models/main_model.h5\n",
      "36431/36431 [==============================] - 164s - loss: 0.1172 - acc: 0.9542 - val_loss: 0.1218 - val_acc: 0.9517\n",
      "Epoch 6/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9564Epoch 00005: val_loss did not improve\n",
      "36431/36431 [==============================] - 164s - loss: 0.1116 - acc: 0.9564 - val_loss: 0.1279 - val_acc: 0.9479\n",
      "Epoch 7/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9581Epoch 00006: val_loss improved from 0.12184 to 0.10780, saving model to /src/DL/planet_understanding_the_amazon_from_space/data/models/main_model.h5\n",
      "36431/36431 [==============================] - 164s - loss: 0.1075 - acc: 0.9581 - val_loss: 0.1078 - val_acc: 0.9578\n",
      "Epoch 8/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9597Epoch 00007: val_loss did not improve\n",
      "36431/36431 [==============================] - 164s - loss: 0.1034 - acc: 0.9597 - val_loss: 0.1088 - val_acc: 0.9576\n",
      "Epoch 9/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9615Epoch 00008: val_loss improved from 0.10780 to 0.10562, saving model to /src/DL/planet_understanding_the_amazon_from_space/data/models/main_model.h5\n",
      "36431/36431 [==============================] - 165s - loss: 0.0993 - acc: 0.9615 - val_loss: 0.1056 - val_acc: 0.9593\n",
      "Epoch 10/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9627Epoch 00009: val_loss improved from 0.10562 to 0.10488, saving model to /src/DL/planet_understanding_the_amazon_from_space/data/models/main_model.h5\n",
      "36431/36431 [==============================] - 164s - loss: 0.0958 - acc: 0.9627 - val_loss: 0.1049 - val_acc: 0.9594\n",
      "Epoch 11/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9644Epoch 00010: val_loss improved from 0.10488 to 0.10349, saving model to /src/DL/planet_understanding_the_amazon_from_space/data/models/main_model.h5\n",
      "36431/36431 [==============================] - 165s - loss: 0.0919 - acc: 0.9644 - val_loss: 0.1035 - val_acc: 0.9602\n",
      "Epoch 12/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9662Epoch 00011: val_loss did not improve\n",
      "36431/36431 [==============================] - 164s - loss: 0.0873 - acc: 0.9662 - val_loss: 0.1041 - val_acc: 0.9605\n",
      "Epoch 13/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9680Epoch 00012: val_loss did not improve\n",
      "36431/36431 [==============================] - 164s - loss: 0.0824 - acc: 0.9680 - val_loss: 0.1065 - val_acc: 0.9594\n",
      "Epoch 14/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9701Epoch 00013: val_loss did not improve\n",
      "36431/36431 [==============================] - 164s - loss: 0.0775 - acc: 0.9700 - val_loss: 0.1073 - val_acc: 0.9589\n",
      "Epoch 15/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9724Epoch 00014: val_loss did not improve\n",
      "36431/36431 [==============================] - 164s - loss: 0.0717 - acc: 0.9724 - val_loss: 0.1099 - val_acc: 0.9581\n",
      "Epoch 16/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9747Epoch 00015: val_loss did not improve\n",
      "36431/36431 [==============================] - 164s - loss: 0.0655 - acc: 0.9747 - val_loss: 0.1089 - val_acc: 0.9598\n",
      "Epoch 17/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9775Epoch 00016: val_loss did not improve\n",
      "36431/36431 [==============================] - 164s - loss: 0.0593 - acc: 0.9775 - val_loss: 0.1127 - val_acc: 0.9587\n",
      "Epoch 18/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9804Epoch 00017: val_loss did not improve\n",
      "36431/36431 [==============================] - 165s - loss: 0.0525 - acc: 0.9804 - val_loss: 0.1184 - val_acc: 0.9584\n",
      "Epoch 19/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9830Epoch 00018: val_loss did not improve\n",
      "36431/36431 [==============================] - 164s - loss: 0.0464 - acc: 0.9830 - val_loss: 0.1183 - val_acc: 0.9585\n",
      "Epoch 20/20\n",
      "36384/36431 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9853Epoch 00019: val_loss did not improve\n",
      "36431/36431 [==============================] - 165s - loss: 0.0412 - acc: 0.9853 - val_loss: 0.1214 - val_acc: 0.9579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7cff5ed7b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X[train_inx], Y[train_inx],\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(X[valid_inx], Y[valid_inx]),\n",
    "          callbacks=[f2_history, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F2 Score 0.9139926925579585; Epoch 15;\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7cfc3e8898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Max F2 Score {}; Epoch {};\".format(max(f2_history.f2_scores),np.argmax(f2_history.f2_scores)))\n",
    "plt.plot(f2_history.f2_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-30d9529ff51c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save(DATA_DIR + '/models/' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4032/4048 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1034902488525677, 0.96022729722878675]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(DATA_DIR + '/models/' + model_name + '.h5', compile=False)\n",
    "opt = optimizers.Adam(lr=1e-3, decay=75e-5)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.evaluate(X[valid_inx], Y[valid_inx], batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40479/40479 [==============================] - 57s    \n"
     ]
    }
   ],
   "source": [
    "p_X = model.predict(X, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: Score 0.9146585253931239 with 0.0905\n",
      "4: Score 0.9141957836996095 with 0.036000000000000004\n",
      "3: Score 0.9142178226932598 with 0.0555\n",
      "6: Score 0.9143275309837556 with 0.1475\n",
      "0: Score 0.9140700463261754 with 0.195\n",
      "2: Score 0.9142790606776148 with 0.1015\n",
      "7: Score 0.9141206606018107 with 0.0655\n",
      "1: Score 0.9140298457960663 with 0.2895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: Score 0.9141847782759426 with 0.1135\n",
      "14: Score 0.9140347023088436 with 0.518\n",
      "10: Score 0.9143496383953952 with 0.15\n",
      "11: Score 0.9151386115873057 with 0.10200000000000001\n",
      "13: Score 0.9140450443429003 with 0.1875\n",
      "12: Score 0.9145534571382067 with 0.136\n",
      "9: Score 0.9141308814091661 with 0.1495\n",
      "15: Score 0.9139778827331259 with 0.1835\n",
      "16: Score 0.9143637260007706 with 0.183\n",
      "29.310418128967285\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "thres = find_best_thresholds(Y[valid_inx], p_X[valid_inx])\n",
    "save_array(DATA_DIR + '/models/' + model_name + '_thres.dat', thres)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925857175729\n",
      "0.926629247864\n",
      "0.918908717244\n"
     ]
    }
   ],
   "source": [
    "print(f2_score(Y, p_X, thres))\n",
    "print(f2_score(Y[train_inx], p_X[train_inx], thres))\n",
    "print(f2_score(Y[valid_inx], p_X[valid_inx], thres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/joblib/pool.py\", line 386, in put\n",
      "    return send(obj)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/joblib/pool.py\", line 372, in send\n",
      "    self._writer.send_bytes(buffer.getvalue())\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "del X\n",
    "del p_X\n",
    "\n",
    "model = load_model(DATA_DIR + '/models/' + model_name + '.h5', compile=False)\n",
    "thres = load_array(DATA_DIR + '/models/' + model_name + '_thres.dat')\n",
    "\n",
    "start = time()\n",
    "X_test = load_images(test_df['image_name'].values, DATA_DIR + '/test-jpg', True, w_size, h_size)\n",
    "print(X_test.shape)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_X_test = model.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "for inx in np.arange(len(test_df)):\n",
    "    test_df['tags'][inx] = ' '.join([inv_label_map[i] for i, b in enumerate(p_X_test[inx] >= thres) if b])\n",
    "print(time() - start)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(DATA_DIR + '/results/' + model_name + '_submission.csv', index=False)\n",
    "FileLink('data/results/' + model_name + '_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print((time() - global_start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 63, 63, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "=================================================================\n",
      "Total params: 1,173,164\n",
      "Trainable params: 1,172,710\n",
      "Non-trainable params: 454\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(DATA_DIR + '/models/' + model_name + '.h5', compile=False)\n",
    "\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model = Sequential(model.layers) # reinitialize\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40479/40479 [==============================] - 57s    \n"
     ]
    }
   ],
   "source": [
    "main_train_feat = model.predict(X, batch_size=batch_size, verbose = 1)\n",
    "save_array(DATA_DIR + '/models/main_train_feat.dat', main_train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 128, 128, 3)\n",
      "24.137157917022705\n"
     ]
    }
   ],
   "source": [
    "del X\n",
    "del main_train_feat\n",
    "\n",
    "start = time()\n",
    "X_test = load_images(test_df['image_name'].values, DATA_DIR + '/test-jpg', True, w_size, h_size)\n",
    "print(X_test.shape)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191/61191 [==============================] - 85s    \n"
     ]
    }
   ],
   "source": [
    "main_test_feat = model.predict(X_test, batch_size=batch_size, verbose = 1)\n",
    "save_array(DATA_DIR + '/models/main_test_feat.dat', main_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main_train_feat = load_array(DATA_DIR + '/models/main_train_feat.dat')\n",
    "# print(main_train_feat.shape)\n",
    "\n",
    "# main_test_feat = load_array(DATA_DIR + '/models/main_test_feat.dat')\n",
    "# print(main_test_feat.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
