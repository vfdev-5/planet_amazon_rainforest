{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train finetunned SqueezeNet model for multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Project\n",
    "project_common_path = os.path.dirname('.')\n",
    "project_common_path = os.path.abspath(os.path.join(project_common_path, '..', 'common'))\n",
    "if not project_common_path in sys.path:\n",
    "    sys.path.append(project_common_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from data_utils import get_id_type_list_for_class, OUTPUT_PATH, GENERATED_DATA, to_set, RESOURCES_PATH\n",
    "from training_utils import classification_train as train, classification_validate as validate\n",
    "from training_utils import exp_decay, step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13724 13724\n"
     ]
    }
   ],
   "source": [
    "from models.squeezenet_multiclassification import get_squeezenet21_rare_tags\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from data_utils import to_set, equalized_data_classes, unique_tags, train_jpg_ids, TRAIN_ENC_CL_CSV\n",
    "from data_utils import load_pretrained_model, get_label\n",
    "from data_utils import DataCache\n",
    "\n",
    "from xy_providers import image_class_labels_provider\n",
    "from models.keras_metrics import binary_crossentropy_with_false_negatives\n",
    "\n",
    "\n",
    "# Setup configuration\n",
    "\n",
    "seed = 2017\n",
    "np.random.seed(seed)\n",
    "\n",
    "cache = DataCache(0)  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "\n",
    "class_index = 0\n",
    "\n",
    "trainval_id_type_list = get_id_type_list_for_class(class_index)\n",
    "\n",
    "\n",
    "### ADD GENERATED IMAGES\n",
    "from glob import glob\n",
    "from data_utils import GENERATED_DATA, to_set, get_label\n",
    "\n",
    "gen_train_jpg_files = glob(os.path.join(GENERATED_DATA, \"train\", \"jpg\", \"*.jpg\"))\n",
    "gen_train_jpg_ids = [s[len(os.path.join(GENERATED_DATA, \"train\", \"jpg\"))+1+len('gen_train_'):-4] for s in gen_train_jpg_files]\n",
    "gen_id_type_list = [(image_id, \"Generated_Train_jpg\") for image_id in gen_train_jpg_ids]\n",
    "class_index_gen_train_jpg_ids = [id_type for id_type in gen_train_jpg_ids if np.sum(get_label(*gen_id_type_list[0], class_index=class_index)) > 0]\n",
    "class_index_gen_id_type_list = [(image_id, \"Generated_Train_jpg\") for image_id in class_index_gen_train_jpg_ids]\n",
    "trainval_id_type_list = trainval_id_type_list + class_index_gen_id_type_list\n",
    "### ADD GENERATED IMAGES\n",
    "\n",
    "class_indices = list(equalized_data_classes.keys())\n",
    "class_indices.remove(class_index)\n",
    "\n",
    "n_other_samples = int(len(trainval_id_type_list) * 1.0 / len(class_indices))\n",
    "\n",
    "for index in class_indices:\n",
    "    id_type_list = np.array(get_id_type_list_for_class(index))\n",
    "    id_type_list = list(to_set(id_type_list) - to_set(trainval_id_type_list))\n",
    "    np.random.shuffle(id_type_list)\n",
    "    trainval_id_type_list.extend(id_type_list[:n_other_samples])\n",
    "\n",
    "print(len(trainval_id_type_list), len(to_set(trainval_id_type_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'seed': seed,\n",
    "\n",
    "    'xy_provider': image_class_labels_provider,\n",
    "\n",
    "    'network': get_squeezenet21_rare_tags,\n",
    "    'network_kwargs': {\n",
    "        'input_shape': (256, 256, 3),\n",
    "        'weights': 'imagenet'\n",
    "    },\n",
    "    'n_classes': len(equalized_data_classes[class_index]),\n",
    "    'image_size': (256, 256),\n",
    "\n",
    "    'optimizer': 'adadelta',\n",
    "    'loss': lambda Y_true, Y_pred: binary_crossentropy_with_false_negatives(Y_true, Y_pred, a=100.0),\n",
    "    'nb_epochs': 50,    # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "    'batch_size': 16,  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "\n",
    "    'normalize_data': True,\n",
    "    'normalization': 'vgg',\n",
    "\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    'lr_kwargs': {\n",
    "        'lr': 0.01,\n",
    "        'a': 0.95,\n",
    "        'init_epoch': 0\n",
    "    },\n",
    "    'lr_decay_f': exp_decay,\n",
    "\n",
    "    # Reduce learning rate on plateau\n",
    "    'on_plateau': True,\n",
    "    'on_plateau_kwargs': {\n",
    "        'monitor': 'val_loss',\n",
    "        'factor': 0.1,\n",
    "        'patience': 2,\n",
    "        'verbose': 1\n",
    "    },\n",
    "\n",
    "    'cache': cache,\n",
    "\n",
    "    'class_index': class_index,\n",
    "    # 'pretrained_model': 'load_best',\n",
    "    # 'pretrained_model': os.path.join(GENERATED_DATA, \"resources\", \"\"),\n",
    "    # 'pretrained_model_template': os.path.join(RESOURCES_PATH,\n",
    "    #                                           \"SqueezeNet21_all_classes_fold={fold_index}_seed=2017_40_val_loss=0.1216_val_precision=0.9153_val_recall=0.8670.h5\"),\n",
    "\n",
    "    'output_path': OUTPUT_PATH,\n",
    "}\n",
    "\n",
    "params['save_prefix_template'] = '{cnn_name}_classe=%i_fold={fold_index}_seed=%i' % (params['class_index'], params['seed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "val_fold_index = 0\n",
    "val_fold_indices = [0, ]  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "hists = []\n",
    "\n",
    "kf = KFold(n_splits=n_folds)\n",
    "trainval_id_type_list = np.array(trainval_id_type_list)\n",
    "for train_index, test_index in kf.split(trainval_id_type_list):\n",
    "    train_id_type_list, val_id_type_list = trainval_id_type_list[train_index], trainval_id_type_list[test_index]\n",
    "\n",
    "    if len(val_fold_indices) > 0:\n",
    "        if val_fold_index not in val_fold_indices:\n",
    "            val_fold_index += 1\n",
    "            continue            \n",
    "            \n",
    "    assert len(to_set(train_id_type_list) & to_set(val_id_type_list)) == 0, \"WTF\"\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18077_18691'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id_type_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('1', '8')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_set(train_id_type_list) & to_set(val_id_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from training_utils import get_id_imgaug_seq, get_gen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loop_max_counter = -1\n",
    "n_limit = -1\n",
    "\n",
    "imgaug_seq = get_id_imgaug_seq()\n",
    "train_gen, train_flow = get_gen_flow(id_type_list=train_id_type_list, imgaug_seq=imgaug_seq, test_mode=True, **params)\n",
    "counter = 0\n",
    "y_true = np.zeros((len(train_id_type_list), len(equalized_data_classes[class_index])))\n",
    "for x, y, info in train_flow:\n",
    "            \n",
    "    y_true[counter*params['batch_size']:(counter+1)*params['batch_size']] = y\n",
    "    counter += 1\n",
    "\n",
    "    loop_max_counter -= 1\n",
    "    if loop_max_counter == 0:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 6)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_true, columns=equalized_data_classes[class_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_utils import TRAIN_ENC_CSV\n",
    "\n",
    "def compute_stats(tags=None, train_enc_csv=TRAIN_ENC_CSV):\n",
    "    if tags is None:\n",
    "        tags = unique_tags\n",
    "    tags_stats = {}\n",
    "    for l in tags:\n",
    "        tags_stats[l] = train_enc_csv[l].sum()\n",
    "    return tags_stats\n",
    "\n",
    "tags_stats = compute_stats(equalized_data_classes[class_index], train_enc_csv=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1134.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(list(tags_stats.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 6 artists>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAD8CAYAAADt9ARWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMBglSWoYjJIkNQxGSZIaBqMkSY3/D/UwJbLu54CNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114680ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(bottom=range(len(tags_stats.keys())), width=tags_stats.values(), tick_label=tags_stats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ---- Validation fold index:  1 / 5\n",
      "2017-07-14 17:23:38.057107 2228 557\n",
      "\n",
      " 2017-07-14 17:23:39.296927 - Loaded SqueezeNet21_rare_tags model ...\n",
      "\n",
      " 2017-07-14 17:23:39.297030 - Start training ...\n",
      "\n",
      "-- Training parameters: 16, 50, 11152, 848\n",
      "\n",
      "-- Fit model\n",
      "- New Keras API found -\n"
     ]
    }
   ],
   "source": [
    "# Start CV\n",
    "\n",
    "n_folds = 5\n",
    "val_fold_index = 0\n",
    "val_fold_indices = [0, ]  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "hists = []\n",
    "\n",
    "kf = KFold(n_splits=n_folds)\n",
    "trainval_id_type_list = np.array(trainval_id_type_list)\n",
    "for train_index, test_index in kf.split(trainval_id_type_list):\n",
    "    train_id_type_list, val_id_type_list = trainval_id_type_list[train_index], trainval_id_type_list[test_index]\n",
    "\n",
    "    if len(val_fold_indices) > 0:\n",
    "        if val_fold_index not in val_fold_indices:\n",
    "            val_fold_index += 1\n",
    "            continue\n",
    "\n",
    "    params['samples_per_epoch'] = 5 * len(train_id_type_list)\n",
    "    params['nb_val_samples'] = int(1.5 * len(val_id_type_list))\n",
    "\n",
    "    val_fold_index += 1\n",
    "    print(\"\\n\\n ---- Validation fold index: \", val_fold_index, \"/\", n_folds)\n",
    "\n",
    "    print(datetime.now(), len(train_id_type_list), len(val_id_type_list))\n",
    "    assert len(to_set(train_id_type_list) & to_set(val_id_type_list)) == 0, \"WTF\"\n",
    "\n",
    "    cnn = params['network'](lr=params['lr_kwargs']['lr'], **params, **params['network_kwargs'])\n",
    "    params['save_prefix'] = params['save_prefix_template'].format(cnn_name=cnn.name, fold_index=val_fold_index-1)\n",
    "    print(\"\\n {} - Loaded {} model ...\".format(datetime.now(), cnn.name))\n",
    "\n",
    "    if 'pretrained_model' in params:\n",
    "        load_pretrained_model(cnn, **params)\n",
    "    elif 'pretrained_model_template' in params:\n",
    "        params['pretrained_model'] = params['pretrained_model_template'].format(fold_index=(val_fold_index-1) % 3)\n",
    "        print((val_fold_index-1) % 3)\n",
    "        print(params['pretrained_model'])\n",
    "        load_pretrained_model(cnn, by_name=True, **params)\n",
    "\n",
    "    print(\"\\n {} - Start training ...\".format(datetime.now()))\n",
    "    h = train(cnn, train_id_type_list, val_id_type_list, **params)\n",
    "    if h is None:\n",
    "        continue\n",
    "    hists.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Validation all classes\n",
    "\n",
    "n_runs = 2\n",
    "n_folds = 5\n",
    "run_counter = 0\n",
    "cv_mean_scores = np.zeros((n_runs, n_folds))\n",
    "val_fold_indices = []  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "\n",
    "params['pretrained_model'] = 'load_best'\n",
    "\n",
    "_trainval_id_type_list = np.array(trainval_id_type_list)\n",
    "\n",
    "while run_counter < n_runs:\n",
    "    run_counter += 1\n",
    "    print(\"\\n\\n ---- New run : \", run_counter, \"/\", n_runs)\n",
    "    val_fold_index = 0\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    for train_index, test_index in kf.split(_trainval_id_type_list):\n",
    "        train_id_type_list, val_id_type_list = _trainval_id_type_list[train_index], _trainval_id_type_list[test_index]\n",
    "\n",
    "        if len(val_fold_indices) > 0:\n",
    "            if val_fold_index not in val_fold_indices:\n",
    "                val_fold_index += 1\n",
    "                continue\n",
    "\n",
    "        val_fold_index += 1\n",
    "        print(\"\\n\\n ---- Validation fold index: \", val_fold_index, \"/\", n_folds)\n",
    "\n",
    "        print(len(train_id_type_list), len(val_id_type_list))\n",
    "        assert len(to_set(train_id_type_list) & to_set(val_id_type_list)) == 0, \"WTF\"\n",
    "\n",
    "        cnn = params['network'](input_shape=params['input_shape'], n_classes=params['n_classes'])\n",
    "        params['save_prefix'] = params['save_prefix_template'].format(cnn_name=cnn.name, fold_index=val_fold_index-1)\n",
    "        print(\"\\n {} - Loaded {} model ...\".format(datetime.now(), cnn.name))\n",
    "\n",
    "        load_pretrained_model(cnn, **params)\n",
    "\n",
    "        params['seed'] += run_counter - 1\n",
    "\n",
    "        f2, mae = validate(cnn, val_id_type_list, verbose=0, **params)\n",
    "        cv_mean_scores[run_counter-1, val_fold_index-1] = f2\n",
    "\n",
    "        np.random.shuffle(_trainval_id_type_list)\n",
    "\n",
    "print(cv_mean_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
