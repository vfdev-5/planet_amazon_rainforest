{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train finetunned SqueezeNet model for multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Project\n",
    "project_common_path = os.path.dirname('.')\n",
    "project_common_path = os.path.abspath(os.path.join(project_common_path, '..', 'common'))\n",
    "if not project_common_path in sys.path:\n",
    "    sys.path.append(project_common_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from data_utils import get_id_type_list_for_class, OUTPUT_PATH, GENERATED_DATA, to_set, RESOURCES_PATH\n",
    "from training_utils import classification_train as train, classification_validate as validate\n",
    "from training_utils import exp_decay, step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2785 2785\n"
     ]
    }
   ],
   "source": [
    "from models.squeezenet_multiclassification import get_squeezenet21_rare_tags\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from data_utils import to_set, equalized_data_classes, unique_tags, train_jpg_ids, TRAIN_ENC_CL_CSV\n",
    "from data_utils import load_pretrained_model, get_label\n",
    "from data_utils import DataCache\n",
    "\n",
    "from xy_providers import image_class_labels_provider\n",
    "from models.keras_metrics import binary_crossentropy_with_false_negatives\n",
    "\n",
    "\n",
    "# Setup configuration\n",
    "\n",
    "seed = 2017\n",
    "np.random.seed(seed)\n",
    "\n",
    "cache = DataCache(0)  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "\n",
    "class_index = 0\n",
    "\n",
    "trainval_id_type_list = get_id_type_list_for_class(class_index)\n",
    "\n",
    "class_indices = list(equalized_data_classes.keys())\n",
    "class_indices.remove(class_index)\n",
    "\n",
    "n_other_samples = int(len(trainval_id_type_list) * 1.0 / len(class_indices))\n",
    "\n",
    "for index in class_indices:\n",
    "    id_type_list = np.array(get_id_type_list_for_class(index))\n",
    "    id_type_list = list(to_set(id_type_list) - to_set(trainval_id_type_list))\n",
    "    np.random.shuffle(id_type_list)\n",
    "    trainval_id_type_list.extend(id_type_list[:n_other_samples])\n",
    "\n",
    "print(len(trainval_id_type_list), len(to_set(trainval_id_type_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'seed': seed,\n",
    "\n",
    "    'xy_provider': image_class_labels_provider,\n",
    "\n",
    "    'network': get_squeezenet21_rare_tags,\n",
    "    'network_kwargs': {\n",
    "        'input_shape': (256, 256, 3),\n",
    "        'weights': 'imagenet'\n",
    "    },\n",
    "    'n_classes': len(equalized_data_classes[class_index]),\n",
    "    'image_size': (256, 256),\n",
    "\n",
    "    'optimizer': 'adadelta',\n",
    "    'loss': lambda Y_true, Y_pred: binary_crossentropy_with_false_negatives(Y_true, Y_pred, a=100.0),\n",
    "    'nb_epochs': 50,    # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "    'batch_size': 16,  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "\n",
    "    'normalize_data': True,\n",
    "    'normalization': 'vgg',\n",
    "\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    'lr_kwargs': {\n",
    "        'lr': 0.01,\n",
    "        'a': 0.95,\n",
    "        'init_epoch': 0\n",
    "    },\n",
    "    'lr_decay_f': exp_decay,\n",
    "\n",
    "    # Reduce learning rate on plateau\n",
    "    'on_plateau': True,\n",
    "    'on_plateau_kwargs': {\n",
    "        'monitor': 'val_loss',\n",
    "        'factor': 0.1,\n",
    "        'patience': 2,\n",
    "        'verbose': 1\n",
    "    },\n",
    "\n",
    "    'cache': cache,\n",
    "\n",
    "    'class_index': class_index,\n",
    "    # 'pretrained_model': 'load_best',\n",
    "    # 'pretrained_model': os.path.join(GENERATED_DATA, \"resources\", \"\"),\n",
    "    # 'pretrained_model_template': os.path.join(RESOURCES_PATH,\n",
    "    #                                           \"SqueezeNet21_all_classes_fold={fold_index}_seed=2017_40_val_loss=0.1216_val_precision=0.9153_val_recall=0.8670.h5\"),\n",
    "\n",
    "    'output_path': OUTPUT_PATH,\n",
    "}\n",
    "\n",
    "params['save_prefix_template'] = '{cnn_name}_classe=%i_fold={fold_index}_seed=%i' % (params['class_index'], params['seed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "val_fold_index = 0\n",
    "val_fold_indices = [0, ]  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "hists = []\n",
    "\n",
    "kf = KFold(n_splits=n_folds)\n",
    "trainval_id_type_list = np.array(trainval_id_type_list)\n",
    "for train_index, test_index in kf.split(trainval_id_type_list):\n",
    "    train_id_type_list, val_id_type_list = trainval_id_type_list[train_index], trainval_id_type_list[test_index]\n",
    "\n",
    "    if len(val_fold_indices) > 0:\n",
    "        if val_fold_index not in val_fold_indices:\n",
    "            val_fold_index += 1\n",
    "            continue\n",
    "\n",
    "            \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from training_utils import get_id_imgaug_seq, get_gen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_limit = 16 * 6\n",
    "\n",
    "imgaug_seq = get_id_imgaug_seq()\n",
    "train_gen, train_flow = get_gen_flow(id_type_list=train_id_type_list[:n_limit], imgaug_seq=imgaug_seq, test_mode=True, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- (16, 256, 256, 3) (16, 6)\n",
      "-- -122.677 128.058 -37.4728 36.9017\n",
      "-- (16, 256, 256, 3) (16, 6)\n",
      "-- -117.677 136.058 -34.2519 38.2597\n",
      "-- (16, 256, 256, 3) (16, 6)\n",
      "-- -118.677 144.057 -33.4185 43.6192\n",
      "-- (16, 256, 256, 3) (16, 6)\n",
      "-- -111.677 143.057 -27.4223 37.7704\n",
      "-- (16, 256, 256, 3) (16, 6)\n",
      "-- -122.677 126.058 -39.0629 37.2503\n",
      "-- (16, 256, 256, 3) (16, 6)\n",
      "-- -114.677 115.218 -27.1071 45.7746\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loop_max_counter = 6\n",
    "counter = 0\n",
    "y_true = np.zeros((params['batch_size'] * loop_max_counter, len(equalized_data_classes[class_index])))\n",
    "for x, y, info in train_flow:\n",
    "    \n",
    "    print('--', x.shape, y.shape)\n",
    "    print('--', x.min(), x.max(), x.mean(), x.std())\n",
    "        \n",
    "    y_true[counter*params['batch_size']:(counter+1)*params['batch_size']] = y\n",
    "    counter += 1\n",
    "    \n",
    "#     n = 5\n",
    "#     for counter in range(params['batch_size']):\n",
    "#         if counter % n == 0:\n",
    "#             plt.figure(figsize=(12, 4))\n",
    "\n",
    "#         if channels_first:\n",
    "#             img = x[counter, :, :, :].transpose([1, 2, 0])\n",
    "#         else:\n",
    "#             img = x[counter, :, :, :]\n",
    "        \n",
    "# #         img2 = scale_percentile(img, q_min=0.0, q_max=100.0)\n",
    "#         img2 = (255.0 * img).astype(np.uint8)\n",
    "#         hls = to_hsl(img2)\n",
    "        \n",
    "#         l = hls[:, :, 1]\n",
    "# #         print(l.min(), l.mean(), l.max()) \n",
    "#         l[l > 180] = 255\n",
    "#         l[l <= 180] = 0\n",
    "#         img2 = l \n",
    "\n",
    "#         plt.subplot(2, n, counter % n + 1)\n",
    "# #         plt.imshow(scale_percentile(img2, q_min=0.0, q_max=100.0))\n",
    "#         plt.imshow(img2)\n",
    "# #         plt.title(\"{}\".format(y[counter]))    \n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.subplot(2, n, counter % n + n + 1)    \n",
    "#         plt.imshow(img)\n",
    "#         plt.axis('off')\n",
    "    \n",
    "#     plt.colorbar()\n",
    "\n",
    "\n",
    "    loop_max_counter -= 1\n",
    "    if loop_max_counter == 0:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ---- Validation fold index:  1 / 5\n",
      "2017-07-14 17:23:38.057107 2228 557\n",
      "\n",
      " 2017-07-14 17:23:39.296927 - Loaded SqueezeNet21_rare_tags model ...\n",
      "\n",
      " 2017-07-14 17:23:39.297030 - Start training ...\n",
      "\n",
      "-- Training parameters: 16, 50, 11152, 848\n",
      "\n",
      "-- Fit model\n",
      "- New Keras API found -\n"
     ]
    }
   ],
   "source": [
    "# Start CV\n",
    "\n",
    "n_folds = 5\n",
    "val_fold_index = 0\n",
    "val_fold_indices = [0, ]  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "hists = []\n",
    "\n",
    "kf = KFold(n_splits=n_folds)\n",
    "trainval_id_type_list = np.array(trainval_id_type_list)\n",
    "for train_index, test_index in kf.split(trainval_id_type_list):\n",
    "    train_id_type_list, val_id_type_list = trainval_id_type_list[train_index], trainval_id_type_list[test_index]\n",
    "\n",
    "    if len(val_fold_indices) > 0:\n",
    "        if val_fold_index not in val_fold_indices:\n",
    "            val_fold_index += 1\n",
    "            continue\n",
    "\n",
    "    params['samples_per_epoch'] = 5 * len(train_id_type_list)\n",
    "    params['nb_val_samples'] = int(1.5 * len(val_id_type_list))\n",
    "\n",
    "    val_fold_index += 1\n",
    "    print(\"\\n\\n ---- Validation fold index: \", val_fold_index, \"/\", n_folds)\n",
    "\n",
    "    print(datetime.now(), len(train_id_type_list), len(val_id_type_list))\n",
    "    assert len(to_set(train_id_type_list) & to_set(val_id_type_list)) == 0, \"WTF\"\n",
    "\n",
    "    cnn = params['network'](lr=params['lr_kwargs']['lr'], **params, **params['network_kwargs'])\n",
    "    params['save_prefix'] = params['save_prefix_template'].format(cnn_name=cnn.name, fold_index=val_fold_index-1)\n",
    "    print(\"\\n {} - Loaded {} model ...\".format(datetime.now(), cnn.name))\n",
    "\n",
    "    if 'pretrained_model' in params:\n",
    "        load_pretrained_model(cnn, **params)\n",
    "    elif 'pretrained_model_template' in params:\n",
    "        params['pretrained_model'] = params['pretrained_model_template'].format(fold_index=(val_fold_index-1) % 3)\n",
    "        print((val_fold_index-1) % 3)\n",
    "        print(params['pretrained_model'])\n",
    "        load_pretrained_model(cnn, by_name=True, **params)\n",
    "\n",
    "    print(\"\\n {} - Start training ...\".format(datetime.now()))\n",
    "    h = train(cnn, train_id_type_list, val_id_type_list, **params)\n",
    "    if h is None:\n",
    "        continue\n",
    "    hists.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Validation all classes\n",
    "\n",
    "n_runs = 2\n",
    "n_folds = 5\n",
    "run_counter = 0\n",
    "cv_mean_scores = np.zeros((n_runs, n_folds))\n",
    "val_fold_indices = []  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "\n",
    "params['pretrained_model'] = 'load_best'\n",
    "\n",
    "_trainval_id_type_list = np.array(trainval_id_type_list)\n",
    "\n",
    "while run_counter < n_runs:\n",
    "    run_counter += 1\n",
    "    print(\"\\n\\n ---- New run : \", run_counter, \"/\", n_runs)\n",
    "    val_fold_index = 0\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    for train_index, test_index in kf.split(_trainval_id_type_list):\n",
    "        train_id_type_list, val_id_type_list = _trainval_id_type_list[train_index], _trainval_id_type_list[test_index]\n",
    "\n",
    "        if len(val_fold_indices) > 0:\n",
    "            if val_fold_index not in val_fold_indices:\n",
    "                val_fold_index += 1\n",
    "                continue\n",
    "\n",
    "        val_fold_index += 1\n",
    "        print(\"\\n\\n ---- Validation fold index: \", val_fold_index, \"/\", n_folds)\n",
    "\n",
    "        print(len(train_id_type_list), len(val_id_type_list))\n",
    "        assert len(to_set(train_id_type_list) & to_set(val_id_type_list)) == 0, \"WTF\"\n",
    "\n",
    "        cnn = params['network'](input_shape=params['input_shape'], n_classes=params['n_classes'])\n",
    "        params['save_prefix'] = params['save_prefix_template'].format(cnn_name=cnn.name, fold_index=val_fold_index-1)\n",
    "        print(\"\\n {} - Loaded {} model ...\".format(datetime.now(), cnn.name))\n",
    "\n",
    "        load_pretrained_model(cnn, **params)\n",
    "\n",
    "        params['seed'] += run_counter - 1\n",
    "\n",
    "        f2, mae = validate(cnn, val_id_type_list, verbose=0, **params)\n",
    "        cv_mean_scores[run_counter-1, val_fold_index-1] = f2\n",
    "\n",
    "        np.random.shuffle(_trainval_id_type_list)\n",
    "\n",
    "print(cv_mean_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
