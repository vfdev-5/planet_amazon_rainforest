{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SqueezeNet model on tif for multi-label classification of tag = 0 (artisanal mining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Project\n",
    "project_common_path = os.path.dirname('.')\n",
    "project_common_path = os.path.abspath(os.path.join(project_common_path, '..', 'common'))\n",
    "if not project_common_path in sys.path:\n",
    "    sys.path.append(project_common_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from data_utils import get_id_type_list_from_df, OUTPUT_PATH, GENERATED_DATA, to_set, RESOURCES_PATH\n",
    "from training_utils import classification_train as train, classification_validate as validate\n",
    "from training_utils import exp_decay, step_decay, get_high_zoom_imgaug_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675 675\n"
     ]
    }
   ],
   "source": [
    "from models.squeezenet_tif_classification import get_squeezenet_on_tif\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from data_utils import equalized_data_classes, unique_tags, TRAIN_ENC_CL_CSV\n",
    "from data_utils import load_pretrained_model, get_label\n",
    "from data_utils import DataCache\n",
    "\n",
    "from xy_providers import tif_image_label_provider\n",
    "from models.keras_metrics import binary_crossentropy_with_false_negatives\n",
    "\n",
    "\n",
    "# Setup configuration\n",
    "\n",
    "seed = 2017\n",
    "np.random.seed(seed)\n",
    "\n",
    "cache = DataCache(6000)  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "\n",
    "tag = equalized_data_classes[0][0]\n",
    "\n",
    "mask = TRAIN_ENC_CL_CSV[tag] > 0\n",
    "\n",
    "trainval_id_type_list = get_id_type_list_from_df(TRAIN_ENC_CL_CSV[mask], 'Train_tif')\n",
    "\n",
    "# ### ADD GENERATED IMAGES\n",
    "# from glob import glob\n",
    "# from data_utils import GENERATED_DATA, to_set, get_label\n",
    "\n",
    "# gen_train_files = glob(os.path.join(GENERATED_DATA, \"train\", \"tif\", \"*.tif\"))\n",
    "# gen_train_ids = [s[len(os.path.join(GENERATED_DATA, \"train\", \"tif\"))+1+len('gen_train_'):-4] for s in gen_train_files]\n",
    "# gen_id_type_list = [(image_id, \"Generated_Train_tif\") for image_id in gen_train_ids]\n",
    "# class_index_gen_train_ids = [id_type for id_type in gen_train_ids if np.sum(get_label(*gen_id_type_list[0], class_index=class_index)) > 0]\n",
    "# class_index_gen_id_type_list = [(image_id, \"Generated_Train_tif\") for image_id in class_index_gen_train_ids]\n",
    "# trainval_id_type_list = trainval_id_type_list + class_index_gen_id_type_list\n",
    "# ### ADD GENERATED IMAGES\n",
    "\n",
    "\n",
    "tags = list(unique_tags)\n",
    "tags.remove(tag)\n",
    "\n",
    "n_other_samples = int(len(trainval_id_type_list) * 1.0 / len(tags))\n",
    "\n",
    "for t in tags:\n",
    "    mask = TRAIN_ENC_CL_CSV[t] > 0    \n",
    "    id_type_list = np.array(get_id_type_list_from_df(TRAIN_ENC_CL_CSV[mask], 'Train_tif'))\n",
    "    id_type_list = list(to_set(id_type_list) - to_set(trainval_id_type_list))\n",
    "    np.random.shuffle(id_type_list)\n",
    "    trainval_id_type_list.extend(id_type_list[:n_other_samples])\n",
    "\n",
    "print(len(trainval_id_type_list), len(to_set(trainval_id_type_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('57', 'Train_tif'), 'artisinal_mine bare_ground clear primary water')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_utils import get_caption\n",
    "trainval_id_type_list[0], get_caption(*trainval_id_type_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'seed': seed,\n",
    "\n",
    "    'xy_provider': tif_image_label_provider,\n",
    "\n",
    "    'network': get_squeezenet_on_tif,\n",
    "    'optimizer': 'nadam',\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'nb_epochs': 25,    # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "    'batch_size': 32,  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "\n",
    "    'normalize_data': True,\n",
    "    'normalization': '',\n",
    "\n",
    "    'train_seq': get_high_zoom_imgaug_seq,\n",
    "    \n",
    "    'image_size': (256, 256),\n",
    "\n",
    "    'tag': tag,\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    'lr_kwargs': {\n",
    "        'lr': 0.01,\n",
    "        'a': 0.95,\n",
    "        'init_epoch': 0\n",
    "    },\n",
    "    'lr_decay_f': exp_decay,\n",
    "\n",
    "    # Reduce learning rate on plateau\n",
    "    'on_plateau': True,\n",
    "    'on_plateau_kwargs': {\n",
    "        'monitor': 'val_loss',\n",
    "        'factor': 0.1,\n",
    "        'patience': 3,\n",
    "        'verbose': 1\n",
    "    },\n",
    "\n",
    "    'cache': cache,\n",
    "\n",
    "#   'pretrained_model': 'load_best',\n",
    "#   'pretrained_model': os.path.join(GENERATED_DATA, \"weights\", \"\"),\n",
    "\n",
    "    'output_path': OUTPUT_PATH,\n",
    "}\n",
    "\n",
    "params['save_prefix_template'] = '{cnn_name}_tag=%i_fold={fold_index}_seed=%i' % (0, params['seed'])\n",
    "params['input_shape'] = params['image_size'] + (7,)\n",
    "params['n_classes'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_utils import get_label\n",
    "labels = np.zeros((len(trainval_id_type_list), 1), dtype=np.uint8)\n",
    "for i, it in enumerate(trainval_id_type_list):\n",
    "    labels[i, 0] = get_label(*it, tag=tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([339], dtype=uint64), 675)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = np.sum(labels, axis=0)\n",
    "stats, len(trainval_id_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ---- Validation fold index:  1 / 5\n",
      "2017-07-18 02:17:52.748380 540 135\n",
      "\n",
      " 2017-07-18 02:17:55.078104 - Loaded Separable_SqueezeNet_BN_on_tif model ...\n",
      "\n",
      " 2017-07-18 02:17:55.078213 - Start training ...\n",
      "\n",
      "-- Training parameters: 32, 25, 544, 160\n",
      "\n",
      "-- Fit model\n",
      "\n",
      "-- Fit stats of train dataset\n",
      "Load existing file: /Users/vfomin/Documents/ML/Kaggle/PlanetAmazonRainForest/common/../output/generated/Separable_SqueezeNet_BN_on_tif_tag=0_fold=0_seed=2017_stats.npz\n",
      "No need to recompute statistics\n",
      "- New Keras API found -\n",
      "Epoch 1/25\n",
      "16/17 [===========================>..] - ETA: 1s - loss: 0.7391 - precision: 0.2483 - recall: 0.1319\n",
      "Epoch validation: f2 = 1.000000, mae=0.000000 \n",
      "\n",
      "17/17 [==============================] - 44s - loss: 0.7358 - precision: 0.2337 - recall: 0.1241 - val_loss: 0.8402 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 28s - loss: 0.6615 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.9857 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 29s - loss: 0.6699 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.9621 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/25\n",
      "16/17 [===========================>..] - ETA: 1s - loss: 0.6657 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch validation: f2 = 1.000000, mae=0.000000 \n",
      "\n",
      "17/17 [==============================] - 38s - loss: 0.6651 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.9646 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/25\n",
      " 3/17 [====>.........................] - ETA: 20s - loss: 0.6384 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "\n",
      " ---- Validation fold index:  2 / 5\n",
      "2017-07-18 02:20:39.880141 540 135\n",
      "\n",
      " 2017-07-18 02:20:43.039200 - Loaded Separable_SqueezeNet_BN_on_tif model ...\n",
      "\n",
      " 2017-07-18 02:20:43.039303 - Start training ...\n",
      "\n",
      "-- Training parameters: 32, 25, 544, 160\n",
      "\n",
      "-- Fit model\n",
      "\n",
      "-- Fit stats of train dataset\n",
      "\n",
      "\n",
      " ---- Validation fold index:  3 / 5\n",
      "2017-07-18 02:20:44.804846 540 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-45514b3ff6c4>\", line 25, in <module>\n",
      "    cnn = params['network'](lr=params['lr_kwargs']['lr'], weights=weights, **params)\n",
      "  File \"/Users/vfomin/Documents/ML/Kaggle/PlanetAmazonRainForest/common/models/squeezenet_tif_classification.py\", line 59, in get_squeezenet_on_tif\n",
      "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
      "  File \"/Users/vfomin/Documents/ML/Kaggle/PlanetAmazonRainForest/common/models/squeezenet_tif_classification.py\", line 34, in fire_module\n",
      "    left = BatchNormalization(name=s_id + bn + exp1x1)(left)\n",
      "  File \"/usr/local/lib/python3.5/site-packages/keras/engine/topology.py\", line 569, in __call__\n",
      "    self.build(input_shapes[0])\n",
      "  File \"/usr/local/lib/python3.5/site-packages/keras/layers/normalization.py\", line 123, in build\n",
      "    trainable=False)\n",
      "  File \"/usr/local/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/site-packages/keras/engine/topology.py\", line 391, in add_weight\n",
      "    weight = K.variable(initializer(shape), dtype=dtype, name=name)\n",
      "  File \"/usr/local/lib/python3.5/site-packages/keras/initializers.py\", line 37, in __call__\n",
      "    return K.constant(1, shape=shape, dtype=dtype)\n",
      "  File \"/usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 357, in constant\n",
      "    return tf.constant(value, dtype=dtype, shape=shape, name=name)\n",
      "  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 102, in constant\n",
      "    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n",
      "  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 367, in make_tensor_proto\n",
      "    if np.prod(shape) == 0:\n",
      "  File \"/usr/local/lib/python3.5/site-packages/numpy/core/fromnumeric.py\", line 2518, in prod\n",
      "    out=out, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/site-packages/numpy/core/_methods.py\", line 35, in _prod\n",
      "    return umr_prod(a, axis, dtype, out, keepdims)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 718, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/posixpath.py\", line 372, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/posixpath.py\", line 405, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/posixpath.py\", line 87, in join\n",
      "    path += sep + b\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Start CV\n",
    "\n",
    "n_folds = 5\n",
    "val_fold_index = 0\n",
    "val_fold_indices = []  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "hists = []\n",
    "\n",
    "kf = KFold(n_splits=n_folds)\n",
    "trainval_id_type_list = np.array(trainval_id_type_list)\n",
    "for train_index, test_index in kf.split(trainval_id_type_list):\n",
    "    train_id_type_list, val_id_type_list = trainval_id_type_list[train_index], trainval_id_type_list[test_index]\n",
    "\n",
    "    if len(val_fold_indices) > 0:\n",
    "        if val_fold_index not in val_fold_indices:\n",
    "            val_fold_index += 1\n",
    "            continue\n",
    "\n",
    "    val_fold_index += 1\n",
    "    print(\"\\n\\n ---- Validation fold index: \", val_fold_index, \"/\", n_folds)\n",
    "\n",
    "    print(datetime.now(), len(train_id_type_list), len(val_id_type_list))\n",
    "    assert len(to_set(train_id_type_list) & to_set(val_id_type_list)) == 0, \"WTF\"\n",
    "\n",
    "    weights = None if 'pretrained_model' in params else None\n",
    "    cnn = params['network'](lr=params['lr_kwargs']['lr'], weights=weights, **params)\n",
    "    params['save_prefix'] = params['save_prefix_template'].format(cnn_name=cnn.name, fold_index=val_fold_index - 1)\n",
    "    print(\"\\n {} - Loaded {} model ...\".format(datetime.now(), cnn.name))\n",
    "\n",
    "    if 'pretrained_model' in params:\n",
    "        load_pretrained_model(cnn, **params)\n",
    "\n",
    "    print(\"\\n {} - Start training ...\".format(datetime.now()))\n",
    "    h = train(cnn, train_id_type_list, val_id_type_list, **params)\n",
    "    if h is None:\n",
    "        continue\n",
    "    hists.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from training_utils import get_gen_flow, get_val_imgaug_seq\n",
    "from metrics import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Fit stats of train dataset\n",
      "Load existing file: /Users/vfomin/Documents/ML/Kaggle/PlanetAmazonRainForest/common/../output/generated/Separable_SqueezeNet_BN_on_tif_tag=0_fold=0_seed=2017_stats.npz\n",
      "No need to recompute statistics\n"
     ]
    }
   ],
   "source": [
    "train_gen, train_flow = get_gen_flow(id_type_list=train_id_type_list,\n",
    "                                     imgaug_seq=params['train_seq'](params['seed']),\n",
    "                                     **params)\n",
    "params2 = dict(params)\n",
    "params2['normalization'] = 'from_save_prefix'\n",
    "\n",
    "val_gen, val_flow = get_gen_flow(id_type_list=val_id_type_list,\n",
    "                                 imgaug_seq=get_val_imgaug_seq(params['seed']),\n",
    "                                 **params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x, y in train_flow:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  ]\n",
      " [ 1.  ]\n",
      " [ 1.  ]\n",
      " [ 1.  ]\n",
      " [ 1.  ]\n",
      " [ 1.  ]\n",
      " [ 0.23]\n",
      " [ 0.23]\n",
      " [ 1.  ]\n",
      " [ 0.23]\n",
      " [ 0.23]\n",
      " [ 0.23]\n",
      " [ 1.  ]\n",
      " [ 0.23]\n",
      " [ 1.  ]\n",
      " [ 0.23]\n",
      " [ 0.23]\n",
      " [ 0.23]\n",
      " [ 0.23]\n",
      " [ 0.23]\n",
      " [ 0.23]\n",
      " [ 1.  ]\n",
      " [ 0.23]\n",
      " [ 1.  ]\n",
      " [ 1.  ]\n",
      " [ 0.23]\n",
      " [ 0.23]\n",
      " [ 1.  ]\n",
      " [ 1.  ]\n",
      " [ 1.  ]\n",
      " [ 1.  ]\n",
      " [ 0.23]]\n",
      "0.833333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict_on_batch(x)\n",
    "print((y_pred > 0.35).astype(np.uint8) - 0.77 * y), \n",
    "print(score(y, (y_pred > 0.35).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x2, y2 in val_flow:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.    0.    0.   -0.77  0.    0.    0.  ]\n",
      " [ 0.    0.   -0.77  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.   -0.77  0.    0.  ]\n",
      " [ 1.    0.    0.   -0.77  0.    0.    0.  ]\n",
      " [ 1.    0.    0.   -0.77  0.    0.    0.  ]\n",
      " [ 0.   -0.77  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.   -0.77  0.    0.    0.    0.  ]\n",
      " [ 0.   -0.77  0.    0.    0.    0.    0.  ]\n",
      " [ 0.23  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.23  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 1.    0.    0.    0.    0.   -0.77  0.  ]\n",
      " [ 0.23  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 1.    0.    0.    0.    0.   -0.77  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.77  0.    0.  ]\n",
      " [ 1.    0.    0.   -0.77  0.    0.    0.  ]\n",
      " [ 0.   -0.77  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.   -0.77  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.   -0.77  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.77  0.    0.  ]\n",
      " [ 0.    0.    0.    0.   -0.77  0.    0.  ]\n",
      " [ 0.23  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.   -0.77  0.  ]\n",
      " [ 1.    0.    0.   -0.77  0.    0.    0.  ]\n",
      " [ 0.23  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.   -0.77  0.    0.  ]\n",
      " [ 0.23  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.   -0.77  0.    0.  ]\n",
      " [ 0.23  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.   -0.77  0.    0.  ]\n",
      " [ 0.   -0.77  0.    0.    0.    0.    0.  ]\n",
      " [ 0.23  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 1.   -0.77  0.    0.    0.    0.    0.  ]]\n",
      "0.573040674603\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict_on_batch(x2)\n",
    "print((y_pred > 0.35).astype(np.uint8) - 0.77 * y2), \n",
    "print(score(y2, (y_pred > 0.1).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Validation all classes\n",
    "\n",
    "n_runs = 2\n",
    "n_folds = 5\n",
    "run_counter = 0\n",
    "cv_mean_scores = np.zeros((n_runs, n_folds))\n",
    "val_fold_indices = []  # !!! CHECK BEFORE LOAD TO FLOYD\n",
    "\n",
    "params['pretrained_model'] = 'load_best'\n",
    "\n",
    "_trainval_id_type_list = np.array(trainval_id_type_list)\n",
    "\n",
    "while run_counter < n_runs:\n",
    "    run_counter += 1\n",
    "    print(\"\\n\\n ---- New run : \", run_counter, \"/\", n_runs)\n",
    "    val_fold_index = 0\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    for train_index, test_index in kf.split(_trainval_id_type_list):\n",
    "        train_id_type_list, val_id_type_list = _trainval_id_type_list[train_index], _trainval_id_type_list[test_index]\n",
    "\n",
    "        if len(val_fold_indices) > 0:\n",
    "            if val_fold_index not in val_fold_indices:\n",
    "                val_fold_index += 1\n",
    "                continue\n",
    "\n",
    "        val_fold_index += 1\n",
    "        print(\"\\n\\n ---- Validation fold index: \", val_fold_index, \"/\", n_folds)\n",
    "\n",
    "        print(len(train_id_type_list), len(val_id_type_list))\n",
    "        assert len(to_set(train_id_type_list) & to_set(val_id_type_list)) == 0, \"WTF\"\n",
    "\n",
    "        cnn = params['network'](input_shape=params['input_shape'], n_classes=params['n_classes'])\n",
    "        params['save_prefix'] = params['save_prefix_template'].format(cnn_name=cnn.name, fold_index=val_fold_index-1)\n",
    "        print(\"\\n {} - Loaded {} model ...\".format(datetime.now(), cnn.name))\n",
    "\n",
    "        load_pretrained_model(cnn, **params)\n",
    "\n",
    "        params['seed'] += run_counter - 1\n",
    "\n",
    "        f2, mae = validate(cnn, val_id_type_list, verbose=0, **params)\n",
    "        cv_mean_scores[run_counter-1, val_fold_index-1] = f2\n",
    "\n",
    "        np.random.shuffle(_trainval_id_type_list)\n",
    "\n",
    "print(cv_mean_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
