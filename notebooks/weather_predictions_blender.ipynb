{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Predictions blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Project\n",
    "project_common_path = os.path.dirname('.')\n",
    "project_common_path = os.path.abspath(os.path.join(project_common_path, '..', 'common'))\n",
    "if not project_common_path in sys.path:\n",
    "    sys.path.append(project_common_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "os.environ['THEANO_FLAGS'] = 'device=cpu'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_utils import get_id_type_list_for_class, GENERATED_DATA, OUTPUT_PATH\n",
    "from test_utils import create_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load predictions on trainval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_utils import unique_tags, get_label\n",
    "\n",
    "target_tags = ['target_' + t for t in unique_tags]\n",
    "val_predictions_resnet_filepath = os.path.join(GENERATED_DATA, \"val_predictions_ResNet50_2017-07-18-14-50.csv\")\n",
    "val_predictions_squeezenet_filepath = os.path.join(GENERATED_DATA, \"val_predictions_SqueezeNet21_2017-07-13-22-23.csv\")\n",
    "\n",
    "val_predictions_vgg19_filepath = os.path.join(GENERATED_DATA, \"val_predictions_deep_model_vgg19_train_LB092919_prob.csv\")\n",
    "val_predictions_weirdcnn_filepath = os.path.join(GENERATED_DATA, \"val_predictions_deep_model_train_LB092655_prob.csv\")\n",
    "\n",
    "def get_val_predictions_df(val_predictions_filepath, search_prefix=\"val_predictions_*.csv\"):\n",
    "    if not os.path.exists(val_predictions_filepath):\n",
    "        val_predictions_csv = glob(os.path.join(OUTPUT_PATH, search_prefix))\n",
    "        df = pd.read_csv(val_predictions_csv[0]).dropna()\n",
    "        for filepath in val_predictions_csv[1:]:\n",
    "            df = pd.concat([df, pd.read_csv(filepath).dropna()])\n",
    "        df.reset_index(inplace=True)   \n",
    "        df.drop('index', axis=1, inplace=True)\n",
    "        df['image_id'] = df['image_name'].apply(lambda x: int(x[len('train_'):]))    \n",
    "        for t in target_tags:\n",
    "            df[t] = ''\n",
    "        def fill_target_tags(row):\n",
    "            image_id = row[0]\n",
    "            labels = get_label(image_id, \"Train_jpg\")\n",
    "            row[1:] = labels    \n",
    "            return row\n",
    "        cols = ['image_id', ] + target_tags\n",
    "        df[cols] = df[cols].apply(fill_target_tags, axis=1)\n",
    "\n",
    "        df.to_csv(val_predictions_filepath, index=False)\n",
    "        val_predictions_df = df\n",
    "        df = None    \n",
    "    else:\n",
    "        val_predictions_df = pd.read_csv(val_predictions_filepath)\n",
    "    return val_predictions_df\n",
    "\n",
    "\n",
    "val_predictions_resnet_df = get_val_predictions_df(val_predictions_resnet_filepath, \"val_predictions_ResNet50*_2017-07-18-14-50.csv\")\n",
    "val_predictions_squeezenet_df = get_val_predictions_df(val_predictions_squeezenet_filepath, \"val_predictions_SqueezeNet21*_2017-07-18-14-50.csv\")\n",
    "val_predictions_vgg19_df = get_val_predictions_df(val_predictions_vgg19_filepath, \"vgg19/deep_model_vgg19_train_LB092919_prob.csv\")\n",
    "val_predictions_weirdcnn_df = get_val_predictions_df(val_predictions_weirdcnn_filepath, \"custom_weird_model/deep_model_train_LB092655_prob.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40448\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>blooming</th>\n",
       "      <th>blow_down</th>\n",
       "      <th>clear</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>...</th>\n",
       "      <th>target_conventional_mine</th>\n",
       "      <th>target_cultivation</th>\n",
       "      <th>target_habitation</th>\n",
       "      <th>target_haze</th>\n",
       "      <th>target_partly_cloudy</th>\n",
       "      <th>target_primary</th>\n",
       "      <th>target_road</th>\n",
       "      <th>target_selective_logging</th>\n",
       "      <th>target_slash_burn</th>\n",
       "      <th>target_water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_18872</td>\n",
       "      <td>0.762381</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.023866</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.983301</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.932843</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_10562</td>\n",
       "      <td>0.106635</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.020308</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_28763</td>\n",
       "      <td>0.196588</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.084854</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_31735</td>\n",
       "      <td>0.084816</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.013537</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>0.014883</td>\n",
       "      <td>0.633817</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.045785</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_320</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name  agriculture  artisinal_mine  bare_ground  blooming  blow_down  \\\n",
       "0  train_18872     0.762381        0.007814     0.023866  0.002480   0.001474   \n",
       "1  train_10562     0.106635        0.000834     0.002179  0.001490   0.001146   \n",
       "2  train_28763     0.196588        0.004786     0.009777  0.002631   0.001869   \n",
       "3  train_31735     0.084816        0.001532     0.013537  0.010144   0.014883   \n",
       "4    train_320     0.106061        0.001101     0.004905  0.004541   0.001737   \n",
       "\n",
       "      clear    cloudy  conventional_mine  cultivation      ...       \\\n",
       "0  0.983301  0.000370           0.002931     0.932843      ...        \n",
       "1  0.000112  0.003351           0.001014     0.020308      ...        \n",
       "2  0.019417  0.105915           0.004077     0.084854      ...        \n",
       "3  0.633817  0.002344           0.002039     0.045785      ...        \n",
       "4  0.000195  0.000810           0.001513     0.102018      ...        \n",
       "\n",
       "   target_conventional_mine  target_cultivation  target_habitation  \\\n",
       "0                         0                   1                  1   \n",
       "1                         0                   0                  0   \n",
       "2                         0                   1                  1   \n",
       "3                         0                   0                  0   \n",
       "4                         0                   0                  0   \n",
       "\n",
       "   target_haze  target_partly_cloudy  target_primary  target_road  \\\n",
       "0            0                     0               1            0   \n",
       "1            0                     1               1            0   \n",
       "2            0                     1               1            0   \n",
       "3            0                     0               1            0   \n",
       "4            0                     1               1            0   \n",
       "\n",
       "   target_selective_logging  target_slash_burn  target_water  \n",
       "0                         0                  1             1  \n",
       "1                         0                  0             0  \n",
       "2                         0                  0             0  \n",
       "3                         0                  0             0  \n",
       "4                         0                  0             0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(val_predictions_resnet_df))\n",
    "val_predictions_resnet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>blooming</th>\n",
       "      <th>blow_down</th>\n",
       "      <th>clear</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>...</th>\n",
       "      <th>target_conventional_mine</th>\n",
       "      <th>target_cultivation</th>\n",
       "      <th>target_habitation</th>\n",
       "      <th>target_haze</th>\n",
       "      <th>target_partly_cloudy</th>\n",
       "      <th>target_primary</th>\n",
       "      <th>target_road</th>\n",
       "      <th>target_selective_logging</th>\n",
       "      <th>target_slash_burn</th>\n",
       "      <th>target_water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_15438</td>\n",
       "      <td>0.986593</td>\n",
       "      <td>1.800301e-07</td>\n",
       "      <td>0.016957</td>\n",
       "      <td>3.479813e-08</td>\n",
       "      <td>2.728809e-07</td>\n",
       "      <td>0.986830</td>\n",
       "      <td>1.494415e-08</td>\n",
       "      <td>2.339067e-04</td>\n",
       "      <td>0.128825</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_12863</td>\n",
       "      <td>0.024612</td>\n",
       "      <td>7.483472e-08</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>8.198895e-03</td>\n",
       "      <td>1.618286e-03</td>\n",
       "      <td>0.997336</td>\n",
       "      <td>1.701083e-08</td>\n",
       "      <td>9.840907e-09</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_10519</td>\n",
       "      <td>0.721716</td>\n",
       "      <td>5.289071e-05</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>1.069636e-04</td>\n",
       "      <td>1.935463e-03</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>2.059214e-05</td>\n",
       "      <td>3.164162e-05</td>\n",
       "      <td>0.509124</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_17178</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>9.790796e-11</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.204151e-03</td>\n",
       "      <td>8.132902e-05</td>\n",
       "      <td>0.998747</td>\n",
       "      <td>8.051727e-10</td>\n",
       "      <td>1.947120e-11</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_5177</td>\n",
       "      <td>0.066280</td>\n",
       "      <td>3.975656e-07</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>5.240596e-04</td>\n",
       "      <td>2.015755e-04</td>\n",
       "      <td>0.348959</td>\n",
       "      <td>4.480021e-04</td>\n",
       "      <td>5.901127e-07</td>\n",
       "      <td>0.016081</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name  agriculture  artisinal_mine  bare_ground      blooming  \\\n",
       "0  train_15438     0.986593    1.800301e-07     0.016957  3.479813e-08   \n",
       "1  train_12863     0.024612    7.483472e-08     0.000639  8.198895e-03   \n",
       "2  train_10519     0.721716    5.289071e-05     0.014284  1.069636e-04   \n",
       "3  train_17178     0.002469    9.790796e-11     0.000020  1.204151e-03   \n",
       "4   train_5177     0.066280    3.975656e-07     0.001354  5.240596e-04   \n",
       "\n",
       "      blow_down     clear        cloudy  conventional_mine  cultivation  \\\n",
       "0  2.728809e-07  0.986830  1.494415e-08       2.339067e-04     0.128825   \n",
       "1  1.618286e-03  0.997336  1.701083e-08       9.840907e-09     0.007981   \n",
       "2  1.935463e-03  0.000348  2.059214e-05       3.164162e-05     0.509124   \n",
       "3  8.132902e-05  0.998747  8.051727e-10       1.947120e-11     0.000470   \n",
       "4  2.015755e-04  0.348959  4.480021e-04       5.901127e-07     0.016081   \n",
       "\n",
       "       ...       target_conventional_mine  target_cultivation  \\\n",
       "0      ...                              0                   1   \n",
       "1      ...                              0                   0   \n",
       "2      ...                              0                   0   \n",
       "3      ...                              0                   0   \n",
       "4      ...                              0                   0   \n",
       "\n",
       "   target_habitation  target_haze  target_partly_cloudy  target_primary  \\\n",
       "0                  0            1                     0               1   \n",
       "1                  0            0                     0               1   \n",
       "2                  0            0                     1               1   \n",
       "3                  0            0                     0               1   \n",
       "4                  0            0                     0               1   \n",
       "\n",
       "   target_road  target_selective_logging  target_slash_burn  target_water  \n",
       "0            1                         0                  0             0  \n",
       "1            0                         0                  0             0  \n",
       "2            0                         0                  0             0  \n",
       "3            0                         0                  0             0  \n",
       "4            0                         0                  0             0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(val_predictions_squeezenet_df))\n",
    "val_predictions_squeezenet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27158, 31357)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_predictions_resnet_df['image_name'].unique()), len(val_predictions_squeezenet_df['image_name'].unique()), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from metrics import score\n",
    "\n",
    "def get_optimal_thresholds(y_true, y_preds):\n",
    "    best_thresholds = [0.0]*len(unique_tags)    \n",
    "    best_score = 0\n",
    "    thrs = np.arange(0.0, 1.0, 0.01)    \n",
    "    for i, tag in enumerate(unique_tags):\n",
    "        print(\"%s : best_score=\" % tag, end=\"\")\n",
    "        thresholds = list(best_thresholds)\n",
    "        for thr in thrs:            \n",
    "            thresholds[i] = thr\n",
    "            s = score(y_true, y_preds > thresholds)\n",
    "            if s > best_score:\n",
    "                best_score = s\n",
    "                best_thresholds[i] = thr\n",
    "        print(\"%f, best_threshold=%f\" % (best_score, best_thresholds[i]))\n",
    "    return best_thresholds, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train xgboost trees to make better predict weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train to predict weather classes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_tags = ['clear', 'cloudy', 'haze', 'partly_cloudy']\n",
    "weather_target_tags = ['target_%s' % t for t in weather_tags]\n",
    "weather_labels = np.where(np.isin(unique_tags, weather_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 5,  6, 10, 11]),),\n",
       " [(0, 'agriculture'),\n",
       "  (1, 'artisinal_mine'),\n",
       "  (2, 'bare_ground'),\n",
       "  (3, 'blooming'),\n",
       "  (4, 'blow_down'),\n",
       "  (5, 'clear'),\n",
       "  (6, 'cloudy'),\n",
       "  (7, 'conventional_mine'),\n",
       "  (8, 'cultivation'),\n",
       "  (9, 'habitation'),\n",
       "  (10, 'haze'),\n",
       "  (11, 'partly_cloudy'),\n",
       "  (12, 'primary'),\n",
       "  (13, 'road'),\n",
       "  (14, 'selective_logging'),\n",
       "  (15, 'slash_burn'),\n",
       "  (16, 'water')],\n",
       " ['target_clear', 'target_cloudy', 'target_haze', 'target_partly_cloudy'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_labels, [(i, t) for i, t in enumerate(unique_tags)], weather_target_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_predictions_df = val_predictions_vgg19_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agriculture</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>blooming</th>\n",
       "      <th>blow_down</th>\n",
       "      <th>clear</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>habitation</th>\n",
       "      <th>...</th>\n",
       "      <th>target_conventional_mine</th>\n",
       "      <th>target_cultivation</th>\n",
       "      <th>target_habitation</th>\n",
       "      <th>target_haze</th>\n",
       "      <th>target_partly_cloudy</th>\n",
       "      <th>target_primary</th>\n",
       "      <th>target_road</th>\n",
       "      <th>target_selective_logging</th>\n",
       "      <th>target_slash_burn</th>\n",
       "      <th>target_water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003752</td>\n",
       "      <td>1.428458e-09</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.581344</td>\n",
       "      <td>2.108085e-05</td>\n",
       "      <td>2.150840e-09</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.799365</td>\n",
       "      <td>1.561381e-04</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.998879</td>\n",
       "      <td>1.573375e-06</td>\n",
       "      <td>1.418633e-04</td>\n",
       "      <td>0.128822</td>\n",
       "      <td>0.038553</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001674</td>\n",
       "      <td>1.083242e-09</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.999015</td>\n",
       "      <td>1.269098e-06</td>\n",
       "      <td>8.769292e-11</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005073</td>\n",
       "      <td>3.921103e-08</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.998185</td>\n",
       "      <td>2.577778e-06</td>\n",
       "      <td>3.010564e-09</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.879332</td>\n",
       "      <td>1.331866e-03</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.998223</td>\n",
       "      <td>4.311219e-07</td>\n",
       "      <td>3.768842e-04</td>\n",
       "      <td>0.343372</td>\n",
       "      <td>0.786686</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   agriculture  artisinal_mine  bare_ground  blooming  blow_down     clear  \\\n",
       "0     0.003752    1.428458e-09     0.000088  0.000230   0.000018  0.581344   \n",
       "1     0.799365    1.561381e-04     0.009740  0.000171   0.000109  0.998879   \n",
       "2     0.001674    1.083242e-09     0.000018  0.000292   0.000128  0.999015   \n",
       "3     0.005073    3.921103e-08     0.000086  0.006642   0.000504  0.998185   \n",
       "4     0.879332    1.331866e-03     0.017324  0.001006   0.000401  0.998223   \n",
       "\n",
       "         cloudy  conventional_mine  cultivation  habitation      ...       \\\n",
       "0  2.108085e-05       2.150840e-09     0.001460    0.000500      ...        \n",
       "1  1.573375e-06       1.418633e-04     0.128822    0.038553      ...        \n",
       "2  1.269098e-06       8.769292e-11     0.000902    0.000416      ...        \n",
       "3  2.577778e-06       3.010564e-09     0.002385    0.002778      ...        \n",
       "4  4.311219e-07       3.768842e-04     0.343372    0.786686      ...        \n",
       "\n",
       "   target_conventional_mine  target_cultivation  target_habitation  \\\n",
       "0                         0                   0                  0   \n",
       "1                         0                   0                  0   \n",
       "2                         0                   0                  0   \n",
       "3                         0                   0                  0   \n",
       "4                         0                   0                  1   \n",
       "\n",
       "   target_haze  target_partly_cloudy  target_primary  target_road  \\\n",
       "0            1                     0               1            0   \n",
       "1            0                     0               1            0   \n",
       "2            0                     0               1            0   \n",
       "3            0                     0               1            0   \n",
       "4            0                     0               1            1   \n",
       "\n",
       "  target_selective_logging  target_slash_burn  target_water  \n",
       "0                        0                  0             0  \n",
       "1                        0                  0             1  \n",
       "2                        0                  0             0  \n",
       "3                        0                  0             0  \n",
       "4                        0                  0             0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple try of xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = val_predictions_df[weather_target_tags].sum(axis=1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=n_folds)\n",
    "\n",
    "trainval_x = val_predictions_df[m][unique_tags].values\n",
    "trainval_y = val_predictions_df[m][weather_target_tags].values\n",
    "\n",
    "d = {\n",
    "    (1, 0, 0, 0) : 0,\n",
    "    (0, 1, 0, 0) : 1,    \n",
    "    (0, 0, 1, 0) : 2,   \n",
    "    (0, 0, 0, 1) : 3,    \n",
    "}\n",
    "\n",
    "def vector_to_index(trainval_y):\n",
    "    \n",
    "    output = np.zeros(len(trainval_y), dtype=np.uint8)\n",
    "    for i, v in enumerate(trainval_y):        \n",
    "        output[i] = d[tuple(v.tolist())]\n",
    "    return output\n",
    "\n",
    "trainval_y_ = vector_to_index(trainval_y)\n",
    "    \n",
    "for train_index, test_index in kf.split(trainval_x):\n",
    "    train_x, val_x = trainval_x[train_index], trainval_x[test_index]\n",
    "    train_y, val_y = trainval_y_[train_index], trainval_y_[test_index]\n",
    "    \n",
    "#     print(train_x.shape, train_y.shape)\n",
    "#     print(train_x[:5, :], train_y[:5])\n",
    "#     print(val_x[:5, :], val_y[:5])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"tree_method\": 'exact',\n",
    "    \"n_estimators\": 150,\n",
    "    \"max_depth\": 3,\n",
    "#     \"subsample\": subsample,\n",
    "#     \"colsample_bytree\": colsample_bytree,\n",
    "    \"silent\": False,    \n",
    "    \"num_class\": len(weather_target_tags)\n",
    "}\n",
    "num_boost_round = 2500\n",
    "early_stopping_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sumpw = val_predictions_df[target_tags[tag_index]].sum()\n",
    "# sumnw = len(val_predictions_df[target_tags[tag_index]]) - sumpw    \n",
    "# scale_pos_weight = sumnw * 1.0 / sumpw\n",
    "\n",
    "# params['scale_pos_weight'] = scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "dval = xgb.DMatrix(val_x, label=val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "watchlist = ((dtrain, 'train'), (dval, 'eval'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.36853\teval-mlogloss:1.36854\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:1.35115\teval-mlogloss:1.35116\n",
      "[2]\ttrain-mlogloss:1.33413\teval-mlogloss:1.33415\n",
      "[3]\ttrain-mlogloss:1.31747\teval-mlogloss:1.3175\n",
      "[4]\ttrain-mlogloss:1.30115\teval-mlogloss:1.30119\n",
      "[5]\ttrain-mlogloss:1.28516\teval-mlogloss:1.2852\n",
      "[6]\ttrain-mlogloss:1.26949\teval-mlogloss:1.26953\n",
      "[7]\ttrain-mlogloss:1.25412\teval-mlogloss:1.25417\n",
      "[8]\ttrain-mlogloss:1.23906\teval-mlogloss:1.23911\n",
      "[9]\ttrain-mlogloss:1.22429\teval-mlogloss:1.22434\n",
      "[10]\ttrain-mlogloss:1.20979\teval-mlogloss:1.20985\n",
      "[11]\ttrain-mlogloss:1.19557\teval-mlogloss:1.19563\n",
      "[12]\ttrain-mlogloss:1.18161\teval-mlogloss:1.18168\n",
      "[13]\ttrain-mlogloss:1.1679\teval-mlogloss:1.16798\n",
      "[14]\ttrain-mlogloss:1.15445\teval-mlogloss:1.15453\n",
      "[15]\ttrain-mlogloss:1.14123\teval-mlogloss:1.14132\n",
      "[16]\ttrain-mlogloss:1.12825\teval-mlogloss:1.12834\n",
      "[17]\ttrain-mlogloss:1.11549\teval-mlogloss:1.11559\n",
      "[18]\ttrain-mlogloss:1.10296\teval-mlogloss:1.10306\n",
      "[19]\ttrain-mlogloss:1.09065\teval-mlogloss:1.09075\n",
      "[20]\ttrain-mlogloss:1.07854\teval-mlogloss:1.07865\n",
      "[21]\ttrain-mlogloss:1.06663\teval-mlogloss:1.06675\n",
      "[22]\ttrain-mlogloss:1.05493\teval-mlogloss:1.05505\n",
      "[23]\ttrain-mlogloss:1.04342\teval-mlogloss:1.04354\n",
      "[24]\ttrain-mlogloss:1.0321\teval-mlogloss:1.03222\n",
      "[25]\ttrain-mlogloss:1.02096\teval-mlogloss:1.02109\n",
      "[26]\ttrain-mlogloss:1.01001\teval-mlogloss:1.01014\n",
      "[27]\ttrain-mlogloss:0.999224\teval-mlogloss:0.999357\n",
      "[28]\ttrain-mlogloss:0.988614\teval-mlogloss:0.988751\n",
      "[29]\ttrain-mlogloss:0.978168\teval-mlogloss:0.978313\n",
      "[30]\ttrain-mlogloss:0.967886\teval-mlogloss:0.968035\n",
      "[31]\ttrain-mlogloss:0.957763\teval-mlogloss:0.95792\n",
      "[32]\ttrain-mlogloss:0.947797\teval-mlogloss:0.947959\n",
      "[33]\ttrain-mlogloss:0.937984\teval-mlogloss:0.938149\n",
      "[34]\ttrain-mlogloss:0.928319\teval-mlogloss:0.92849\n",
      "[35]\ttrain-mlogloss:0.9188\teval-mlogloss:0.918981\n",
      "[36]\ttrain-mlogloss:0.909424\teval-mlogloss:0.909608\n",
      "[37]\ttrain-mlogloss:0.900187\teval-mlogloss:0.900376\n",
      "[38]\ttrain-mlogloss:0.891087\teval-mlogloss:0.891281\n",
      "[39]\ttrain-mlogloss:0.88212\teval-mlogloss:0.882321\n",
      "[40]\ttrain-mlogloss:0.873287\teval-mlogloss:0.873486\n",
      "[41]\ttrain-mlogloss:0.864582\teval-mlogloss:0.864784\n",
      "[42]\ttrain-mlogloss:0.856004\teval-mlogloss:0.856202\n",
      "[43]\ttrain-mlogloss:0.847549\teval-mlogloss:0.847747\n",
      "[44]\ttrain-mlogloss:0.839215\teval-mlogloss:0.839411\n",
      "[45]\ttrain-mlogloss:0.831\teval-mlogloss:0.831192\n",
      "[46]\ttrain-mlogloss:0.822901\teval-mlogloss:0.823092\n",
      "[47]\ttrain-mlogloss:0.814916\teval-mlogloss:0.815103\n",
      "[48]\ttrain-mlogloss:0.807042\teval-mlogloss:0.807226\n",
      "[49]\ttrain-mlogloss:0.799278\teval-mlogloss:0.79946\n",
      "[50]\ttrain-mlogloss:0.791622\teval-mlogloss:0.791803\n",
      "[51]\ttrain-mlogloss:0.784071\teval-mlogloss:0.784249\n",
      "[52]\ttrain-mlogloss:0.776624\teval-mlogloss:0.776798\n",
      "[53]\ttrain-mlogloss:0.769278\teval-mlogloss:0.769451\n",
      "[54]\ttrain-mlogloss:0.762033\teval-mlogloss:0.762206\n",
      "[55]\ttrain-mlogloss:0.754886\teval-mlogloss:0.755055\n",
      "[56]\ttrain-mlogloss:0.747835\teval-mlogloss:0.748006\n",
      "[57]\ttrain-mlogloss:0.740879\teval-mlogloss:0.741045\n",
      "[58]\ttrain-mlogloss:0.734016\teval-mlogloss:0.734182\n",
      "[59]\ttrain-mlogloss:0.727243\teval-mlogloss:0.72741\n",
      "[60]\ttrain-mlogloss:0.720561\teval-mlogloss:0.72073\n",
      "[61]\ttrain-mlogloss:0.713967\teval-mlogloss:0.714134\n",
      "[62]\ttrain-mlogloss:0.70746\teval-mlogloss:0.707628\n",
      "[63]\ttrain-mlogloss:0.701038\teval-mlogloss:0.701205\n",
      "[64]\ttrain-mlogloss:0.6947\teval-mlogloss:0.694866\n",
      "[65]\ttrain-mlogloss:0.688442\teval-mlogloss:0.688613\n",
      "[66]\ttrain-mlogloss:0.682265\teval-mlogloss:0.68244\n",
      "[67]\ttrain-mlogloss:0.676168\teval-mlogloss:0.676348\n",
      "[68]\ttrain-mlogloss:0.67015\teval-mlogloss:0.670333\n",
      "[69]\ttrain-mlogloss:0.664209\teval-mlogloss:0.664398\n",
      "[70]\ttrain-mlogloss:0.658343\teval-mlogloss:0.658536\n",
      "[71]\ttrain-mlogloss:0.652552\teval-mlogloss:0.652752\n",
      "[72]\ttrain-mlogloss:0.646835\teval-mlogloss:0.647035\n",
      "[73]\ttrain-mlogloss:0.641189\teval-mlogloss:0.641397\n",
      "[74]\ttrain-mlogloss:0.635615\teval-mlogloss:0.635827\n",
      "[75]\ttrain-mlogloss:0.630111\teval-mlogloss:0.63033\n",
      "[76]\ttrain-mlogloss:0.624675\teval-mlogloss:0.624901\n",
      "[77]\ttrain-mlogloss:0.619308\teval-mlogloss:0.619539\n",
      "[78]\ttrain-mlogloss:0.614007\teval-mlogloss:0.614243\n",
      "[79]\ttrain-mlogloss:0.608773\teval-mlogloss:0.609016\n",
      "[80]\ttrain-mlogloss:0.603603\teval-mlogloss:0.603851\n",
      "[81]\ttrain-mlogloss:0.598497\teval-mlogloss:0.598752\n",
      "[82]\ttrain-mlogloss:0.593454\teval-mlogloss:0.593714\n",
      "[83]\ttrain-mlogloss:0.588473\teval-mlogloss:0.588743\n",
      "[84]\ttrain-mlogloss:0.583553\teval-mlogloss:0.583828\n",
      "[85]\ttrain-mlogloss:0.578694\teval-mlogloss:0.578978\n",
      "[86]\ttrain-mlogloss:0.573893\teval-mlogloss:0.574182\n",
      "[87]\ttrain-mlogloss:0.569151\teval-mlogloss:0.56945\n",
      "[88]\ttrain-mlogloss:0.564467\teval-mlogloss:0.564771\n",
      "[89]\ttrain-mlogloss:0.55984\teval-mlogloss:0.560151\n",
      "[90]\ttrain-mlogloss:0.555268\teval-mlogloss:0.555585\n",
      "[91]\ttrain-mlogloss:0.550751\teval-mlogloss:0.551077\n",
      "[92]\ttrain-mlogloss:0.546289\teval-mlogloss:0.546624\n",
      "[93]\ttrain-mlogloss:0.54188\teval-mlogloss:0.542226\n",
      "[94]\ttrain-mlogloss:0.537524\teval-mlogloss:0.537879\n",
      "[95]\ttrain-mlogloss:0.53322\teval-mlogloss:0.533586\n",
      "[96]\ttrain-mlogloss:0.528967\teval-mlogloss:0.529342\n",
      "[97]\ttrain-mlogloss:0.524765\teval-mlogloss:0.525152\n",
      "[98]\ttrain-mlogloss:0.520613\teval-mlogloss:0.521005\n",
      "[99]\ttrain-mlogloss:0.516509\teval-mlogloss:0.516907\n",
      "[100]\ttrain-mlogloss:0.512454\teval-mlogloss:0.512862\n",
      "[101]\ttrain-mlogloss:0.508447\teval-mlogloss:0.50886\n",
      "[102]\ttrain-mlogloss:0.504486\teval-mlogloss:0.504909\n",
      "[103]\ttrain-mlogloss:0.500572\teval-mlogloss:0.501001\n",
      "[104]\ttrain-mlogloss:0.496703\teval-mlogloss:0.49714\n",
      "[105]\ttrain-mlogloss:0.49288\teval-mlogloss:0.493322\n",
      "[106]\ttrain-mlogloss:0.489101\teval-mlogloss:0.489552\n",
      "[107]\ttrain-mlogloss:0.485367\teval-mlogloss:0.485823\n",
      "[108]\ttrain-mlogloss:0.481676\teval-mlogloss:0.482138\n",
      "[109]\ttrain-mlogloss:0.478027\teval-mlogloss:0.478498\n",
      "[110]\ttrain-mlogloss:0.474421\teval-mlogloss:0.474899\n",
      "[111]\ttrain-mlogloss:0.470857\teval-mlogloss:0.471341\n",
      "[112]\ttrain-mlogloss:0.467334\teval-mlogloss:0.467825\n",
      "[113]\ttrain-mlogloss:0.463852\teval-mlogloss:0.464347\n",
      "[114]\ttrain-mlogloss:0.460409\teval-mlogloss:0.460911\n",
      "[115]\ttrain-mlogloss:0.457007\teval-mlogloss:0.457512\n",
      "[116]\ttrain-mlogloss:0.453643\teval-mlogloss:0.454152\n",
      "[117]\ttrain-mlogloss:0.450318\teval-mlogloss:0.450832\n",
      "[118]\ttrain-mlogloss:0.447032\teval-mlogloss:0.447548\n",
      "[119]\ttrain-mlogloss:0.443782\teval-mlogloss:0.444302\n",
      "[120]\ttrain-mlogloss:0.44057\teval-mlogloss:0.441095\n",
      "[121]\ttrain-mlogloss:0.437394\teval-mlogloss:0.437921\n",
      "[122]\ttrain-mlogloss:0.434254\teval-mlogloss:0.434789\n",
      "[123]\ttrain-mlogloss:0.43115\teval-mlogloss:0.431685\n",
      "[124]\ttrain-mlogloss:0.428081\teval-mlogloss:0.428621\n",
      "[125]\ttrain-mlogloss:0.425046\teval-mlogloss:0.42559\n",
      "[126]\ttrain-mlogloss:0.422046\teval-mlogloss:0.422593\n",
      "[127]\ttrain-mlogloss:0.41908\teval-mlogloss:0.419629\n",
      "[128]\ttrain-mlogloss:0.416147\teval-mlogloss:0.416703\n",
      "[129]\ttrain-mlogloss:0.413246\teval-mlogloss:0.413807\n",
      "[130]\ttrain-mlogloss:0.410376\teval-mlogloss:0.410942\n",
      "[131]\ttrain-mlogloss:0.407541\teval-mlogloss:0.408113\n",
      "[132]\ttrain-mlogloss:0.404736\teval-mlogloss:0.405314\n",
      "[133]\ttrain-mlogloss:0.401964\teval-mlogloss:0.40255\n",
      "[134]\ttrain-mlogloss:0.39922\teval-mlogloss:0.399812\n",
      "[135]\ttrain-mlogloss:0.396508\teval-mlogloss:0.397104\n",
      "[136]\ttrain-mlogloss:0.393825\teval-mlogloss:0.394426\n",
      "[137]\ttrain-mlogloss:0.391173\teval-mlogloss:0.391781\n",
      "[138]\ttrain-mlogloss:0.388549\teval-mlogloss:0.389162\n",
      "[139]\ttrain-mlogloss:0.385956\teval-mlogloss:0.386576\n",
      "[140]\ttrain-mlogloss:0.38339\teval-mlogloss:0.384016\n",
      "[141]\ttrain-mlogloss:0.380854\teval-mlogloss:0.381483\n",
      "[142]\ttrain-mlogloss:0.378346\teval-mlogloss:0.378982\n",
      "[143]\ttrain-mlogloss:0.375866\teval-mlogloss:0.376507\n",
      "[144]\ttrain-mlogloss:0.373413\teval-mlogloss:0.374059\n",
      "[145]\ttrain-mlogloss:0.370988\teval-mlogloss:0.371639\n",
      "[146]\ttrain-mlogloss:0.368589\teval-mlogloss:0.369245\n",
      "[147]\ttrain-mlogloss:0.366216\teval-mlogloss:0.366878\n",
      "[148]\ttrain-mlogloss:0.36387\teval-mlogloss:0.364536\n",
      "[149]\ttrain-mlogloss:0.361549\teval-mlogloss:0.362221\n",
      "[150]\ttrain-mlogloss:0.359254\teval-mlogloss:0.35993\n",
      "[151]\ttrain-mlogloss:0.356984\teval-mlogloss:0.357665\n",
      "[152]\ttrain-mlogloss:0.354739\teval-mlogloss:0.355423\n",
      "[153]\ttrain-mlogloss:0.352519\teval-mlogloss:0.353209\n",
      "[154]\ttrain-mlogloss:0.350323\teval-mlogloss:0.351019\n",
      "[155]\ttrain-mlogloss:0.348151\teval-mlogloss:0.348852\n",
      "[156]\ttrain-mlogloss:0.346002\teval-mlogloss:0.346709\n",
      "[157]\ttrain-mlogloss:0.343877\teval-mlogloss:0.344588\n",
      "[158]\ttrain-mlogloss:0.341776\teval-mlogloss:0.342489\n",
      "[159]\ttrain-mlogloss:0.339697\teval-mlogloss:0.340413\n",
      "[160]\ttrain-mlogloss:0.33764\teval-mlogloss:0.338362\n",
      "[161]\ttrain-mlogloss:0.335607\teval-mlogloss:0.336331\n",
      "[162]\ttrain-mlogloss:0.333595\teval-mlogloss:0.334324\n",
      "[163]\ttrain-mlogloss:0.331605\teval-mlogloss:0.332338\n",
      "[164]\ttrain-mlogloss:0.329636\teval-mlogloss:0.330373\n",
      "[165]\ttrain-mlogloss:0.327689\teval-mlogloss:0.32843\n",
      "[166]\ttrain-mlogloss:0.325763\teval-mlogloss:0.326507\n",
      "[167]\ttrain-mlogloss:0.323857\teval-mlogloss:0.324608\n",
      "[168]\ttrain-mlogloss:0.321973\teval-mlogloss:0.322728\n",
      "[169]\ttrain-mlogloss:0.320108\teval-mlogloss:0.32087\n",
      "[170]\ttrain-mlogloss:0.318264\teval-mlogloss:0.319031\n",
      "[171]\ttrain-mlogloss:0.316439\teval-mlogloss:0.317213\n",
      "[172]\ttrain-mlogloss:0.314635\teval-mlogloss:0.315414\n",
      "[173]\ttrain-mlogloss:0.312849\teval-mlogloss:0.313635\n",
      "[174]\ttrain-mlogloss:0.311082\teval-mlogloss:0.311878\n",
      "[175]\ttrain-mlogloss:0.309334\teval-mlogloss:0.310141\n",
      "[176]\ttrain-mlogloss:0.307605\teval-mlogloss:0.308423\n",
      "[177]\ttrain-mlogloss:0.305894\teval-mlogloss:0.306722\n",
      "[178]\ttrain-mlogloss:0.304201\teval-mlogloss:0.305041\n",
      "[179]\ttrain-mlogloss:0.302527\teval-mlogloss:0.30338\n",
      "[180]\ttrain-mlogloss:0.30087\teval-mlogloss:0.301731\n",
      "[181]\ttrain-mlogloss:0.299231\teval-mlogloss:0.300106\n",
      "[182]\ttrain-mlogloss:0.297609\teval-mlogloss:0.298497\n",
      "[183]\ttrain-mlogloss:0.296004\teval-mlogloss:0.296904\n",
      "[184]\ttrain-mlogloss:0.294415\teval-mlogloss:0.295327\n",
      "[185]\ttrain-mlogloss:0.292843\teval-mlogloss:0.293768\n",
      "[186]\ttrain-mlogloss:0.291288\teval-mlogloss:0.292227\n",
      "[187]\ttrain-mlogloss:0.28975\teval-mlogloss:0.290698\n",
      "[188]\ttrain-mlogloss:0.288228\teval-mlogloss:0.28919\n",
      "[189]\ttrain-mlogloss:0.286722\teval-mlogloss:0.287697\n",
      "[190]\ttrain-mlogloss:0.285231\teval-mlogloss:0.286219\n",
      "[191]\ttrain-mlogloss:0.283757\teval-mlogloss:0.284754\n",
      "[192]\ttrain-mlogloss:0.282298\teval-mlogloss:0.28331\n",
      "[193]\ttrain-mlogloss:0.280854\teval-mlogloss:0.281877\n",
      "[194]\ttrain-mlogloss:0.279426\teval-mlogloss:0.280461\n",
      "[195]\ttrain-mlogloss:0.278013\teval-mlogloss:0.279057\n",
      "[196]\ttrain-mlogloss:0.276615\teval-mlogloss:0.277669\n",
      "[197]\ttrain-mlogloss:0.275231\teval-mlogloss:0.276295\n",
      "[198]\ttrain-mlogloss:0.273862\teval-mlogloss:0.274936\n",
      "[199]\ttrain-mlogloss:0.272507\teval-mlogloss:0.273592\n",
      "[200]\ttrain-mlogloss:0.271166\teval-mlogloss:0.27226\n",
      "[201]\ttrain-mlogloss:0.269839\teval-mlogloss:0.27094\n",
      "[202]\ttrain-mlogloss:0.268526\teval-mlogloss:0.269635\n",
      "[203]\ttrain-mlogloss:0.267227\teval-mlogloss:0.268344\n",
      "[204]\ttrain-mlogloss:0.265941\teval-mlogloss:0.267066\n",
      "[205]\ttrain-mlogloss:0.264668\teval-mlogloss:0.265803\n",
      "[206]\ttrain-mlogloss:0.263409\teval-mlogloss:0.264553\n",
      "[207]\ttrain-mlogloss:0.262163\teval-mlogloss:0.263314\n",
      "[208]\ttrain-mlogloss:0.260929\teval-mlogloss:0.26209\n",
      "[209]\ttrain-mlogloss:0.259709\teval-mlogloss:0.260877\n",
      "[210]\ttrain-mlogloss:0.258501\teval-mlogloss:0.259677\n",
      "[211]\ttrain-mlogloss:0.257306\teval-mlogloss:0.258491\n",
      "[212]\ttrain-mlogloss:0.256123\teval-mlogloss:0.257313\n",
      "[213]\ttrain-mlogloss:0.254953\teval-mlogloss:0.256151\n",
      "[214]\ttrain-mlogloss:0.253795\teval-mlogloss:0.254997\n",
      "[215]\ttrain-mlogloss:0.252648\teval-mlogloss:0.253856\n",
      "[216]\ttrain-mlogloss:0.251514\teval-mlogloss:0.252729\n",
      "[217]\ttrain-mlogloss:0.250391\teval-mlogloss:0.251609\n",
      "[218]\ttrain-mlogloss:0.24928\teval-mlogloss:0.250502\n",
      "[219]\ttrain-mlogloss:0.248181\teval-mlogloss:0.249406\n",
      "[220]\ttrain-mlogloss:0.247093\teval-mlogloss:0.248323\n",
      "[221]\ttrain-mlogloss:0.246017\teval-mlogloss:0.247251\n",
      "[222]\ttrain-mlogloss:0.244952\teval-mlogloss:0.246191\n",
      "[223]\ttrain-mlogloss:0.243899\teval-mlogloss:0.245143\n",
      "[224]\ttrain-mlogloss:0.242856\teval-mlogloss:0.244105\n",
      "[225]\ttrain-mlogloss:0.241824\teval-mlogloss:0.243079\n",
      "[226]\ttrain-mlogloss:0.240803\teval-mlogloss:0.242062\n",
      "[227]\ttrain-mlogloss:0.239793\teval-mlogloss:0.241056\n",
      "[228]\ttrain-mlogloss:0.238792\teval-mlogloss:0.24006\n",
      "[229]\ttrain-mlogloss:0.237802\teval-mlogloss:0.239076\n",
      "[230]\ttrain-mlogloss:0.236822\teval-mlogloss:0.238102\n",
      "[231]\ttrain-mlogloss:0.235852\teval-mlogloss:0.237139\n",
      "[232]\ttrain-mlogloss:0.234892\teval-mlogloss:0.236186\n",
      "[233]\ttrain-mlogloss:0.233942\teval-mlogloss:0.235244\n",
      "[234]\ttrain-mlogloss:0.233002\teval-mlogloss:0.234311\n",
      "[235]\ttrain-mlogloss:0.232071\teval-mlogloss:0.233388\n",
      "[236]\ttrain-mlogloss:0.231151\teval-mlogloss:0.232474\n",
      "[237]\ttrain-mlogloss:0.230239\teval-mlogloss:0.23157\n",
      "[238]\ttrain-mlogloss:0.229337\teval-mlogloss:0.230676\n",
      "[239]\ttrain-mlogloss:0.228445\teval-mlogloss:0.22979\n",
      "[240]\ttrain-mlogloss:0.227561\teval-mlogloss:0.228912\n",
      "[241]\ttrain-mlogloss:0.226687\teval-mlogloss:0.22804\n",
      "[242]\ttrain-mlogloss:0.225821\teval-mlogloss:0.227178\n",
      "[243]\ttrain-mlogloss:0.224965\teval-mlogloss:0.226324\n",
      "[244]\ttrain-mlogloss:0.224118\teval-mlogloss:0.225478\n",
      "[245]\ttrain-mlogloss:0.223279\teval-mlogloss:0.224644\n",
      "[246]\ttrain-mlogloss:0.222449\teval-mlogloss:0.223819\n",
      "[247]\ttrain-mlogloss:0.221628\teval-mlogloss:0.223001\n",
      "[248]\ttrain-mlogloss:0.220815\teval-mlogloss:0.222192\n",
      "[249]\ttrain-mlogloss:0.22001\teval-mlogloss:0.22139\n",
      "[250]\ttrain-mlogloss:0.219214\teval-mlogloss:0.220598\n",
      "[251]\ttrain-mlogloss:0.218426\teval-mlogloss:0.219814\n",
      "[252]\ttrain-mlogloss:0.217646\teval-mlogloss:0.219038\n",
      "[253]\ttrain-mlogloss:0.216874\teval-mlogloss:0.21827\n",
      "[254]\ttrain-mlogloss:0.216109\teval-mlogloss:0.217512\n",
      "[255]\ttrain-mlogloss:0.215353\teval-mlogloss:0.216762\n",
      "[256]\ttrain-mlogloss:0.214604\teval-mlogloss:0.216019\n",
      "[257]\ttrain-mlogloss:0.213863\teval-mlogloss:0.215285\n",
      "[258]\ttrain-mlogloss:0.213129\teval-mlogloss:0.214558\n",
      "[259]\ttrain-mlogloss:0.212402\teval-mlogloss:0.213837\n",
      "[260]\ttrain-mlogloss:0.211683\teval-mlogloss:0.213125\n",
      "[261]\ttrain-mlogloss:0.210971\teval-mlogloss:0.21242\n",
      "[262]\ttrain-mlogloss:0.210265\teval-mlogloss:0.211719\n",
      "[263]\ttrain-mlogloss:0.209567\teval-mlogloss:0.211028\n",
      "[264]\ttrain-mlogloss:0.208876\teval-mlogloss:0.210347\n",
      "[265]\ttrain-mlogloss:0.208192\teval-mlogloss:0.209671\n",
      "[266]\ttrain-mlogloss:0.207514\teval-mlogloss:0.209003\n",
      "[267]\ttrain-mlogloss:0.206844\teval-mlogloss:0.208342\n",
      "[268]\ttrain-mlogloss:0.20618\teval-mlogloss:0.207687\n",
      "[269]\ttrain-mlogloss:0.205522\teval-mlogloss:0.207037\n",
      "[270]\ttrain-mlogloss:0.204872\teval-mlogloss:0.206391\n",
      "[271]\ttrain-mlogloss:0.204229\teval-mlogloss:0.20575\n",
      "[272]\ttrain-mlogloss:0.203592\teval-mlogloss:0.205116\n",
      "[273]\ttrain-mlogloss:0.202962\teval-mlogloss:0.204488\n",
      "[274]\ttrain-mlogloss:0.202338\teval-mlogloss:0.203867\n",
      "[275]\ttrain-mlogloss:0.201721\teval-mlogloss:0.203252\n",
      "[276]\ttrain-mlogloss:0.20111\teval-mlogloss:0.202646\n",
      "[277]\ttrain-mlogloss:0.200505\teval-mlogloss:0.202047\n",
      "[278]\ttrain-mlogloss:0.199906\teval-mlogloss:0.201453\n",
      "[279]\ttrain-mlogloss:0.199313\teval-mlogloss:0.200866\n",
      "[280]\ttrain-mlogloss:0.198726\teval-mlogloss:0.200284\n",
      "[281]\ttrain-mlogloss:0.198145\teval-mlogloss:0.199707\n",
      "[282]\ttrain-mlogloss:0.19757\teval-mlogloss:0.199134\n",
      "[283]\ttrain-mlogloss:0.197001\teval-mlogloss:0.198571\n",
      "[284]\ttrain-mlogloss:0.196437\teval-mlogloss:0.198012\n",
      "[285]\ttrain-mlogloss:0.195879\teval-mlogloss:0.197457\n",
      "[286]\ttrain-mlogloss:0.195327\teval-mlogloss:0.196908\n",
      "[287]\ttrain-mlogloss:0.19478\teval-mlogloss:0.196368\n",
      "[288]\ttrain-mlogloss:0.194238\teval-mlogloss:0.195832\n",
      "[289]\ttrain-mlogloss:0.193702\teval-mlogloss:0.195302\n",
      "[290]\ttrain-mlogloss:0.193171\teval-mlogloss:0.194776\n",
      "[291]\ttrain-mlogloss:0.192646\teval-mlogloss:0.194257\n",
      "[292]\ttrain-mlogloss:0.192125\teval-mlogloss:0.193744\n",
      "[293]\ttrain-mlogloss:0.19161\teval-mlogloss:0.193234\n",
      "[294]\ttrain-mlogloss:0.1911\teval-mlogloss:0.192727\n",
      "[295]\ttrain-mlogloss:0.190594\teval-mlogloss:0.192225\n",
      "[296]\ttrain-mlogloss:0.190094\teval-mlogloss:0.191732\n",
      "[297]\ttrain-mlogloss:0.189599\teval-mlogloss:0.19124\n",
      "[298]\ttrain-mlogloss:0.189108\teval-mlogloss:0.190752\n",
      "[299]\ttrain-mlogloss:0.188622\teval-mlogloss:0.19027\n",
      "[300]\ttrain-mlogloss:0.188141\teval-mlogloss:0.189791\n",
      "[301]\ttrain-mlogloss:0.187664\teval-mlogloss:0.18932\n",
      "[302]\ttrain-mlogloss:0.187192\teval-mlogloss:0.188853\n",
      "[303]\ttrain-mlogloss:0.186725\teval-mlogloss:0.188389\n",
      "[304]\ttrain-mlogloss:0.186262\teval-mlogloss:0.187933\n",
      "[305]\ttrain-mlogloss:0.185804\teval-mlogloss:0.187477\n",
      "[306]\ttrain-mlogloss:0.18535\teval-mlogloss:0.18703\n",
      "[307]\ttrain-mlogloss:0.184901\teval-mlogloss:0.186587\n",
      "[308]\ttrain-mlogloss:0.184456\teval-mlogloss:0.186146\n",
      "[309]\ttrain-mlogloss:0.184015\teval-mlogloss:0.185711\n",
      "[310]\ttrain-mlogloss:0.183579\teval-mlogloss:0.185279\n",
      "[311]\ttrain-mlogloss:0.183147\teval-mlogloss:0.184852\n",
      "[312]\ttrain-mlogloss:0.182719\teval-mlogloss:0.184431\n",
      "[313]\ttrain-mlogloss:0.182296\teval-mlogloss:0.184009\n",
      "[314]\ttrain-mlogloss:0.181876\teval-mlogloss:0.183597\n",
      "[315]\ttrain-mlogloss:0.181461\teval-mlogloss:0.183189\n",
      "[316]\ttrain-mlogloss:0.181049\teval-mlogloss:0.182787\n",
      "[317]\ttrain-mlogloss:0.180642\teval-mlogloss:0.182388\n",
      "[318]\ttrain-mlogloss:0.180238\teval-mlogloss:0.18199\n",
      "[319]\ttrain-mlogloss:0.179838\teval-mlogloss:0.1816\n",
      "[320]\ttrain-mlogloss:0.179443\teval-mlogloss:0.181212\n",
      "[321]\ttrain-mlogloss:0.179051\teval-mlogloss:0.180826\n",
      "[322]\ttrain-mlogloss:0.178663\teval-mlogloss:0.180446\n",
      "[323]\ttrain-mlogloss:0.178279\teval-mlogloss:0.180073\n",
      "[324]\ttrain-mlogloss:0.177898\teval-mlogloss:0.179697\n",
      "[325]\ttrain-mlogloss:0.177521\teval-mlogloss:0.179331\n",
      "[326]\ttrain-mlogloss:0.177148\teval-mlogloss:0.178965\n",
      "[327]\ttrain-mlogloss:0.176778\teval-mlogloss:0.178606\n",
      "[328]\ttrain-mlogloss:0.176412\teval-mlogloss:0.178247\n",
      "[329]\ttrain-mlogloss:0.17605\teval-mlogloss:0.177892\n",
      "[330]\ttrain-mlogloss:0.17569\teval-mlogloss:0.177543\n",
      "[331]\ttrain-mlogloss:0.175335\teval-mlogloss:0.177195\n",
      "[332]\ttrain-mlogloss:0.174982\teval-mlogloss:0.176854\n",
      "[333]\ttrain-mlogloss:0.174634\teval-mlogloss:0.176511\n",
      "[334]\ttrain-mlogloss:0.174288\teval-mlogloss:0.176173\n",
      "[335]\ttrain-mlogloss:0.173946\teval-mlogloss:0.175842\n",
      "[336]\ttrain-mlogloss:0.173607\teval-mlogloss:0.175509\n",
      "[337]\ttrain-mlogloss:0.173271\teval-mlogloss:0.17518\n",
      "[338]\ttrain-mlogloss:0.172939\teval-mlogloss:0.174854\n",
      "[339]\ttrain-mlogloss:0.17261\teval-mlogloss:0.174532\n",
      "[340]\ttrain-mlogloss:0.172284\teval-mlogloss:0.174211\n",
      "[341]\ttrain-mlogloss:0.171961\teval-mlogloss:0.173895\n",
      "[342]\ttrain-mlogloss:0.171642\teval-mlogloss:0.173579\n",
      "[343]\ttrain-mlogloss:0.171325\teval-mlogloss:0.173269\n",
      "[344]\ttrain-mlogloss:0.171012\teval-mlogloss:0.172963\n",
      "[345]\ttrain-mlogloss:0.170703\teval-mlogloss:0.172663\n",
      "[346]\ttrain-mlogloss:0.170395\teval-mlogloss:0.172364\n",
      "[347]\ttrain-mlogloss:0.17009\teval-mlogloss:0.172069\n",
      "[348]\ttrain-mlogloss:0.169789\teval-mlogloss:0.171776\n",
      "[349]\ttrain-mlogloss:0.16949\teval-mlogloss:0.171487\n",
      "[350]\ttrain-mlogloss:0.169194\teval-mlogloss:0.171201\n",
      "[351]\ttrain-mlogloss:0.1689\teval-mlogloss:0.170918\n",
      "[352]\ttrain-mlogloss:0.16861\teval-mlogloss:0.170638\n",
      "[353]\ttrain-mlogloss:0.168322\teval-mlogloss:0.170362\n",
      "[354]\ttrain-mlogloss:0.168038\teval-mlogloss:0.170088\n",
      "[355]\ttrain-mlogloss:0.167756\teval-mlogloss:0.169818\n",
      "[356]\ttrain-mlogloss:0.167476\teval-mlogloss:0.169548\n",
      "[357]\ttrain-mlogloss:0.167199\teval-mlogloss:0.169284\n",
      "[358]\ttrain-mlogloss:0.166925\teval-mlogloss:0.169019\n",
      "[359]\ttrain-mlogloss:0.166653\teval-mlogloss:0.168759\n",
      "[360]\ttrain-mlogloss:0.166385\teval-mlogloss:0.168499\n",
      "[361]\ttrain-mlogloss:0.166118\teval-mlogloss:0.168241\n",
      "[362]\ttrain-mlogloss:0.165854\teval-mlogloss:0.167987\n",
      "[363]\ttrain-mlogloss:0.165593\teval-mlogloss:0.167733\n",
      "[364]\ttrain-mlogloss:0.165333\teval-mlogloss:0.167486\n",
      "[365]\ttrain-mlogloss:0.165076\teval-mlogloss:0.16724\n",
      "[366]\ttrain-mlogloss:0.164821\teval-mlogloss:0.166995\n",
      "[367]\ttrain-mlogloss:0.164568\teval-mlogloss:0.166753\n",
      "[368]\ttrain-mlogloss:0.164317\teval-mlogloss:0.166515\n",
      "[369]\ttrain-mlogloss:0.16407\teval-mlogloss:0.166276\n",
      "[370]\ttrain-mlogloss:0.163823\teval-mlogloss:0.166042\n",
      "[371]\ttrain-mlogloss:0.16358\teval-mlogloss:0.16581\n",
      "[372]\ttrain-mlogloss:0.163339\teval-mlogloss:0.165578\n",
      "[373]\ttrain-mlogloss:0.163099\teval-mlogloss:0.165351\n",
      "[374]\ttrain-mlogloss:0.162863\teval-mlogloss:0.165126\n",
      "[375]\ttrain-mlogloss:0.162627\teval-mlogloss:0.164902\n",
      "[376]\ttrain-mlogloss:0.162394\teval-mlogloss:0.164679\n",
      "[377]\ttrain-mlogloss:0.162164\teval-mlogloss:0.164457\n",
      "[378]\ttrain-mlogloss:0.161935\teval-mlogloss:0.164239\n",
      "[379]\ttrain-mlogloss:0.161709\teval-mlogloss:0.164023\n",
      "[380]\ttrain-mlogloss:0.161484\teval-mlogloss:0.163809\n",
      "[381]\ttrain-mlogloss:0.161261\teval-mlogloss:0.163596\n",
      "[382]\ttrain-mlogloss:0.161041\teval-mlogloss:0.163385\n",
      "[383]\ttrain-mlogloss:0.160822\teval-mlogloss:0.163177\n",
      "[384]\ttrain-mlogloss:0.160606\teval-mlogloss:0.16297\n",
      "[385]\ttrain-mlogloss:0.160391\teval-mlogloss:0.162766\n",
      "[386]\ttrain-mlogloss:0.160179\teval-mlogloss:0.162564\n",
      "[387]\ttrain-mlogloss:0.159968\teval-mlogloss:0.162362\n",
      "[388]\ttrain-mlogloss:0.159759\teval-mlogloss:0.162164\n",
      "[389]\ttrain-mlogloss:0.159553\teval-mlogloss:0.161967\n",
      "[390]\ttrain-mlogloss:0.159349\teval-mlogloss:0.161772\n",
      "[391]\ttrain-mlogloss:0.159147\teval-mlogloss:0.161579\n",
      "[392]\ttrain-mlogloss:0.158948\teval-mlogloss:0.161387\n",
      "[393]\ttrain-mlogloss:0.15875\teval-mlogloss:0.161198\n",
      "[394]\ttrain-mlogloss:0.158553\teval-mlogloss:0.16101\n",
      "[395]\ttrain-mlogloss:0.158359\teval-mlogloss:0.160825\n",
      "[396]\ttrain-mlogloss:0.158166\teval-mlogloss:0.160639\n",
      "[397]\ttrain-mlogloss:0.157976\teval-mlogloss:0.160458\n",
      "[398]\ttrain-mlogloss:0.157787\teval-mlogloss:0.160277\n",
      "[399]\ttrain-mlogloss:0.157599\teval-mlogloss:0.160098\n",
      "[400]\ttrain-mlogloss:0.157414\teval-mlogloss:0.159922\n",
      "[401]\ttrain-mlogloss:0.15723\teval-mlogloss:0.159748\n",
      "[402]\ttrain-mlogloss:0.157048\teval-mlogloss:0.159578\n",
      "[403]\ttrain-mlogloss:0.156867\teval-mlogloss:0.159408\n",
      "[404]\ttrain-mlogloss:0.156688\teval-mlogloss:0.159238\n",
      "[405]\ttrain-mlogloss:0.156511\teval-mlogloss:0.159073\n",
      "[406]\ttrain-mlogloss:0.156335\teval-mlogloss:0.158909\n",
      "[407]\ttrain-mlogloss:0.156162\teval-mlogloss:0.158743\n",
      "[408]\ttrain-mlogloss:0.155989\teval-mlogloss:0.158584\n",
      "[409]\ttrain-mlogloss:0.155819\teval-mlogloss:0.158424\n",
      "[410]\ttrain-mlogloss:0.15565\teval-mlogloss:0.158265\n",
      "[411]\ttrain-mlogloss:0.155482\teval-mlogloss:0.158109\n",
      "[412]\ttrain-mlogloss:0.155315\teval-mlogloss:0.157954\n",
      "[413]\ttrain-mlogloss:0.15515\teval-mlogloss:0.157799\n",
      "[414]\ttrain-mlogloss:0.154986\teval-mlogloss:0.157645\n",
      "[415]\ttrain-mlogloss:0.154823\teval-mlogloss:0.157493\n",
      "[416]\ttrain-mlogloss:0.154662\teval-mlogloss:0.157344\n",
      "[417]\ttrain-mlogloss:0.154502\teval-mlogloss:0.157195\n",
      "[418]\ttrain-mlogloss:0.154344\teval-mlogloss:0.157045\n",
      "[419]\ttrain-mlogloss:0.154187\teval-mlogloss:0.156899\n",
      "[420]\ttrain-mlogloss:0.154032\teval-mlogloss:0.156755\n",
      "[421]\ttrain-mlogloss:0.153878\teval-mlogloss:0.156612\n",
      "[422]\ttrain-mlogloss:0.153725\teval-mlogloss:0.156469\n",
      "[423]\ttrain-mlogloss:0.153573\teval-mlogloss:0.156332\n",
      "[424]\ttrain-mlogloss:0.153423\teval-mlogloss:0.156191\n",
      "[425]\ttrain-mlogloss:0.153275\teval-mlogloss:0.156055\n",
      "[426]\ttrain-mlogloss:0.153127\teval-mlogloss:0.155921\n",
      "[427]\ttrain-mlogloss:0.15298\teval-mlogloss:0.155783\n",
      "[428]\ttrain-mlogloss:0.152835\teval-mlogloss:0.15565\n",
      "[429]\ttrain-mlogloss:0.152691\teval-mlogloss:0.155518\n",
      "[430]\ttrain-mlogloss:0.152549\teval-mlogloss:0.155386\n",
      "[431]\ttrain-mlogloss:0.152408\teval-mlogloss:0.155257\n",
      "[432]\ttrain-mlogloss:0.152267\teval-mlogloss:0.155127\n",
      "[433]\ttrain-mlogloss:0.152128\teval-mlogloss:0.155001\n",
      "[434]\ttrain-mlogloss:0.15199\teval-mlogloss:0.154874\n",
      "[435]\ttrain-mlogloss:0.151854\teval-mlogloss:0.154749\n",
      "[436]\ttrain-mlogloss:0.151718\teval-mlogloss:0.154625\n",
      "[437]\ttrain-mlogloss:0.151584\teval-mlogloss:0.154501\n",
      "[438]\ttrain-mlogloss:0.151451\teval-mlogloss:0.154379\n",
      "[439]\ttrain-mlogloss:0.151319\teval-mlogloss:0.15426\n",
      "[440]\ttrain-mlogloss:0.151187\teval-mlogloss:0.15414\n",
      "[441]\ttrain-mlogloss:0.151056\teval-mlogloss:0.154021\n",
      "[442]\ttrain-mlogloss:0.150926\teval-mlogloss:0.153906\n",
      "[443]\ttrain-mlogloss:0.150798\teval-mlogloss:0.153792\n",
      "[444]\ttrain-mlogloss:0.150671\teval-mlogloss:0.153676\n",
      "[445]\ttrain-mlogloss:0.150543\teval-mlogloss:0.153563\n",
      "[446]\ttrain-mlogloss:0.150418\teval-mlogloss:0.153455\n",
      "[447]\ttrain-mlogloss:0.150294\teval-mlogloss:0.15334\n",
      "[448]\ttrain-mlogloss:0.150171\teval-mlogloss:0.153229\n",
      "[449]\ttrain-mlogloss:0.15005\teval-mlogloss:0.15312\n",
      "[450]\ttrain-mlogloss:0.149931\teval-mlogloss:0.153011\n",
      "[451]\ttrain-mlogloss:0.149811\teval-mlogloss:0.152899\n",
      "[452]\ttrain-mlogloss:0.149693\teval-mlogloss:0.152795\n",
      "[453]\ttrain-mlogloss:0.149577\teval-mlogloss:0.15269\n",
      "[454]\ttrain-mlogloss:0.14946\teval-mlogloss:0.152582\n",
      "[455]\ttrain-mlogloss:0.149345\teval-mlogloss:0.15248\n",
      "[456]\ttrain-mlogloss:0.14923\teval-mlogloss:0.152378\n",
      "[457]\ttrain-mlogloss:0.149118\teval-mlogloss:0.152276\n",
      "[458]\ttrain-mlogloss:0.149004\teval-mlogloss:0.152172\n",
      "[459]\ttrain-mlogloss:0.148893\teval-mlogloss:0.152071\n",
      "[460]\ttrain-mlogloss:0.148782\teval-mlogloss:0.15197\n",
      "[461]\ttrain-mlogloss:0.148673\teval-mlogloss:0.151873\n",
      "[462]\ttrain-mlogloss:0.148565\teval-mlogloss:0.151778\n",
      "[463]\ttrain-mlogloss:0.148457\teval-mlogloss:0.15168\n",
      "[464]\ttrain-mlogloss:0.148349\teval-mlogloss:0.151583\n",
      "[465]\ttrain-mlogloss:0.148243\teval-mlogloss:0.151487\n",
      "[466]\ttrain-mlogloss:0.148139\teval-mlogloss:0.151392\n",
      "[467]\ttrain-mlogloss:0.148035\teval-mlogloss:0.151299\n",
      "[468]\ttrain-mlogloss:0.147931\teval-mlogloss:0.151204\n",
      "[469]\ttrain-mlogloss:0.147828\teval-mlogloss:0.151112\n",
      "[470]\ttrain-mlogloss:0.147727\teval-mlogloss:0.151021\n",
      "[471]\ttrain-mlogloss:0.147626\teval-mlogloss:0.150933\n",
      "[472]\ttrain-mlogloss:0.147526\teval-mlogloss:0.150845\n",
      "[473]\ttrain-mlogloss:0.147425\teval-mlogloss:0.150756\n",
      "[474]\ttrain-mlogloss:0.147327\teval-mlogloss:0.150668\n",
      "[475]\ttrain-mlogloss:0.147228\teval-mlogloss:0.150584\n",
      "[476]\ttrain-mlogloss:0.147131\teval-mlogloss:0.150496\n",
      "[477]\ttrain-mlogloss:0.147033\teval-mlogloss:0.15041\n",
      "[478]\ttrain-mlogloss:0.146937\teval-mlogloss:0.15033\n",
      "[479]\ttrain-mlogloss:0.146842\teval-mlogloss:0.150244\n",
      "[480]\ttrain-mlogloss:0.146747\teval-mlogloss:0.150161\n",
      "[481]\ttrain-mlogloss:0.146653\teval-mlogloss:0.150084\n",
      "[482]\ttrain-mlogloss:0.146561\teval-mlogloss:0.149999\n",
      "[483]\ttrain-mlogloss:0.146469\teval-mlogloss:0.149922\n",
      "[484]\ttrain-mlogloss:0.146377\teval-mlogloss:0.14984\n",
      "[485]\ttrain-mlogloss:0.146287\teval-mlogloss:0.149765\n",
      "[486]\ttrain-mlogloss:0.146197\teval-mlogloss:0.149685\n",
      "[487]\ttrain-mlogloss:0.146107\teval-mlogloss:0.149607\n",
      "[488]\ttrain-mlogloss:0.146019\teval-mlogloss:0.14953\n",
      "[489]\ttrain-mlogloss:0.14593\teval-mlogloss:0.149455\n",
      "[490]\ttrain-mlogloss:0.145844\teval-mlogloss:0.149381\n",
      "[491]\ttrain-mlogloss:0.145755\teval-mlogloss:0.149306\n",
      "[492]\ttrain-mlogloss:0.145669\teval-mlogloss:0.14923\n",
      "[493]\ttrain-mlogloss:0.14558\teval-mlogloss:0.149159\n",
      "[494]\ttrain-mlogloss:0.145497\teval-mlogloss:0.149086\n",
      "[495]\ttrain-mlogloss:0.145411\teval-mlogloss:0.149016\n",
      "[496]\ttrain-mlogloss:0.145327\teval-mlogloss:0.148946\n",
      "[497]\ttrain-mlogloss:0.145244\teval-mlogloss:0.148873\n",
      "[498]\ttrain-mlogloss:0.145161\teval-mlogloss:0.148805\n",
      "[499]\ttrain-mlogloss:0.14508\teval-mlogloss:0.148737\n",
      "[500]\ttrain-mlogloss:0.144997\teval-mlogloss:0.148666\n",
      "[501]\ttrain-mlogloss:0.144918\teval-mlogloss:0.148598\n",
      "[502]\ttrain-mlogloss:0.144837\teval-mlogloss:0.148533\n",
      "[503]\ttrain-mlogloss:0.144756\teval-mlogloss:0.148464\n",
      "[504]\ttrain-mlogloss:0.144677\teval-mlogloss:0.1484\n",
      "[505]\ttrain-mlogloss:0.1446\teval-mlogloss:0.148333\n",
      "[506]\ttrain-mlogloss:0.144524\teval-mlogloss:0.148269\n",
      "[507]\ttrain-mlogloss:0.144447\teval-mlogloss:0.148205\n",
      "[508]\ttrain-mlogloss:0.144372\teval-mlogloss:0.148142\n",
      "[509]\ttrain-mlogloss:0.144297\teval-mlogloss:0.148077\n",
      "[510]\ttrain-mlogloss:0.144223\teval-mlogloss:0.148017\n",
      "[511]\ttrain-mlogloss:0.144148\teval-mlogloss:0.147954\n",
      "[512]\ttrain-mlogloss:0.144074\teval-mlogloss:0.147891\n",
      "[513]\ttrain-mlogloss:0.144003\teval-mlogloss:0.147833\n",
      "[514]\ttrain-mlogloss:0.143929\teval-mlogloss:0.147771\n",
      "[515]\ttrain-mlogloss:0.143857\teval-mlogloss:0.14771\n",
      "[516]\ttrain-mlogloss:0.143788\teval-mlogloss:0.147653\n",
      "[517]\ttrain-mlogloss:0.143715\teval-mlogloss:0.147593\n",
      "[518]\ttrain-mlogloss:0.143647\teval-mlogloss:0.147538\n",
      "[519]\ttrain-mlogloss:0.143577\teval-mlogloss:0.14748\n",
      "[520]\ttrain-mlogloss:0.143507\teval-mlogloss:0.147422\n",
      "[521]\ttrain-mlogloss:0.143439\teval-mlogloss:0.147368\n",
      "[522]\ttrain-mlogloss:0.143372\teval-mlogloss:0.147311\n",
      "[523]\ttrain-mlogloss:0.143303\teval-mlogloss:0.147255\n",
      "[524]\ttrain-mlogloss:0.143237\teval-mlogloss:0.147203\n",
      "[525]\ttrain-mlogloss:0.143169\teval-mlogloss:0.147149\n",
      "[526]\ttrain-mlogloss:0.143104\teval-mlogloss:0.147096\n",
      "[527]\ttrain-mlogloss:0.143037\teval-mlogloss:0.147042\n",
      "[528]\ttrain-mlogloss:0.142973\teval-mlogloss:0.146993\n",
      "[529]\ttrain-mlogloss:0.142908\teval-mlogloss:0.146942\n",
      "[530]\ttrain-mlogloss:0.142844\teval-mlogloss:0.146891\n",
      "[531]\ttrain-mlogloss:0.14278\teval-mlogloss:0.14684\n",
      "[532]\ttrain-mlogloss:0.142717\teval-mlogloss:0.14679\n",
      "[533]\ttrain-mlogloss:0.142656\teval-mlogloss:0.146738\n",
      "[534]\ttrain-mlogloss:0.142591\teval-mlogloss:0.146688\n",
      "[535]\ttrain-mlogloss:0.14253\teval-mlogloss:0.146637\n",
      "[536]\ttrain-mlogloss:0.142469\teval-mlogloss:0.14659\n",
      "[537]\ttrain-mlogloss:0.142408\teval-mlogloss:0.146539\n",
      "[538]\ttrain-mlogloss:0.142347\teval-mlogloss:0.146491\n",
      "[539]\ttrain-mlogloss:0.142287\teval-mlogloss:0.146442\n",
      "[540]\ttrain-mlogloss:0.142228\teval-mlogloss:0.146397\n",
      "[541]\ttrain-mlogloss:0.142169\teval-mlogloss:0.146349\n",
      "[542]\ttrain-mlogloss:0.142111\teval-mlogloss:0.146302\n",
      "[543]\ttrain-mlogloss:0.142054\teval-mlogloss:0.146258\n",
      "[544]\ttrain-mlogloss:0.141996\teval-mlogloss:0.146211\n",
      "[545]\ttrain-mlogloss:0.141939\teval-mlogloss:0.146164\n",
      "[546]\ttrain-mlogloss:0.141883\teval-mlogloss:0.146119\n",
      "[547]\ttrain-mlogloss:0.141828\teval-mlogloss:0.146074\n",
      "[548]\ttrain-mlogloss:0.141773\teval-mlogloss:0.146031\n",
      "[549]\ttrain-mlogloss:0.14172\teval-mlogloss:0.145986\n",
      "[550]\ttrain-mlogloss:0.141668\teval-mlogloss:0.145944\n",
      "[551]\ttrain-mlogloss:0.141615\teval-mlogloss:0.1459\n",
      "[552]\ttrain-mlogloss:0.141562\teval-mlogloss:0.145859\n",
      "[553]\ttrain-mlogloss:0.141509\teval-mlogloss:0.145817\n",
      "[554]\ttrain-mlogloss:0.141459\teval-mlogloss:0.145778\n",
      "[555]\ttrain-mlogloss:0.141407\teval-mlogloss:0.145736\n",
      "[556]\ttrain-mlogloss:0.141356\teval-mlogloss:0.145694\n",
      "[557]\ttrain-mlogloss:0.141304\teval-mlogloss:0.145654\n",
      "[558]\ttrain-mlogloss:0.141253\teval-mlogloss:0.145616\n",
      "[559]\ttrain-mlogloss:0.141203\teval-mlogloss:0.145575\n",
      "[560]\ttrain-mlogloss:0.141153\teval-mlogloss:0.145538\n",
      "[561]\ttrain-mlogloss:0.141102\teval-mlogloss:0.145497\n",
      "[562]\ttrain-mlogloss:0.141052\teval-mlogloss:0.145458\n",
      "[563]\ttrain-mlogloss:0.141004\teval-mlogloss:0.145419\n",
      "[564]\ttrain-mlogloss:0.140955\teval-mlogloss:0.145381\n",
      "[565]\ttrain-mlogloss:0.140907\teval-mlogloss:0.145344\n",
      "[566]\ttrain-mlogloss:0.140859\teval-mlogloss:0.145306\n",
      "[567]\ttrain-mlogloss:0.14081\teval-mlogloss:0.145269\n",
      "[568]\ttrain-mlogloss:0.140763\teval-mlogloss:0.145232\n",
      "[569]\ttrain-mlogloss:0.140716\teval-mlogloss:0.145195\n",
      "[570]\ttrain-mlogloss:0.14067\teval-mlogloss:0.145162\n",
      "[571]\ttrain-mlogloss:0.140622\teval-mlogloss:0.145123\n",
      "[572]\ttrain-mlogloss:0.140577\teval-mlogloss:0.145091\n",
      "[573]\ttrain-mlogloss:0.140529\teval-mlogloss:0.145053\n",
      "[574]\ttrain-mlogloss:0.140483\teval-mlogloss:0.145018\n",
      "[575]\ttrain-mlogloss:0.140437\teval-mlogloss:0.144983\n",
      "[576]\ttrain-mlogloss:0.140391\teval-mlogloss:0.144948\n",
      "[577]\ttrain-mlogloss:0.140343\teval-mlogloss:0.144911\n",
      "[578]\ttrain-mlogloss:0.140298\teval-mlogloss:0.144881\n",
      "[579]\ttrain-mlogloss:0.140252\teval-mlogloss:0.144845\n",
      "[580]\ttrain-mlogloss:0.140206\teval-mlogloss:0.144813\n",
      "[581]\ttrain-mlogloss:0.14016\teval-mlogloss:0.14478\n",
      "[582]\ttrain-mlogloss:0.140116\teval-mlogloss:0.144747\n",
      "[583]\ttrain-mlogloss:0.140071\teval-mlogloss:0.144712\n",
      "[584]\ttrain-mlogloss:0.140028\teval-mlogloss:0.144682\n",
      "[585]\ttrain-mlogloss:0.139984\teval-mlogloss:0.14465\n",
      "[586]\ttrain-mlogloss:0.13994\teval-mlogloss:0.144619\n",
      "[587]\ttrain-mlogloss:0.139895\teval-mlogloss:0.144587\n",
      "[588]\ttrain-mlogloss:0.13985\teval-mlogloss:0.144556\n",
      "[589]\ttrain-mlogloss:0.139806\teval-mlogloss:0.144525\n",
      "[590]\ttrain-mlogloss:0.139763\teval-mlogloss:0.144492\n",
      "[591]\ttrain-mlogloss:0.139719\teval-mlogloss:0.14446\n",
      "[592]\ttrain-mlogloss:0.139678\teval-mlogloss:0.144431\n",
      "[593]\ttrain-mlogloss:0.139635\teval-mlogloss:0.144401\n",
      "[594]\ttrain-mlogloss:0.139593\teval-mlogloss:0.144371\n",
      "[595]\ttrain-mlogloss:0.13955\teval-mlogloss:0.144343\n",
      "[596]\ttrain-mlogloss:0.139511\teval-mlogloss:0.144314\n",
      "[597]\ttrain-mlogloss:0.139469\teval-mlogloss:0.144284\n",
      "[598]\ttrain-mlogloss:0.139427\teval-mlogloss:0.144257\n",
      "[599]\ttrain-mlogloss:0.139387\teval-mlogloss:0.144231\n",
      "[600]\ttrain-mlogloss:0.139347\teval-mlogloss:0.144203\n",
      "[601]\ttrain-mlogloss:0.139308\teval-mlogloss:0.144175\n",
      "[602]\ttrain-mlogloss:0.13927\teval-mlogloss:0.14415\n",
      "[603]\ttrain-mlogloss:0.139229\teval-mlogloss:0.144124\n",
      "[604]\ttrain-mlogloss:0.139188\teval-mlogloss:0.144096\n",
      "[605]\ttrain-mlogloss:0.139148\teval-mlogloss:0.14407\n",
      "[606]\ttrain-mlogloss:0.13911\teval-mlogloss:0.144045\n",
      "[607]\ttrain-mlogloss:0.13907\teval-mlogloss:0.144019\n",
      "[608]\ttrain-mlogloss:0.139031\teval-mlogloss:0.143991\n",
      "[609]\ttrain-mlogloss:0.138993\teval-mlogloss:0.143967\n",
      "[610]\ttrain-mlogloss:0.138953\teval-mlogloss:0.143944\n",
      "[611]\ttrain-mlogloss:0.138916\teval-mlogloss:0.143919\n",
      "[612]\ttrain-mlogloss:0.138879\teval-mlogloss:0.143897\n",
      "[613]\ttrain-mlogloss:0.13884\teval-mlogloss:0.14387\n",
      "[614]\ttrain-mlogloss:0.138802\teval-mlogloss:0.143848\n",
      "[615]\ttrain-mlogloss:0.138767\teval-mlogloss:0.143824\n",
      "[616]\ttrain-mlogloss:0.138731\teval-mlogloss:0.143801\n",
      "[617]\ttrain-mlogloss:0.138693\teval-mlogloss:0.143776\n",
      "[618]\ttrain-mlogloss:0.138656\teval-mlogloss:0.143754\n",
      "[619]\ttrain-mlogloss:0.138621\teval-mlogloss:0.143731\n",
      "[620]\ttrain-mlogloss:0.138586\teval-mlogloss:0.14371\n",
      "[621]\ttrain-mlogloss:0.138552\teval-mlogloss:0.143686\n",
      "[622]\ttrain-mlogloss:0.138516\teval-mlogloss:0.143663\n",
      "[623]\ttrain-mlogloss:0.138481\teval-mlogloss:0.143641\n",
      "[624]\ttrain-mlogloss:0.138446\teval-mlogloss:0.143622\n",
      "[625]\ttrain-mlogloss:0.138411\teval-mlogloss:0.143599\n",
      "[626]\ttrain-mlogloss:0.138377\teval-mlogloss:0.143577\n",
      "[627]\ttrain-mlogloss:0.138342\teval-mlogloss:0.143555\n",
      "[628]\ttrain-mlogloss:0.13831\teval-mlogloss:0.143532\n",
      "[629]\ttrain-mlogloss:0.138276\teval-mlogloss:0.143511\n",
      "[630]\ttrain-mlogloss:0.13824\teval-mlogloss:0.143488\n",
      "[631]\ttrain-mlogloss:0.138208\teval-mlogloss:0.143468\n",
      "[632]\ttrain-mlogloss:0.138175\teval-mlogloss:0.143449\n",
      "[633]\ttrain-mlogloss:0.138143\teval-mlogloss:0.143427\n",
      "[634]\ttrain-mlogloss:0.138108\teval-mlogloss:0.143404\n",
      "[635]\ttrain-mlogloss:0.138075\teval-mlogloss:0.143387\n",
      "[636]\ttrain-mlogloss:0.138042\teval-mlogloss:0.143367\n",
      "[637]\ttrain-mlogloss:0.138011\teval-mlogloss:0.143348\n",
      "[638]\ttrain-mlogloss:0.13798\teval-mlogloss:0.143328\n",
      "[639]\ttrain-mlogloss:0.137947\teval-mlogloss:0.143307\n",
      "[640]\ttrain-mlogloss:0.137917\teval-mlogloss:0.143288\n",
      "[641]\ttrain-mlogloss:0.137887\teval-mlogloss:0.143268\n",
      "[642]\ttrain-mlogloss:0.137856\teval-mlogloss:0.143249\n",
      "[643]\ttrain-mlogloss:0.137825\teval-mlogloss:0.143231\n",
      "[644]\ttrain-mlogloss:0.137794\teval-mlogloss:0.143213\n",
      "[645]\ttrain-mlogloss:0.137765\teval-mlogloss:0.143198\n",
      "[646]\ttrain-mlogloss:0.137734\teval-mlogloss:0.143181\n",
      "[647]\ttrain-mlogloss:0.137704\teval-mlogloss:0.143161\n",
      "[648]\ttrain-mlogloss:0.137674\teval-mlogloss:0.143143\n",
      "[649]\ttrain-mlogloss:0.137644\teval-mlogloss:0.143126\n",
      "[650]\ttrain-mlogloss:0.137615\teval-mlogloss:0.143109\n",
      "[651]\ttrain-mlogloss:0.137587\teval-mlogloss:0.14309\n",
      "[652]\ttrain-mlogloss:0.137559\teval-mlogloss:0.143073\n",
      "[653]\ttrain-mlogloss:0.137527\teval-mlogloss:0.143058\n",
      "[654]\ttrain-mlogloss:0.137498\teval-mlogloss:0.143041\n",
      "[655]\ttrain-mlogloss:0.137469\teval-mlogloss:0.143022\n",
      "[656]\ttrain-mlogloss:0.13744\teval-mlogloss:0.143005\n",
      "[657]\ttrain-mlogloss:0.137412\teval-mlogloss:0.142991\n",
      "[658]\ttrain-mlogloss:0.137383\teval-mlogloss:0.14297\n",
      "[659]\ttrain-mlogloss:0.137353\teval-mlogloss:0.142955\n",
      "[660]\ttrain-mlogloss:0.137327\teval-mlogloss:0.142936\n",
      "[661]\ttrain-mlogloss:0.137299\teval-mlogloss:0.142921\n",
      "[662]\ttrain-mlogloss:0.137269\teval-mlogloss:0.142903\n",
      "[663]\ttrain-mlogloss:0.137242\teval-mlogloss:0.142889\n",
      "[664]\ttrain-mlogloss:0.137212\teval-mlogloss:0.142876\n",
      "[665]\ttrain-mlogloss:0.137182\teval-mlogloss:0.14286\n",
      "[666]\ttrain-mlogloss:0.137154\teval-mlogloss:0.142845\n",
      "[667]\ttrain-mlogloss:0.137126\teval-mlogloss:0.14283\n",
      "[668]\ttrain-mlogloss:0.137098\teval-mlogloss:0.142813\n",
      "[669]\ttrain-mlogloss:0.137071\teval-mlogloss:0.142798\n",
      "[670]\ttrain-mlogloss:0.137045\teval-mlogloss:0.142782\n",
      "[671]\ttrain-mlogloss:0.137019\teval-mlogloss:0.142766\n",
      "[672]\ttrain-mlogloss:0.136994\teval-mlogloss:0.14275\n",
      "[673]\ttrain-mlogloss:0.136968\teval-mlogloss:0.142738\n",
      "[674]\ttrain-mlogloss:0.136942\teval-mlogloss:0.142723\n",
      "[675]\ttrain-mlogloss:0.136914\teval-mlogloss:0.142705\n",
      "[676]\ttrain-mlogloss:0.13689\teval-mlogloss:0.142691\n",
      "[677]\ttrain-mlogloss:0.136863\teval-mlogloss:0.142677\n",
      "[678]\ttrain-mlogloss:0.136837\teval-mlogloss:0.142665\n",
      "[679]\ttrain-mlogloss:0.136807\teval-mlogloss:0.142654\n",
      "[680]\ttrain-mlogloss:0.136781\teval-mlogloss:0.142641\n",
      "[681]\ttrain-mlogloss:0.136754\teval-mlogloss:0.142627\n",
      "[682]\ttrain-mlogloss:0.136728\teval-mlogloss:0.142613\n",
      "[683]\ttrain-mlogloss:0.136704\teval-mlogloss:0.1426\n",
      "[684]\ttrain-mlogloss:0.136679\teval-mlogloss:0.142587\n",
      "[685]\ttrain-mlogloss:0.136653\teval-mlogloss:0.142573\n",
      "[686]\ttrain-mlogloss:0.136623\teval-mlogloss:0.142563\n",
      "[687]\ttrain-mlogloss:0.136594\teval-mlogloss:0.142547\n",
      "[688]\ttrain-mlogloss:0.136569\teval-mlogloss:0.142535\n",
      "[689]\ttrain-mlogloss:0.136544\teval-mlogloss:0.142522\n",
      "[690]\ttrain-mlogloss:0.13652\teval-mlogloss:0.14251\n",
      "[691]\ttrain-mlogloss:0.136493\teval-mlogloss:0.142497\n",
      "[692]\ttrain-mlogloss:0.136468\teval-mlogloss:0.142486\n",
      "[693]\ttrain-mlogloss:0.13644\teval-mlogloss:0.142476\n",
      "[694]\ttrain-mlogloss:0.136417\teval-mlogloss:0.142461\n",
      "[695]\ttrain-mlogloss:0.136391\teval-mlogloss:0.142448\n",
      "[696]\ttrain-mlogloss:0.136363\teval-mlogloss:0.142435\n",
      "[697]\ttrain-mlogloss:0.136338\teval-mlogloss:0.142421\n",
      "[698]\ttrain-mlogloss:0.136314\teval-mlogloss:0.14241\n",
      "[699]\ttrain-mlogloss:0.136285\teval-mlogloss:0.142399\n",
      "[700]\ttrain-mlogloss:0.136259\teval-mlogloss:0.142386\n",
      "[701]\ttrain-mlogloss:0.136234\teval-mlogloss:0.142375\n",
      "[702]\ttrain-mlogloss:0.136212\teval-mlogloss:0.142362\n",
      "[703]\ttrain-mlogloss:0.136189\teval-mlogloss:0.14235\n",
      "[704]\ttrain-mlogloss:0.136162\teval-mlogloss:0.142342\n",
      "[705]\ttrain-mlogloss:0.136134\teval-mlogloss:0.14233\n",
      "[706]\ttrain-mlogloss:0.136109\teval-mlogloss:0.142318\n",
      "[707]\ttrain-mlogloss:0.136082\teval-mlogloss:0.142307\n",
      "[708]\ttrain-mlogloss:0.136058\teval-mlogloss:0.142295\n",
      "[709]\ttrain-mlogloss:0.136032\teval-mlogloss:0.142281\n",
      "[710]\ttrain-mlogloss:0.136008\teval-mlogloss:0.142272\n",
      "[711]\ttrain-mlogloss:0.135984\teval-mlogloss:0.142261\n",
      "[712]\ttrain-mlogloss:0.135957\teval-mlogloss:0.14225\n",
      "[713]\ttrain-mlogloss:0.135932\teval-mlogloss:0.14224\n",
      "[714]\ttrain-mlogloss:0.135904\teval-mlogloss:0.142232\n",
      "[715]\ttrain-mlogloss:0.135882\teval-mlogloss:0.142222\n",
      "[716]\ttrain-mlogloss:0.13586\teval-mlogloss:0.142209\n",
      "[717]\ttrain-mlogloss:0.135836\teval-mlogloss:0.142198\n",
      "[718]\ttrain-mlogloss:0.135807\teval-mlogloss:0.14219\n",
      "[719]\ttrain-mlogloss:0.135785\teval-mlogloss:0.142181\n",
      "[720]\ttrain-mlogloss:0.135762\teval-mlogloss:0.142168\n",
      "[721]\ttrain-mlogloss:0.135738\teval-mlogloss:0.142157\n",
      "[722]\ttrain-mlogloss:0.135712\teval-mlogloss:0.142151\n",
      "[723]\ttrain-mlogloss:0.135687\teval-mlogloss:0.14214\n",
      "[724]\ttrain-mlogloss:0.135664\teval-mlogloss:0.142131\n",
      "[725]\ttrain-mlogloss:0.135644\teval-mlogloss:0.14212\n",
      "[726]\ttrain-mlogloss:0.135617\teval-mlogloss:0.142111\n",
      "[727]\ttrain-mlogloss:0.135595\teval-mlogloss:0.142101\n",
      "[728]\ttrain-mlogloss:0.135569\teval-mlogloss:0.142091\n",
      "[729]\ttrain-mlogloss:0.135549\teval-mlogloss:0.142082\n",
      "[730]\ttrain-mlogloss:0.135522\teval-mlogloss:0.142072\n",
      "[731]\ttrain-mlogloss:0.135501\teval-mlogloss:0.142063\n",
      "[732]\ttrain-mlogloss:0.135477\teval-mlogloss:0.142054\n",
      "[733]\ttrain-mlogloss:0.135453\teval-mlogloss:0.142045\n",
      "[734]\ttrain-mlogloss:0.13543\teval-mlogloss:0.142038\n",
      "[735]\ttrain-mlogloss:0.135404\teval-mlogloss:0.142027\n",
      "[736]\ttrain-mlogloss:0.135383\teval-mlogloss:0.142017\n",
      "[737]\ttrain-mlogloss:0.135356\teval-mlogloss:0.14201\n",
      "[738]\ttrain-mlogloss:0.135329\teval-mlogloss:0.142001\n",
      "[739]\ttrain-mlogloss:0.135308\teval-mlogloss:0.141989\n",
      "[740]\ttrain-mlogloss:0.135284\teval-mlogloss:0.14198\n",
      "[741]\ttrain-mlogloss:0.135259\teval-mlogloss:0.141975\n",
      "[742]\ttrain-mlogloss:0.135234\teval-mlogloss:0.141964\n",
      "[743]\ttrain-mlogloss:0.135213\teval-mlogloss:0.141954\n",
      "[744]\ttrain-mlogloss:0.135192\teval-mlogloss:0.141948\n",
      "[745]\ttrain-mlogloss:0.135168\teval-mlogloss:0.141943\n",
      "[746]\ttrain-mlogloss:0.135146\teval-mlogloss:0.141935\n",
      "[747]\ttrain-mlogloss:0.135125\teval-mlogloss:0.141927\n",
      "[748]\ttrain-mlogloss:0.135099\teval-mlogloss:0.141915\n",
      "[749]\ttrain-mlogloss:0.135075\teval-mlogloss:0.14191\n",
      "[750]\ttrain-mlogloss:0.135054\teval-mlogloss:0.141901\n",
      "[751]\ttrain-mlogloss:0.135034\teval-mlogloss:0.141893\n",
      "[752]\ttrain-mlogloss:0.135011\teval-mlogloss:0.141885\n",
      "[753]\ttrain-mlogloss:0.134988\teval-mlogloss:0.141881\n",
      "[754]\ttrain-mlogloss:0.134967\teval-mlogloss:0.141872\n",
      "[755]\ttrain-mlogloss:0.134947\teval-mlogloss:0.141865\n",
      "[756]\ttrain-mlogloss:0.134925\teval-mlogloss:0.14186\n",
      "[757]\ttrain-mlogloss:0.134904\teval-mlogloss:0.141853\n",
      "[758]\ttrain-mlogloss:0.134881\teval-mlogloss:0.141845\n",
      "[759]\ttrain-mlogloss:0.134857\teval-mlogloss:0.141839\n",
      "[760]\ttrain-mlogloss:0.134833\teval-mlogloss:0.141832\n",
      "[761]\ttrain-mlogloss:0.134812\teval-mlogloss:0.141824\n",
      "[762]\ttrain-mlogloss:0.134791\teval-mlogloss:0.141814\n",
      "[763]\ttrain-mlogloss:0.13477\teval-mlogloss:0.141808\n",
      "[764]\ttrain-mlogloss:0.134746\teval-mlogloss:0.141801\n",
      "[765]\ttrain-mlogloss:0.134726\teval-mlogloss:0.141795\n",
      "[766]\ttrain-mlogloss:0.134704\teval-mlogloss:0.141786\n",
      "[767]\ttrain-mlogloss:0.134679\teval-mlogloss:0.14178\n",
      "[768]\ttrain-mlogloss:0.134662\teval-mlogloss:0.141774\n",
      "[769]\ttrain-mlogloss:0.134638\teval-mlogloss:0.141765\n",
      "[770]\ttrain-mlogloss:0.134615\teval-mlogloss:0.141762\n",
      "[771]\ttrain-mlogloss:0.134594\teval-mlogloss:0.141757\n",
      "[772]\ttrain-mlogloss:0.134576\teval-mlogloss:0.14175\n",
      "[773]\ttrain-mlogloss:0.134552\teval-mlogloss:0.141743\n",
      "[774]\ttrain-mlogloss:0.134528\teval-mlogloss:0.141736\n",
      "[775]\ttrain-mlogloss:0.134507\teval-mlogloss:0.141732\n",
      "[776]\ttrain-mlogloss:0.134488\teval-mlogloss:0.141725\n",
      "[777]\ttrain-mlogloss:0.134462\teval-mlogloss:0.141717\n",
      "[778]\ttrain-mlogloss:0.134442\teval-mlogloss:0.141712\n",
      "[779]\ttrain-mlogloss:0.13442\teval-mlogloss:0.141707\n",
      "[780]\ttrain-mlogloss:0.134398\teval-mlogloss:0.141703\n",
      "[781]\ttrain-mlogloss:0.134374\teval-mlogloss:0.141697\n",
      "[782]\ttrain-mlogloss:0.134351\teval-mlogloss:0.141691\n",
      "[783]\ttrain-mlogloss:0.134327\teval-mlogloss:0.141688\n",
      "[784]\ttrain-mlogloss:0.134304\teval-mlogloss:0.141682\n",
      "[785]\ttrain-mlogloss:0.134281\teval-mlogloss:0.141677\n",
      "[786]\ttrain-mlogloss:0.134257\teval-mlogloss:0.141676\n",
      "[787]\ttrain-mlogloss:0.134234\teval-mlogloss:0.141667\n",
      "[788]\ttrain-mlogloss:0.134215\teval-mlogloss:0.141661\n",
      "[789]\ttrain-mlogloss:0.13419\teval-mlogloss:0.141657\n",
      "[790]\ttrain-mlogloss:0.134172\teval-mlogloss:0.141649\n",
      "[791]\ttrain-mlogloss:0.134147\teval-mlogloss:0.141646\n",
      "[792]\ttrain-mlogloss:0.134128\teval-mlogloss:0.141643\n",
      "[793]\ttrain-mlogloss:0.134105\teval-mlogloss:0.14164\n",
      "[794]\ttrain-mlogloss:0.134083\teval-mlogloss:0.141631\n",
      "[795]\ttrain-mlogloss:0.13406\teval-mlogloss:0.14163\n",
      "[796]\ttrain-mlogloss:0.134039\teval-mlogloss:0.141625\n",
      "[797]\ttrain-mlogloss:0.13402\teval-mlogloss:0.141619\n",
      "[798]\ttrain-mlogloss:0.133999\teval-mlogloss:0.141618\n",
      "[799]\ttrain-mlogloss:0.133981\teval-mlogloss:0.141612\n",
      "[800]\ttrain-mlogloss:0.133959\teval-mlogloss:0.141603\n",
      "[801]\ttrain-mlogloss:0.133941\teval-mlogloss:0.141599\n",
      "[802]\ttrain-mlogloss:0.133918\teval-mlogloss:0.141599\n",
      "[803]\ttrain-mlogloss:0.133901\teval-mlogloss:0.141591\n",
      "[804]\ttrain-mlogloss:0.13388\teval-mlogloss:0.141587\n",
      "[805]\ttrain-mlogloss:0.133864\teval-mlogloss:0.141582\n",
      "[806]\ttrain-mlogloss:0.133843\teval-mlogloss:0.141574\n",
      "[807]\ttrain-mlogloss:0.133822\teval-mlogloss:0.141574\n",
      "[808]\ttrain-mlogloss:0.133804\teval-mlogloss:0.141571\n",
      "[809]\ttrain-mlogloss:0.133784\teval-mlogloss:0.141565\n",
      "[810]\ttrain-mlogloss:0.133768\teval-mlogloss:0.141559\n",
      "[811]\ttrain-mlogloss:0.133747\teval-mlogloss:0.141558\n",
      "[812]\ttrain-mlogloss:0.133729\teval-mlogloss:0.14155\n",
      "[813]\ttrain-mlogloss:0.13371\teval-mlogloss:0.141545\n",
      "[814]\ttrain-mlogloss:0.133688\teval-mlogloss:0.141545\n",
      "[815]\ttrain-mlogloss:0.13367\teval-mlogloss:0.141539\n",
      "[816]\ttrain-mlogloss:0.133654\teval-mlogloss:0.141535\n",
      "[817]\ttrain-mlogloss:0.133638\teval-mlogloss:0.141529\n",
      "[818]\ttrain-mlogloss:0.133616\teval-mlogloss:0.141524\n",
      "[819]\ttrain-mlogloss:0.133598\teval-mlogloss:0.141519\n",
      "[820]\ttrain-mlogloss:0.133578\teval-mlogloss:0.141521\n",
      "[821]\ttrain-mlogloss:0.133559\teval-mlogloss:0.141513\n",
      "[822]\ttrain-mlogloss:0.133544\teval-mlogloss:0.141512\n",
      "[823]\ttrain-mlogloss:0.133524\teval-mlogloss:0.141507\n",
      "[824]\ttrain-mlogloss:0.133508\teval-mlogloss:0.1415\n",
      "[825]\ttrain-mlogloss:0.133489\teval-mlogloss:0.1415\n",
      "[826]\ttrain-mlogloss:0.133471\teval-mlogloss:0.141496\n",
      "[827]\ttrain-mlogloss:0.133453\teval-mlogloss:0.141491\n",
      "[828]\ttrain-mlogloss:0.133433\teval-mlogloss:0.141486\n",
      "[829]\ttrain-mlogloss:0.133416\teval-mlogloss:0.141482\n",
      "[830]\ttrain-mlogloss:0.133398\teval-mlogloss:0.141476\n",
      "[831]\ttrain-mlogloss:0.133378\teval-mlogloss:0.141475\n",
      "[832]\ttrain-mlogloss:0.133361\teval-mlogloss:0.141472\n",
      "[833]\ttrain-mlogloss:0.133339\teval-mlogloss:0.141466\n",
      "[834]\ttrain-mlogloss:0.133321\teval-mlogloss:0.141464\n",
      "[835]\ttrain-mlogloss:0.133305\teval-mlogloss:0.141461\n",
      "[836]\ttrain-mlogloss:0.133288\teval-mlogloss:0.141458\n",
      "[837]\ttrain-mlogloss:0.133267\teval-mlogloss:0.141455\n",
      "[838]\ttrain-mlogloss:0.133251\teval-mlogloss:0.141452\n",
      "[839]\ttrain-mlogloss:0.13323\teval-mlogloss:0.141446\n",
      "[840]\ttrain-mlogloss:0.133215\teval-mlogloss:0.141445\n",
      "[841]\ttrain-mlogloss:0.133194\teval-mlogloss:0.141442\n",
      "[842]\ttrain-mlogloss:0.133177\teval-mlogloss:0.141436\n",
      "[843]\ttrain-mlogloss:0.133161\teval-mlogloss:0.141432\n",
      "[844]\ttrain-mlogloss:0.133143\teval-mlogloss:0.141431\n",
      "[845]\ttrain-mlogloss:0.133124\teval-mlogloss:0.141425\n",
      "[846]\ttrain-mlogloss:0.133105\teval-mlogloss:0.141424\n",
      "[847]\ttrain-mlogloss:0.133087\teval-mlogloss:0.141419\n",
      "[848]\ttrain-mlogloss:0.133072\teval-mlogloss:0.141416\n",
      "[849]\ttrain-mlogloss:0.133058\teval-mlogloss:0.141413\n",
      "[850]\ttrain-mlogloss:0.133037\teval-mlogloss:0.141414\n",
      "[851]\ttrain-mlogloss:0.13302\teval-mlogloss:0.141409\n",
      "[852]\ttrain-mlogloss:0.133003\teval-mlogloss:0.141406\n",
      "[853]\ttrain-mlogloss:0.132988\teval-mlogloss:0.141404\n",
      "[854]\ttrain-mlogloss:0.132968\teval-mlogloss:0.141399\n",
      "[855]\ttrain-mlogloss:0.132951\teval-mlogloss:0.141395\n",
      "[856]\ttrain-mlogloss:0.132935\teval-mlogloss:0.14139\n",
      "[857]\ttrain-mlogloss:0.13292\teval-mlogloss:0.141388\n",
      "[858]\ttrain-mlogloss:0.132901\teval-mlogloss:0.141384\n",
      "[859]\ttrain-mlogloss:0.132883\teval-mlogloss:0.141379\n",
      "[860]\ttrain-mlogloss:0.132868\teval-mlogloss:0.141379\n",
      "[861]\ttrain-mlogloss:0.132852\teval-mlogloss:0.141375\n",
      "[862]\ttrain-mlogloss:0.132833\teval-mlogloss:0.141373\n",
      "[863]\ttrain-mlogloss:0.13282\teval-mlogloss:0.14137\n",
      "[864]\ttrain-mlogloss:0.132804\teval-mlogloss:0.141367\n",
      "[865]\ttrain-mlogloss:0.132783\teval-mlogloss:0.141364\n",
      "[866]\ttrain-mlogloss:0.132771\teval-mlogloss:0.141364\n",
      "[867]\ttrain-mlogloss:0.132751\teval-mlogloss:0.141362\n",
      "[868]\ttrain-mlogloss:0.132732\teval-mlogloss:0.141359\n",
      "[869]\ttrain-mlogloss:0.132714\teval-mlogloss:0.141358\n",
      "[870]\ttrain-mlogloss:0.132699\teval-mlogloss:0.141355\n",
      "[871]\ttrain-mlogloss:0.132682\teval-mlogloss:0.141354\n",
      "[872]\ttrain-mlogloss:0.132664\teval-mlogloss:0.141354\n",
      "[873]\ttrain-mlogloss:0.132646\teval-mlogloss:0.141353\n",
      "[874]\ttrain-mlogloss:0.13263\teval-mlogloss:0.141349\n",
      "[875]\ttrain-mlogloss:0.132616\teval-mlogloss:0.141348\n",
      "[876]\ttrain-mlogloss:0.132598\teval-mlogloss:0.141345\n",
      "[877]\ttrain-mlogloss:0.132583\teval-mlogloss:0.141343\n",
      "[878]\ttrain-mlogloss:0.132564\teval-mlogloss:0.141342\n",
      "[879]\ttrain-mlogloss:0.132549\teval-mlogloss:0.141342\n",
      "[880]\ttrain-mlogloss:0.132531\teval-mlogloss:0.141342\n",
      "[881]\ttrain-mlogloss:0.132511\teval-mlogloss:0.14134\n",
      "[882]\ttrain-mlogloss:0.132497\teval-mlogloss:0.141339\n",
      "[883]\ttrain-mlogloss:0.132483\teval-mlogloss:0.141335\n",
      "[884]\ttrain-mlogloss:0.132462\teval-mlogloss:0.141337\n",
      "[885]\ttrain-mlogloss:0.132445\teval-mlogloss:0.141333\n",
      "[886]\ttrain-mlogloss:0.13243\teval-mlogloss:0.14133\n",
      "[887]\ttrain-mlogloss:0.132409\teval-mlogloss:0.141329\n",
      "[888]\ttrain-mlogloss:0.132396\teval-mlogloss:0.141326\n",
      "[889]\ttrain-mlogloss:0.132377\teval-mlogloss:0.141323\n",
      "[890]\ttrain-mlogloss:0.132359\teval-mlogloss:0.141321\n",
      "[891]\ttrain-mlogloss:0.132346\teval-mlogloss:0.141317\n",
      "[892]\ttrain-mlogloss:0.132327\teval-mlogloss:0.141317\n",
      "[893]\ttrain-mlogloss:0.132309\teval-mlogloss:0.141318\n",
      "[894]\ttrain-mlogloss:0.132294\teval-mlogloss:0.141315\n",
      "[895]\ttrain-mlogloss:0.132277\teval-mlogloss:0.141312\n",
      "[896]\ttrain-mlogloss:0.132258\teval-mlogloss:0.14131\n",
      "[897]\ttrain-mlogloss:0.132242\teval-mlogloss:0.14131\n",
      "[898]\ttrain-mlogloss:0.132227\teval-mlogloss:0.141304\n",
      "[899]\ttrain-mlogloss:0.132206\teval-mlogloss:0.141302\n",
      "[900]\ttrain-mlogloss:0.132193\teval-mlogloss:0.141301\n",
      "[901]\ttrain-mlogloss:0.132175\teval-mlogloss:0.141298\n",
      "[902]\ttrain-mlogloss:0.132162\teval-mlogloss:0.141299\n",
      "[903]\ttrain-mlogloss:0.132143\teval-mlogloss:0.141297\n",
      "[904]\ttrain-mlogloss:0.132125\teval-mlogloss:0.141296\n",
      "[905]\ttrain-mlogloss:0.132106\teval-mlogloss:0.141293\n",
      "[906]\ttrain-mlogloss:0.132091\teval-mlogloss:0.141295\n",
      "[907]\ttrain-mlogloss:0.132072\teval-mlogloss:0.141293\n",
      "[908]\ttrain-mlogloss:0.132058\teval-mlogloss:0.141291\n",
      "[909]\ttrain-mlogloss:0.132043\teval-mlogloss:0.141289\n",
      "[910]\ttrain-mlogloss:0.132021\teval-mlogloss:0.14129\n",
      "[911]\ttrain-mlogloss:0.132008\teval-mlogloss:0.141288\n",
      "[912]\ttrain-mlogloss:0.131992\teval-mlogloss:0.141288\n",
      "[913]\ttrain-mlogloss:0.131977\teval-mlogloss:0.141287\n",
      "[914]\ttrain-mlogloss:0.131956\teval-mlogloss:0.141285\n",
      "[915]\ttrain-mlogloss:0.131944\teval-mlogloss:0.141282\n",
      "[916]\ttrain-mlogloss:0.131924\teval-mlogloss:0.14128\n",
      "[917]\ttrain-mlogloss:0.131911\teval-mlogloss:0.141281\n",
      "[918]\ttrain-mlogloss:0.131892\teval-mlogloss:0.141281\n",
      "[919]\ttrain-mlogloss:0.131876\teval-mlogloss:0.141279\n",
      "[920]\ttrain-mlogloss:0.131863\teval-mlogloss:0.141277\n",
      "[921]\ttrain-mlogloss:0.131845\teval-mlogloss:0.141275\n",
      "[922]\ttrain-mlogloss:0.131829\teval-mlogloss:0.141272\n",
      "[923]\ttrain-mlogloss:0.131816\teval-mlogloss:0.141271\n",
      "[924]\ttrain-mlogloss:0.131799\teval-mlogloss:0.141271\n",
      "[925]\ttrain-mlogloss:0.131782\teval-mlogloss:0.141272\n",
      "[926]\ttrain-mlogloss:0.131768\teval-mlogloss:0.14127\n",
      "[927]\ttrain-mlogloss:0.131753\teval-mlogloss:0.141267\n",
      "[928]\ttrain-mlogloss:0.131736\teval-mlogloss:0.141265\n",
      "[929]\ttrain-mlogloss:0.131719\teval-mlogloss:0.141264\n",
      "[930]\ttrain-mlogloss:0.131705\teval-mlogloss:0.141265\n",
      "[931]\ttrain-mlogloss:0.131689\teval-mlogloss:0.141267\n",
      "[932]\ttrain-mlogloss:0.13167\teval-mlogloss:0.141268\n",
      "[933]\ttrain-mlogloss:0.131656\teval-mlogloss:0.141267\n",
      "[934]\ttrain-mlogloss:0.131641\teval-mlogloss:0.141264\n",
      "[935]\ttrain-mlogloss:0.131625\teval-mlogloss:0.141263\n",
      "[936]\ttrain-mlogloss:0.131613\teval-mlogloss:0.141259\n",
      "[937]\ttrain-mlogloss:0.131594\teval-mlogloss:0.14126\n",
      "[938]\ttrain-mlogloss:0.13158\teval-mlogloss:0.141259\n",
      "[939]\ttrain-mlogloss:0.131565\teval-mlogloss:0.141258\n",
      "[940]\ttrain-mlogloss:0.13155\teval-mlogloss:0.141256\n",
      "[941]\ttrain-mlogloss:0.131532\teval-mlogloss:0.141254\n",
      "[942]\ttrain-mlogloss:0.131513\teval-mlogloss:0.141253\n",
      "[943]\ttrain-mlogloss:0.131498\teval-mlogloss:0.141255\n",
      "[944]\ttrain-mlogloss:0.131483\teval-mlogloss:0.141251\n",
      "[945]\ttrain-mlogloss:0.131469\teval-mlogloss:0.14125\n",
      "[946]\ttrain-mlogloss:0.131451\teval-mlogloss:0.141248\n",
      "[947]\ttrain-mlogloss:0.131438\teval-mlogloss:0.141249\n",
      "[948]\ttrain-mlogloss:0.131421\teval-mlogloss:0.141248\n",
      "[949]\ttrain-mlogloss:0.131407\teval-mlogloss:0.141249\n",
      "[950]\ttrain-mlogloss:0.13139\teval-mlogloss:0.141248\n",
      "[951]\ttrain-mlogloss:0.131374\teval-mlogloss:0.141248\n",
      "[952]\ttrain-mlogloss:0.131358\teval-mlogloss:0.141247\n",
      "[953]\ttrain-mlogloss:0.131347\teval-mlogloss:0.141248\n",
      "[954]\ttrain-mlogloss:0.131331\teval-mlogloss:0.141247\n",
      "[955]\ttrain-mlogloss:0.131315\teval-mlogloss:0.141247\n",
      "[956]\ttrain-mlogloss:0.1313\teval-mlogloss:0.141248\n",
      "[957]\ttrain-mlogloss:0.131287\teval-mlogloss:0.141249\n",
      "[958]\ttrain-mlogloss:0.13127\teval-mlogloss:0.141249\n",
      "[959]\ttrain-mlogloss:0.131258\teval-mlogloss:0.14125\n",
      "[960]\ttrain-mlogloss:0.131248\teval-mlogloss:0.141249\n",
      "[961]\ttrain-mlogloss:0.131232\teval-mlogloss:0.141251\n",
      "[962]\ttrain-mlogloss:0.131217\teval-mlogloss:0.141251\n",
      "[963]\ttrain-mlogloss:0.131202\teval-mlogloss:0.141251\n",
      "[964]\ttrain-mlogloss:0.131189\teval-mlogloss:0.14125\n",
      "[965]\ttrain-mlogloss:0.131175\teval-mlogloss:0.141248\n",
      "[966]\ttrain-mlogloss:0.13116\teval-mlogloss:0.141248\n",
      "[967]\ttrain-mlogloss:0.131143\teval-mlogloss:0.14125\n",
      "[968]\ttrain-mlogloss:0.131129\teval-mlogloss:0.141249\n",
      "[969]\ttrain-mlogloss:0.131115\teval-mlogloss:0.141247\n",
      "[970]\ttrain-mlogloss:0.131102\teval-mlogloss:0.141249\n",
      "[971]\ttrain-mlogloss:0.131088\teval-mlogloss:0.141251\n",
      "[972]\ttrain-mlogloss:0.131074\teval-mlogloss:0.141253\n",
      "[973]\ttrain-mlogloss:0.131062\teval-mlogloss:0.14125\n",
      "[974]\ttrain-mlogloss:0.131047\teval-mlogloss:0.14125\n",
      "[975]\ttrain-mlogloss:0.131033\teval-mlogloss:0.141252\n",
      "[976]\ttrain-mlogloss:0.131019\teval-mlogloss:0.141251\n",
      "[977]\ttrain-mlogloss:0.131004\teval-mlogloss:0.141251\n",
      "[978]\ttrain-mlogloss:0.13099\teval-mlogloss:0.141249\n",
      "[979]\ttrain-mlogloss:0.130977\teval-mlogloss:0.14125\n",
      "[980]\ttrain-mlogloss:0.130961\teval-mlogloss:0.141249\n",
      "[981]\ttrain-mlogloss:0.130947\teval-mlogloss:0.141248\n",
      "[982]\ttrain-mlogloss:0.130934\teval-mlogloss:0.14125\n",
      "[983]\ttrain-mlogloss:0.130921\teval-mlogloss:0.141248\n",
      "[984]\ttrain-mlogloss:0.130905\teval-mlogloss:0.141249\n",
      "[985]\ttrain-mlogloss:0.130892\teval-mlogloss:0.141248\n",
      "[986]\ttrain-mlogloss:0.130875\teval-mlogloss:0.141248\n",
      "[987]\ttrain-mlogloss:0.13086\teval-mlogloss:0.141249\n",
      "[988]\ttrain-mlogloss:0.130846\teval-mlogloss:0.141247\n",
      "[989]\ttrain-mlogloss:0.130834\teval-mlogloss:0.14125\n",
      "[990]\ttrain-mlogloss:0.130819\teval-mlogloss:0.14125\n",
      "[991]\ttrain-mlogloss:0.130809\teval-mlogloss:0.14125\n",
      "[992]\ttrain-mlogloss:0.130794\teval-mlogloss:0.141249\n",
      "[993]\ttrain-mlogloss:0.130782\teval-mlogloss:0.141249\n",
      "[994]\ttrain-mlogloss:0.130765\teval-mlogloss:0.141253\n",
      "[995]\ttrain-mlogloss:0.130749\teval-mlogloss:0.141252\n",
      "[996]\ttrain-mlogloss:0.130736\teval-mlogloss:0.141254\n",
      "[997]\ttrain-mlogloss:0.130717\teval-mlogloss:0.14125\n",
      "[998]\ttrain-mlogloss:0.1307\teval-mlogloss:0.14125\n",
      "[999]\ttrain-mlogloss:0.130685\teval-mlogloss:0.141248\n",
      "[1000]\ttrain-mlogloss:0.130673\teval-mlogloss:0.141249\n",
      "[1001]\ttrain-mlogloss:0.13066\teval-mlogloss:0.141246\n",
      "[1002]\ttrain-mlogloss:0.130647\teval-mlogloss:0.141247\n",
      "[1003]\ttrain-mlogloss:0.130631\teval-mlogloss:0.141247\n",
      "[1004]\ttrain-mlogloss:0.130616\teval-mlogloss:0.141246\n",
      "[1005]\ttrain-mlogloss:0.130603\teval-mlogloss:0.141248\n",
      "[1006]\ttrain-mlogloss:0.130586\teval-mlogloss:0.141248\n",
      "[1007]\ttrain-mlogloss:0.130571\teval-mlogloss:0.141251\n",
      "[1008]\ttrain-mlogloss:0.130555\teval-mlogloss:0.141251\n",
      "[1009]\ttrain-mlogloss:0.130543\teval-mlogloss:0.141251\n",
      "[1010]\ttrain-mlogloss:0.130531\teval-mlogloss:0.141254\n",
      "[1011]\ttrain-mlogloss:0.130519\teval-mlogloss:0.141251\n",
      "[1012]\ttrain-mlogloss:0.130501\teval-mlogloss:0.141254\n",
      "[1013]\ttrain-mlogloss:0.130487\teval-mlogloss:0.141251\n",
      "[1014]\ttrain-mlogloss:0.130471\teval-mlogloss:0.14125\n",
      "[1015]\ttrain-mlogloss:0.130454\teval-mlogloss:0.141252\n",
      "[1016]\ttrain-mlogloss:0.13044\teval-mlogloss:0.141252\n",
      "[1017]\ttrain-mlogloss:0.130427\teval-mlogloss:0.141251\n",
      "[1018]\ttrain-mlogloss:0.130411\teval-mlogloss:0.141248\n",
      "[1019]\ttrain-mlogloss:0.130393\teval-mlogloss:0.141248\n",
      "[1020]\ttrain-mlogloss:0.130378\teval-mlogloss:0.141246\n",
      "[1021]\ttrain-mlogloss:0.130364\teval-mlogloss:0.141246\n",
      "[1022]\ttrain-mlogloss:0.130351\teval-mlogloss:0.141246\n",
      "[1023]\ttrain-mlogloss:0.130334\teval-mlogloss:0.141245\n",
      "[1024]\ttrain-mlogloss:0.130321\teval-mlogloss:0.141246\n",
      "[1025]\ttrain-mlogloss:0.130305\teval-mlogloss:0.141246\n",
      "[1026]\ttrain-mlogloss:0.13029\teval-mlogloss:0.141243\n",
      "[1027]\ttrain-mlogloss:0.130276\teval-mlogloss:0.141244\n",
      "[1028]\ttrain-mlogloss:0.130263\teval-mlogloss:0.141242\n",
      "[1029]\ttrain-mlogloss:0.130246\teval-mlogloss:0.141241\n",
      "[1030]\ttrain-mlogloss:0.130232\teval-mlogloss:0.141241\n",
      "[1031]\ttrain-mlogloss:0.130217\teval-mlogloss:0.141242\n",
      "[1032]\ttrain-mlogloss:0.130205\teval-mlogloss:0.141241\n",
      "[1033]\ttrain-mlogloss:0.13019\teval-mlogloss:0.141242\n",
      "[1034]\ttrain-mlogloss:0.130174\teval-mlogloss:0.14124\n",
      "[1035]\ttrain-mlogloss:0.13016\teval-mlogloss:0.14124\n",
      "[1036]\ttrain-mlogloss:0.130144\teval-mlogloss:0.141239\n",
      "[1037]\ttrain-mlogloss:0.130132\teval-mlogloss:0.14124\n",
      "[1038]\ttrain-mlogloss:0.130114\teval-mlogloss:0.141246\n",
      "[1039]\ttrain-mlogloss:0.130096\teval-mlogloss:0.141247\n",
      "[1040]\ttrain-mlogloss:0.130084\teval-mlogloss:0.141247\n",
      "[1041]\ttrain-mlogloss:0.130068\teval-mlogloss:0.141247\n",
      "[1042]\ttrain-mlogloss:0.130053\teval-mlogloss:0.141244\n",
      "[1043]\ttrain-mlogloss:0.13004\teval-mlogloss:0.141246\n",
      "[1044]\ttrain-mlogloss:0.130026\teval-mlogloss:0.141245\n",
      "[1045]\ttrain-mlogloss:0.130008\teval-mlogloss:0.141247\n",
      "[1046]\ttrain-mlogloss:0.129993\teval-mlogloss:0.14125\n",
      "[1047]\ttrain-mlogloss:0.129981\teval-mlogloss:0.141248\n",
      "[1048]\ttrain-mlogloss:0.129969\teval-mlogloss:0.141249\n",
      "[1049]\ttrain-mlogloss:0.129953\teval-mlogloss:0.141247\n",
      "[1050]\ttrain-mlogloss:0.129936\teval-mlogloss:0.14125\n",
      "[1051]\ttrain-mlogloss:0.129917\teval-mlogloss:0.141249\n",
      "[1052]\ttrain-mlogloss:0.129898\teval-mlogloss:0.141251\n",
      "[1053]\ttrain-mlogloss:0.129885\teval-mlogloss:0.141251\n",
      "[1054]\ttrain-mlogloss:0.129873\teval-mlogloss:0.141257\n",
      "[1055]\ttrain-mlogloss:0.129856\teval-mlogloss:0.141257\n",
      "[1056]\ttrain-mlogloss:0.129837\teval-mlogloss:0.141253\n",
      "[1057]\ttrain-mlogloss:0.129828\teval-mlogloss:0.141255\n",
      "[1058]\ttrain-mlogloss:0.129813\teval-mlogloss:0.141256\n",
      "[1059]\ttrain-mlogloss:0.129799\teval-mlogloss:0.141257\n",
      "[1060]\ttrain-mlogloss:0.129781\teval-mlogloss:0.141256\n",
      "[1061]\ttrain-mlogloss:0.129766\teval-mlogloss:0.141258\n",
      "[1062]\ttrain-mlogloss:0.129748\teval-mlogloss:0.141258\n",
      "[1063]\ttrain-mlogloss:0.129734\teval-mlogloss:0.141257\n",
      "[1064]\ttrain-mlogloss:0.129716\teval-mlogloss:0.141258\n",
      "[1065]\ttrain-mlogloss:0.129705\teval-mlogloss:0.14126\n",
      "[1066]\ttrain-mlogloss:0.129691\teval-mlogloss:0.141259\n",
      "[1067]\ttrain-mlogloss:0.129674\teval-mlogloss:0.141261\n",
      "[1068]\ttrain-mlogloss:0.129658\teval-mlogloss:0.141262\n",
      "[1069]\ttrain-mlogloss:0.129641\teval-mlogloss:0.141262\n",
      "[1070]\ttrain-mlogloss:0.129628\teval-mlogloss:0.141261\n",
      "[1071]\ttrain-mlogloss:0.12961\teval-mlogloss:0.141263\n",
      "[1072]\ttrain-mlogloss:0.129597\teval-mlogloss:0.141265\n",
      "[1073]\ttrain-mlogloss:0.129582\teval-mlogloss:0.141268\n",
      "[1074]\ttrain-mlogloss:0.129562\teval-mlogloss:0.141269\n",
      "[1075]\ttrain-mlogloss:0.129547\teval-mlogloss:0.141267\n",
      "[1076]\ttrain-mlogloss:0.129534\teval-mlogloss:0.141271\n",
      "[1077]\ttrain-mlogloss:0.129522\teval-mlogloss:0.141274\n",
      "[1078]\ttrain-mlogloss:0.129508\teval-mlogloss:0.141278\n",
      "[1079]\ttrain-mlogloss:0.129492\teval-mlogloss:0.141276\n",
      "[1080]\ttrain-mlogloss:0.129472\teval-mlogloss:0.141278\n",
      "[1081]\ttrain-mlogloss:0.129459\teval-mlogloss:0.141282\n",
      "[1082]\ttrain-mlogloss:0.129444\teval-mlogloss:0.141282\n",
      "[1083]\ttrain-mlogloss:0.129426\teval-mlogloss:0.141285\n",
      "[1084]\ttrain-mlogloss:0.129408\teval-mlogloss:0.141284\n",
      "[1085]\ttrain-mlogloss:0.129395\teval-mlogloss:0.141287\n",
      "[1086]\ttrain-mlogloss:0.129378\teval-mlogloss:0.141288\n",
      "[1087]\ttrain-mlogloss:0.129366\teval-mlogloss:0.141287\n",
      "[1088]\ttrain-mlogloss:0.129353\teval-mlogloss:0.141291\n",
      "[1089]\ttrain-mlogloss:0.129337\teval-mlogloss:0.141294\n",
      "[1090]\ttrain-mlogloss:0.12932\teval-mlogloss:0.141297\n",
      "[1091]\ttrain-mlogloss:0.129305\teval-mlogloss:0.141296\n",
      "[1092]\ttrain-mlogloss:0.129291\teval-mlogloss:0.141294\n",
      "[1093]\ttrain-mlogloss:0.129278\teval-mlogloss:0.141299\n",
      "[1094]\ttrain-mlogloss:0.129262\teval-mlogloss:0.141299\n",
      "[1095]\ttrain-mlogloss:0.129249\teval-mlogloss:0.141302\n",
      "[1096]\ttrain-mlogloss:0.129233\teval-mlogloss:0.141306\n",
      "[1097]\ttrain-mlogloss:0.129222\teval-mlogloss:0.141306\n",
      "[1098]\ttrain-mlogloss:0.129209\teval-mlogloss:0.141309\n",
      "[1099]\ttrain-mlogloss:0.129195\teval-mlogloss:0.141315\n",
      "[1100]\ttrain-mlogloss:0.129179\teval-mlogloss:0.141317\n",
      "[1101]\ttrain-mlogloss:0.129163\teval-mlogloss:0.141315\n",
      "[1102]\ttrain-mlogloss:0.129151\teval-mlogloss:0.141316\n",
      "[1103]\ttrain-mlogloss:0.129137\teval-mlogloss:0.141314\n",
      "[1104]\ttrain-mlogloss:0.129126\teval-mlogloss:0.141316\n",
      "[1105]\ttrain-mlogloss:0.129112\teval-mlogloss:0.141319\n",
      "[1106]\ttrain-mlogloss:0.129101\teval-mlogloss:0.141321\n",
      "[1107]\ttrain-mlogloss:0.129083\teval-mlogloss:0.141324\n",
      "[1108]\ttrain-mlogloss:0.129068\teval-mlogloss:0.141325\n",
      "[1109]\ttrain-mlogloss:0.129055\teval-mlogloss:0.141327\n",
      "[1110]\ttrain-mlogloss:0.129045\teval-mlogloss:0.141329\n",
      "[1111]\ttrain-mlogloss:0.12903\teval-mlogloss:0.141334\n",
      "[1112]\ttrain-mlogloss:0.129009\teval-mlogloss:0.141335\n",
      "[1113]\ttrain-mlogloss:0.128993\teval-mlogloss:0.141339\n",
      "[1114]\ttrain-mlogloss:0.12898\teval-mlogloss:0.141341\n",
      "[1115]\ttrain-mlogloss:0.128969\teval-mlogloss:0.141342\n",
      "[1116]\ttrain-mlogloss:0.128956\teval-mlogloss:0.141344\n",
      "[1117]\ttrain-mlogloss:0.128947\teval-mlogloss:0.141344\n",
      "[1118]\ttrain-mlogloss:0.128937\teval-mlogloss:0.141344\n",
      "[1119]\ttrain-mlogloss:0.128919\teval-mlogloss:0.141347\n",
      "[1120]\ttrain-mlogloss:0.128903\teval-mlogloss:0.141351\n",
      "[1121]\ttrain-mlogloss:0.128885\teval-mlogloss:0.141352\n",
      "[1122]\ttrain-mlogloss:0.128875\teval-mlogloss:0.141352\n",
      "[1123]\ttrain-mlogloss:0.128858\teval-mlogloss:0.141355\n",
      "[1124]\ttrain-mlogloss:0.128845\teval-mlogloss:0.141357\n",
      "[1125]\ttrain-mlogloss:0.128833\teval-mlogloss:0.141359\n",
      "[1126]\ttrain-mlogloss:0.128816\teval-mlogloss:0.14136\n",
      "[1127]\ttrain-mlogloss:0.128804\teval-mlogloss:0.14136\n",
      "[1128]\ttrain-mlogloss:0.128793\teval-mlogloss:0.14136\n",
      "[1129]\ttrain-mlogloss:0.12878\teval-mlogloss:0.141363\n",
      "[1130]\ttrain-mlogloss:0.128764\teval-mlogloss:0.141367\n",
      "[1131]\ttrain-mlogloss:0.128748\teval-mlogloss:0.14137\n",
      "[1132]\ttrain-mlogloss:0.128737\teval-mlogloss:0.141371\n",
      "[1133]\ttrain-mlogloss:0.128724\teval-mlogloss:0.141376\n",
      "[1134]\ttrain-mlogloss:0.128708\teval-mlogloss:0.141378\n",
      "[1135]\ttrain-mlogloss:0.128697\teval-mlogloss:0.14138\n",
      "[1136]\ttrain-mlogloss:0.128685\teval-mlogloss:0.141383\n",
      "Stopping. Best iteration:\n",
      "[1036]\ttrain-mlogloss:0.130144\teval-mlogloss:0.141239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds_ = gbm.predict(xgb.DMatrix(val_x), ntree_limit=gbm.best_iteration+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 0], dtype=uint8), array([0, 0, 1, 0]))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_preds_[0] > 0.5).astype(np.uint8), trainval_y[test_index][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 0], dtype=uint8), array([1, 0, 0, 0]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_preds_[1] > 0.5).astype(np.uint8), trainval_y[test_index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94063588527384567"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(trainval_y[test_index], (y_preds_ > 0.5).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94136465821784143"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(trainval_y[test_index], (val_predictions_df[weather_tags].values[test_index] > 0.5).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run CV with a random search of optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_params(iter_num):\n",
    "    if iter_num > 0:\n",
    "        for z in range(iter_num):\n",
    "            print(\"\\n-- Iteration: {}\".format(z))\n",
    "            eta = np.random.uniform(0.05, 0.001)\n",
    "            max_depth = np.random.randint(2, 6)\n",
    "            subsample = np.random.uniform(0.5, 0.95)\n",
    "            colsample_bytree = np.random.uniform(0.5, 0.95)\n",
    "            yield eta, max_depth, subsample, colsample_bytree\n",
    "    else:\n",
    "        eta = 0.05\n",
    "        max_depth = 3\n",
    "        subsample = 0.8204967474962096\n",
    "        colsample_bytree = 0.7089159774987868\n",
    "        yield eta, max_depth, subsample, colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------\n",
      " Tag index: 0\n",
      "\n",
      "-- Iteration: 0\n",
      "XGBoost params. ETA: 0.023096741976626596, MAX_DEPTH: 2, SUBSAMPLE: 0.9294778786611162, COLSAMPLE_BY_TREE: 0.684612705671509\n",
      "Best cv result:  test-logloss-mean     0.246641\n",
      "test-logloss-std      0.009194\n",
      "train-logloss-mean    0.233773\n",
      "train-logloss-std     0.002104\n",
      "Name: 1209, dtype: float64\n",
      "Best params:  {'seed': 2017, 'scale_pos_weight': 2.2825856875356183, 'booster': 'gbtree', 'subsample': 0.9294778786611162, 'eta': 0.023096741976626596, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.684612705671509, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 2}\n",
      "\n",
      "-- Iteration: 1\n",
      "XGBoost params. ETA: 0.023096741976626596, MAX_DEPTH: 2, SUBSAMPLE: 0.9294778786611162, COLSAMPLE_BY_TREE: 0.684612705671509\n",
      "\n",
      "-- Iteration: 2\n",
      "XGBoost params. ETA: 0.020594509346487103, MAX_DEPTH: 3, SUBSAMPLE: 0.8326168479972074, COLSAMPLE_BY_TREE: 0.8939410323228981\n",
      "Best cv result:  test-logloss-mean     0.245555\n",
      "test-logloss-std      0.007506\n",
      "train-logloss-mean    0.229909\n",
      "train-logloss-std     0.002073\n",
      "Name: 713, dtype: float64\n",
      "Best params:  {'seed': 2020, 'scale_pos_weight': 2.2825856875356183, 'booster': 'gbtree', 'subsample': 0.8326168479972074, 'eta': 0.020594509346487103, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.8939410323228981, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 3}\n",
      "\n",
      "-- Iteration: 3\n",
      "XGBoost params. ETA: 0.02653115436725616, MAX_DEPTH: 5, SUBSAMPLE: 0.8162897671482163, COLSAMPLE_BY_TREE: 0.5151974580887335\n",
      "Best cv result:  test-logloss-mean     0.242842\n",
      "test-logloss-std      0.005992\n",
      "train-logloss-mean    0.161151\n",
      "train-logloss-std     0.001139\n",
      "Name: 1231, dtype: float64\n",
      "Best params:  {'seed': 2023, 'scale_pos_weight': 2.2825856875356183, 'booster': 'gbtree', 'subsample': 0.8162897671482163, 'eta': 0.02653115436725616, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.5151974580887335, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 5}\n",
      "\n",
      "-- Iteration: 4\n",
      "XGBoost params. ETA: 0.0031731299894125695, MAX_DEPTH: 5, SUBSAMPLE: 0.6800766082244368, COLSAMPLE_BY_TREE: 0.9180867956437442\n",
      "\n",
      "-- Iteration: 5\n",
      "XGBoost params. ETA: 0.0069887935550004415, MAX_DEPTH: 5, SUBSAMPLE: 0.7007627562491288, COLSAMPLE_BY_TREE: 0.8127945000047486\n",
      "\n",
      "-- Iteration: 6\n",
      "XGBoost params. ETA: 0.024988972967877485, MAX_DEPTH: 5, SUBSAMPLE: 0.7387515922133331, COLSAMPLE_BY_TREE: 0.5829334344789511\n",
      "Best cv result:  test-logloss-mean     0.242049\n",
      "test-logloss-std      0.007255\n",
      "train-logloss-mean    0.160882\n",
      "train-logloss-std     0.001986\n",
      "Name: 1272, dtype: float64\n",
      "Best params:  {'seed': 2038, 'scale_pos_weight': 2.2825856875356183, 'booster': 'gbtree', 'subsample': 0.7387515922133331, 'eta': 0.024988972967877485, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.5829334344789511, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 5}\n",
      "\n",
      "-- Iteration: 7\n",
      "XGBoost params. ETA: 0.019341114998370035, MAX_DEPTH: 5, SUBSAMPLE: 0.9267089554755925, COLSAMPLE_BY_TREE: 0.5455976440998712\n",
      "\n",
      "-- Iteration: 8\n",
      "XGBoost params. ETA: 0.02200964775463629, MAX_DEPTH: 2, SUBSAMPLE: 0.5765852508220348, COLSAMPLE_BY_TREE: 0.641941243761094\n",
      "\n",
      "-- Iteration: 9\n",
      "XGBoost params. ETA: 0.01959216312177087, MAX_DEPTH: 2, SUBSAMPLE: 0.69522483565335, COLSAMPLE_BY_TREE: 0.5249707473915985\n",
      "\n",
      "-- Iteration: 10\n",
      "XGBoost params. ETA: 0.0042383026863690235, MAX_DEPTH: 4, SUBSAMPLE: 0.9231953410445346, COLSAMPLE_BY_TREE: 0.777191690126488\n",
      "\n",
      "-- Iteration: 11\n",
      "XGBoost params. ETA: 0.0107439367380886, MAX_DEPTH: 5, SUBSAMPLE: 0.6636904286793001, COLSAMPLE_BY_TREE: 0.8394974530607874\n",
      "\n",
      "-- Iteration: 12\n",
      "XGBoost params. ETA: 0.03214890916462293, MAX_DEPTH: 4, SUBSAMPLE: 0.6630006836862006, COLSAMPLE_BY_TREE: 0.757752550842564\n",
      "\n",
      "-- Iteration: 13\n",
      "XGBoost params. ETA: 0.04028406241827938, MAX_DEPTH: 2, SUBSAMPLE: 0.7301804030518279, COLSAMPLE_BY_TREE: 0.5508254789509297\n",
      "\n",
      "-- Iteration: 14\n",
      "XGBoost params. ETA: 0.03617273607658269, MAX_DEPTH: 5, SUBSAMPLE: 0.6340682509577085, COLSAMPLE_BY_TREE: 0.9152266627015204\n",
      "\n",
      "----------------\n",
      " Tag index: 1\n",
      "\n",
      "-- Iteration: 0\n",
      "XGBoost params. ETA: 0.04144630059934719, MAX_DEPTH: 2, SUBSAMPLE: 0.8608381638965238, COLSAMPLE_BY_TREE: 0.6646866411758835\n",
      "Best cv result:  test-logloss-mean     0.020719\n",
      "test-logloss-std      0.003679\n",
      "train-logloss-mean    0.007811\n",
      "train-logloss-std     0.000595\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2017, 'scale_pos_weight': 114.2, 'booster': 'gbtree', 'subsample': 0.8608381638965238, 'eta': 0.04144630059934719, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.6646866411758835, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 2}\n",
      "\n",
      "-- Iteration: 1\n",
      "XGBoost params. ETA: 0.023096741976626596, MAX_DEPTH: 2, SUBSAMPLE: 0.9294778786611162, COLSAMPLE_BY_TREE: 0.684612705671509\n",
      "\n",
      "-- Iteration: 2\n",
      "XGBoost params. ETA: 0.020594509346487103, MAX_DEPTH: 3, SUBSAMPLE: 0.8326168479972074, COLSAMPLE_BY_TREE: 0.8939410323228981\n",
      "Best cv result:  test-logloss-mean     0.019379\n",
      "test-logloss-std      0.002068\n",
      "train-logloss-mean    0.004422\n",
      "train-logloss-std     0.000326\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2020, 'scale_pos_weight': 114.2, 'booster': 'gbtree', 'subsample': 0.8326168479972074, 'eta': 0.020594509346487103, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.8939410323228981, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 3}\n",
      "\n",
      "-- Iteration: 3\n",
      "XGBoost params. ETA: 0.02653115436725616, MAX_DEPTH: 5, SUBSAMPLE: 0.8162897671482163, COLSAMPLE_BY_TREE: 0.5151974580887335\n",
      "Best cv result:  test-logloss-mean     0.017904\n",
      "test-logloss-std      0.004026\n",
      "train-logloss-mean    0.002297\n",
      "train-logloss-std     0.000264\n",
      "Name: 783, dtype: float64\n",
      "Best params:  {'seed': 2023, 'scale_pos_weight': 114.2, 'booster': 'gbtree', 'subsample': 0.8162897671482163, 'eta': 0.02653115436725616, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.5151974580887335, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 5}\n",
      "\n",
      "-- Iteration: 4\n",
      "XGBoost params. ETA: 0.0031731299894125695, MAX_DEPTH: 5, SUBSAMPLE: 0.6800766082244368, COLSAMPLE_BY_TREE: 0.9180867956437442\n",
      "\n",
      "-- Iteration: 5\n",
      "XGBoost params. ETA: 0.0069887935550004415, MAX_DEPTH: 5, SUBSAMPLE: 0.7007627562491288, COLSAMPLE_BY_TREE: 0.8127945000047486\n",
      "\n",
      "-- Iteration: 6\n",
      "XGBoost params. ETA: 0.024988972967877485, MAX_DEPTH: 5, SUBSAMPLE: 0.7387515922133331, COLSAMPLE_BY_TREE: 0.5829334344789511\n",
      "\n",
      "-- Iteration: 7\n",
      "XGBoost params. ETA: 0.019341114998370035, MAX_DEPTH: 5, SUBSAMPLE: 0.9267089554755925, COLSAMPLE_BY_TREE: 0.5455976440998712\n",
      "\n",
      "-- Iteration: 8\n",
      "XGBoost params. ETA: 0.02200964775463629, MAX_DEPTH: 2, SUBSAMPLE: 0.5765852508220348, COLSAMPLE_BY_TREE: 0.641941243761094\n",
      "\n",
      "-- Iteration: 9\n",
      "XGBoost params. ETA: 0.01959216312177087, MAX_DEPTH: 2, SUBSAMPLE: 0.69522483565335, COLSAMPLE_BY_TREE: 0.5249707473915985\n",
      "\n",
      "-- Iteration: 10\n",
      "XGBoost params. ETA: 0.0042383026863690235, MAX_DEPTH: 4, SUBSAMPLE: 0.9231953410445346, COLSAMPLE_BY_TREE: 0.777191690126488\n",
      "\n",
      "-- Iteration: 11\n",
      "XGBoost params. ETA: 0.0107439367380886, MAX_DEPTH: 5, SUBSAMPLE: 0.6636904286793001, COLSAMPLE_BY_TREE: 0.8394974530607874\n",
      "\n",
      "-- Iteration: 12\n",
      "XGBoost params. ETA: 0.03214890916462293, MAX_DEPTH: 4, SUBSAMPLE: 0.6630006836862006, COLSAMPLE_BY_TREE: 0.757752550842564\n",
      "\n",
      "-- Iteration: 13\n",
      "XGBoost params. ETA: 0.04028406241827938, MAX_DEPTH: 2, SUBSAMPLE: 0.7301804030518279, COLSAMPLE_BY_TREE: 0.5508254789509297\n",
      "\n",
      "-- Iteration: 14\n",
      "XGBoost params. ETA: 0.03617273607658269, MAX_DEPTH: 5, SUBSAMPLE: 0.6340682509577085, COLSAMPLE_BY_TREE: 0.9152266627015204\n",
      "\n",
      "----------------\n",
      " Tag index: 2\n",
      "\n",
      "-- Iteration: 0\n",
      "XGBoost params. ETA: 0.04144630059934719, MAX_DEPTH: 2, SUBSAMPLE: 0.8608381638965238, COLSAMPLE_BY_TREE: 0.6646866411758835\n",
      "Best cv result:  test-logloss-mean     0.221659\n",
      "test-logloss-std      0.003985\n",
      "train-logloss-mean    0.196590\n",
      "train-logloss-std     0.004302\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2017, 'scale_pos_weight': 43.849833147942157, 'booster': 'gbtree', 'subsample': 0.8608381638965238, 'eta': 0.04144630059934719, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.6646866411758835, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 2}\n",
      "\n",
      "-- Iteration: 1\n",
      "XGBoost params. ETA: 0.023096741976626596, MAX_DEPTH: 2, SUBSAMPLE: 0.9294778786611162, COLSAMPLE_BY_TREE: 0.684612705671509\n",
      "\n",
      "-- Iteration: 2\n",
      "XGBoost params. ETA: 0.020594509346487103, MAX_DEPTH: 3, SUBSAMPLE: 0.8326168479972074, COLSAMPLE_BY_TREE: 0.8939410323228981\n",
      "Best cv result:  test-logloss-mean     0.195541\n",
      "test-logloss-std      0.004818\n",
      "train-logloss-mean    0.168027\n",
      "train-logloss-std     0.005118\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2020, 'scale_pos_weight': 43.849833147942157, 'booster': 'gbtree', 'subsample': 0.8326168479972074, 'eta': 0.020594509346487103, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.8939410323228981, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 3}\n",
      "\n",
      "-- Iteration: 3\n",
      "XGBoost params. ETA: 0.02653115436725616, MAX_DEPTH: 5, SUBSAMPLE: 0.8162897671482163, COLSAMPLE_BY_TREE: 0.5151974580887335\n",
      "Best cv result:  test-logloss-mean     0.098508\n",
      "test-logloss-std      0.002563\n",
      "train-logloss-mean    0.034253\n",
      "train-logloss-std     0.001150\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2023, 'scale_pos_weight': 43.849833147942157, 'booster': 'gbtree', 'subsample': 0.8162897671482163, 'eta': 0.02653115436725616, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.5151974580887335, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 5}\n",
      "\n",
      "-- Iteration: 4\n",
      "XGBoost params. ETA: 0.0031731299894125695, MAX_DEPTH: 5, SUBSAMPLE: 0.6800766082244368, COLSAMPLE_BY_TREE: 0.9180867956437442\n",
      "\n",
      "-- Iteration: 5\n",
      "XGBoost params. ETA: 0.0069887935550004415, MAX_DEPTH: 5, SUBSAMPLE: 0.7007627562491288, COLSAMPLE_BY_TREE: 0.8127945000047486\n",
      "\n",
      "-- Iteration: 6\n",
      "XGBoost params. ETA: 0.024988972967877485, MAX_DEPTH: 5, SUBSAMPLE: 0.7387515922133331, COLSAMPLE_BY_TREE: 0.5829334344789511\n",
      "\n",
      "-- Iteration: 7\n",
      "XGBoost params. ETA: 0.019341114998370035, MAX_DEPTH: 5, SUBSAMPLE: 0.9267089554755925, COLSAMPLE_BY_TREE: 0.5455976440998712\n",
      "\n",
      "-- Iteration: 8\n",
      "XGBoost params. ETA: 0.02200964775463629, MAX_DEPTH: 2, SUBSAMPLE: 0.5765852508220348, COLSAMPLE_BY_TREE: 0.641941243761094\n",
      "\n",
      "-- Iteration: 9\n",
      "XGBoost params. ETA: 0.01959216312177087, MAX_DEPTH: 2, SUBSAMPLE: 0.69522483565335, COLSAMPLE_BY_TREE: 0.5249707473915985\n",
      "\n",
      "-- Iteration: 10\n",
      "XGBoost params. ETA: 0.0042383026863690235, MAX_DEPTH: 4, SUBSAMPLE: 0.9231953410445346, COLSAMPLE_BY_TREE: 0.777191690126488\n",
      "\n",
      "-- Iteration: 11\n",
      "XGBoost params. ETA: 0.0107439367380886, MAX_DEPTH: 5, SUBSAMPLE: 0.6636904286793001, COLSAMPLE_BY_TREE: 0.8394974530607874\n",
      "\n",
      "-- Iteration: 12\n",
      "XGBoost params. ETA: 0.03214890916462293, MAX_DEPTH: 4, SUBSAMPLE: 0.6630006836862006, COLSAMPLE_BY_TREE: 0.757752550842564\n",
      "\n",
      "-- Iteration: 13\n",
      "XGBoost params. ETA: 0.04028406241827938, MAX_DEPTH: 2, SUBSAMPLE: 0.7301804030518279, COLSAMPLE_BY_TREE: 0.5508254789509297\n",
      "\n",
      "-- Iteration: 14\n",
      "XGBoost params. ETA: 0.03617273607658269, MAX_DEPTH: 5, SUBSAMPLE: 0.6340682509577085, COLSAMPLE_BY_TREE: 0.9152266627015204\n",
      "Best cv result:  test-logloss-mean     0.095615\n",
      "test-logloss-std      0.004706\n",
      "train-logloss-mean    0.013333\n",
      "train-logloss-std     0.000482\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2122, 'scale_pos_weight': 43.849833147942157, 'booster': 'gbtree', 'subsample': 0.6340682509577085, 'eta': 0.03617273607658269, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.9152266627015204, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 5}\n",
      "\n",
      "----------------\n",
      " Tag index: 3\n",
      "\n",
      "-- Iteration: 0\n",
      "XGBoost params. ETA: 0.04144630059934719, MAX_DEPTH: 2, SUBSAMPLE: 0.8608381638965238, COLSAMPLE_BY_TREE: 0.6646866411758835\n",
      "Best cv result:  test-logloss-mean     0.115228\n",
      "test-logloss-std      0.001973\n",
      "train-logloss-mean    0.095366\n",
      "train-logloss-std     0.004766\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2017, 'scale_pos_weight': 124.21739130434783, 'booster': 'gbtree', 'subsample': 0.8608381638965238, 'eta': 0.04144630059934719, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.6646866411758835, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 2}\n",
      "\n",
      "-- Iteration: 1\n",
      "XGBoost params. ETA: 0.023096741976626596, MAX_DEPTH: 2, SUBSAMPLE: 0.9294778786611162, COLSAMPLE_BY_TREE: 0.684612705671509\n",
      "\n",
      "-- Iteration: 2\n",
      "XGBoost params. ETA: 0.020594509346487103, MAX_DEPTH: 3, SUBSAMPLE: 0.8326168479972074, COLSAMPLE_BY_TREE: 0.8939410323228981\n",
      "Best cv result:  test-logloss-mean     0.097231\n",
      "test-logloss-std      0.005099\n",
      "train-logloss-mean    0.074486\n",
      "train-logloss-std     0.003989\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2020, 'scale_pos_weight': 124.21739130434783, 'booster': 'gbtree', 'subsample': 0.8326168479972074, 'eta': 0.020594509346487103, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.8939410323228981, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 3}\n",
      "\n",
      "-- Iteration: 3\n",
      "XGBoost params. ETA: 0.02653115436725616, MAX_DEPTH: 5, SUBSAMPLE: 0.8162897671482163, COLSAMPLE_BY_TREE: 0.5151974580887335\n",
      "Best cv result:  test-logloss-mean     0.042778\n",
      "test-logloss-std      0.002957\n",
      "train-logloss-mean    0.005431\n",
      "train-logloss-std     0.000186\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2023, 'scale_pos_weight': 124.21739130434783, 'booster': 'gbtree', 'subsample': 0.8162897671482163, 'eta': 0.02653115436725616, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.5151974580887335, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 5}\n",
      "\n",
      "-- Iteration: 4\n",
      "XGBoost params. ETA: 0.0031731299894125695, MAX_DEPTH: 5, SUBSAMPLE: 0.6800766082244368, COLSAMPLE_BY_TREE: 0.9180867956437442\n",
      "\n",
      "-- Iteration: 5\n",
      "XGBoost params. ETA: 0.0069887935550004415, MAX_DEPTH: 5, SUBSAMPLE: 0.7007627562491288, COLSAMPLE_BY_TREE: 0.8127945000047486\n",
      "\n",
      "-- Iteration: 6\n",
      "XGBoost params. ETA: 0.024988972967877485, MAX_DEPTH: 5, SUBSAMPLE: 0.7387515922133331, COLSAMPLE_BY_TREE: 0.5829334344789511\n",
      "\n",
      "-- Iteration: 7\n",
      "XGBoost params. ETA: 0.019341114998370035, MAX_DEPTH: 5, SUBSAMPLE: 0.9267089554755925, COLSAMPLE_BY_TREE: 0.5455976440998712\n",
      "\n",
      "-- Iteration: 8\n",
      "XGBoost params. ETA: 0.02200964775463629, MAX_DEPTH: 2, SUBSAMPLE: 0.5765852508220348, COLSAMPLE_BY_TREE: 0.641941243761094\n",
      "\n",
      "-- Iteration: 9\n",
      "XGBoost params. ETA: 0.01959216312177087, MAX_DEPTH: 2, SUBSAMPLE: 0.69522483565335, COLSAMPLE_BY_TREE: 0.5249707473915985\n",
      "\n",
      "-- Iteration: 10\n",
      "XGBoost params. ETA: 0.0042383026863690235, MAX_DEPTH: 4, SUBSAMPLE: 0.9231953410445346, COLSAMPLE_BY_TREE: 0.777191690126488\n",
      "\n",
      "-- Iteration: 11\n",
      "XGBoost params. ETA: 0.0107439367380886, MAX_DEPTH: 5, SUBSAMPLE: 0.6636904286793001, COLSAMPLE_BY_TREE: 0.8394974530607874\n",
      "\n",
      "-- Iteration: 12\n",
      "XGBoost params. ETA: 0.03214890916462293, MAX_DEPTH: 4, SUBSAMPLE: 0.6630006836862006, COLSAMPLE_BY_TREE: 0.757752550842564\n",
      "\n",
      "-- Iteration: 13\n",
      "XGBoost params. ETA: 0.04028406241827938, MAX_DEPTH: 2, SUBSAMPLE: 0.7301804030518279, COLSAMPLE_BY_TREE: 0.5508254789509297\n",
      "\n",
      "-- Iteration: 14\n",
      "XGBoost params. ETA: 0.03617273607658269, MAX_DEPTH: 5, SUBSAMPLE: 0.6340682509577085, COLSAMPLE_BY_TREE: 0.9152266627015204\n",
      "\n",
      "----------------\n",
      " Tag index: 4\n",
      "\n",
      "-- Iteration: 0\n",
      "XGBoost params. ETA: 0.04144630059934719, MAX_DEPTH: 2, SUBSAMPLE: 0.8608381638965238, COLSAMPLE_BY_TREE: 0.6646866411758835\n",
      "Best cv result:  test-logloss-mean     0.027645\n",
      "test-logloss-std      0.001991\n",
      "train-logloss-mean    0.014610\n",
      "train-logloss-std     0.001396\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2017, 'scale_pos_weight': 437.26086956521738, 'booster': 'gbtree', 'subsample': 0.8608381638965238, 'eta': 0.04144630059934719, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.6646866411758835, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 2}\n",
      "\n",
      "-- Iteration: 1\n",
      "XGBoost params. ETA: 0.023096741976626596, MAX_DEPTH: 2, SUBSAMPLE: 0.9294778786611162, COLSAMPLE_BY_TREE: 0.684612705671509\n",
      "\n",
      "-- Iteration: 2\n",
      "XGBoost params. ETA: 0.020594509346487103, MAX_DEPTH: 3, SUBSAMPLE: 0.8326168479972074, COLSAMPLE_BY_TREE: 0.8939410323228981\n",
      "Best cv result:  test-logloss-mean     0.023420\n",
      "test-logloss-std      0.002907\n",
      "train-logloss-mean    0.010370\n",
      "train-logloss-std     0.002611\n",
      "Name: 1999, dtype: float64\n",
      "Best params:  {'seed': 2020, 'scale_pos_weight': 437.26086956521738, 'booster': 'gbtree', 'subsample': 0.8326168479972074, 'eta': 0.020594509346487103, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.8939410323228981, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 3}\n",
      "\n",
      "-- Iteration: 3\n",
      "XGBoost params. ETA: 0.02653115436725616, MAX_DEPTH: 5, SUBSAMPLE: 0.8162897671482163, COLSAMPLE_BY_TREE: 0.5151974580887335\n",
      "Best cv result:  test-logloss-mean     0.016297\n",
      "test-logloss-std      0.001485\n",
      "train-logloss-mean    0.001687\n",
      "train-logloss-std     0.000198\n",
      "Name: 1096, dtype: float64\n",
      "Best params:  {'seed': 2023, 'scale_pos_weight': 437.26086956521738, 'booster': 'gbtree', 'subsample': 0.8162897671482163, 'eta': 0.02653115436725616, 'silent': 1, 'objective': 'binary:logistic', 'colsample_bytree': 0.5151974580887335, 'tree_method': 'exact', 'eval_metric': 'logloss', 'max_depth': 5}\n",
      "\n",
      "-- Iteration: 4\n",
      "XGBoost params. ETA: 0.0031731299894125695, MAX_DEPTH: 5, SUBSAMPLE: 0.6800766082244368, COLSAMPLE_BY_TREE: 0.9180867956437442\n",
      "\n",
      "-- Iteration: 5\n",
      "XGBoost params. ETA: 0.0069887935550004415, MAX_DEPTH: 5, SUBSAMPLE: 0.7007627562491288, COLSAMPLE_BY_TREE: 0.8127945000047486\n",
      "\n",
      "-- Iteration: 6\n",
      "XGBoost params. ETA: 0.024988972967877485, MAX_DEPTH: 5, SUBSAMPLE: 0.7387515922133331, COLSAMPLE_BY_TREE: 0.5829334344789511\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-94dc298ea805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m                            \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                            \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                            early_stopping_rounds=early_stopping_rounds, nfold=n_folds, verbose_eval=False)\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mmin_test_logloss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test-%s-mean'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vfomin/Documents/ML/xgboost/python-package/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    405\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vfomin/Documents/ML/xgboost/python-package/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vfomin/Documents/ML/xgboost/python-package/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#eta_values = [0.05, 0.025, 0.01, 0.0075, 0.005, 0.0025, 0.001]\n",
    "\n",
    "eval_metric = 'logloss'\n",
    "\n",
    "\n",
    "best_params_for_tag_index = {}\n",
    "for tag_index in range(0, len(unique_tags)):\n",
    "    \n",
    "    print(\"\\n----------------\\n Tag index: {}\".format(tag_index))    \n",
    "    seed = 2017\n",
    "    n_folds = 5\n",
    "    dtrainval = xgb.DMatrix(trainval_x, label=trainval_y[:, tag_index], feature_names=unique_tags)\n",
    "\n",
    "    best_params_for_tag_index[tag_index] = {\n",
    "        'test-%s-mean' % eval_metric: 1e10,\n",
    "        'params': None,\n",
    "    }\n",
    "    \n",
    "    sumpw = val_predictions_df[target_tags[tag_index]].sum()\n",
    "    sumnw = len(val_predictions_df[target_tags[tag_index]]) - sumpw    \n",
    "    scale_pos_weight = sumnw * 1.0 / sumpw\n",
    "    \n",
    "    iter_num = 15\n",
    "#     iter_num = -1   \n",
    "    gen = generate_params(iter_num)\n",
    "    z = 0\n",
    "    for (eta, max_depth, subsample, colsample_bytree) in gen:\n",
    "        z += 1\n",
    "        seed += z-1\n",
    "        print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth,subsample,colsample_bytree))\n",
    "        params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"booster\": \"gbtree\",\n",
    "            \"eval_metric\": eval_metric\n",
    "            ,\n",
    "            \"eta\": eta,\n",
    "            \"tree_method\": 'exact',\n",
    "            \"max_depth\": max_depth,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"silent\": 1,\n",
    "            \"seed\": seed, \n",
    "            \"scale_pos_weight\": scale_pos_weight,\n",
    "        }\n",
    "        num_boost_round = 2000\n",
    "        early_stopping_rounds = 100\n",
    "\n",
    "        cvresult = xgb.cv(params, dtrain=dtrainval,\n",
    "                           seed=params['seed'], \n",
    "                           num_boost_round=num_boost_round, \n",
    "                           early_stopping_rounds=early_stopping_rounds, nfold=n_folds, verbose_eval=False)\n",
    "                \n",
    "        min_test_logloss_mean = cvresult['test-%s-mean' % params['eval_metric']].min()\n",
    "        if best_params_for_tag_index[tag_index]['test-%s-mean' % params['eval_metric']] > min_test_logloss_mean:\n",
    "            best_params_for_tag_index[tag_index]['test-%s-mean' % params['eval_metric']] = min_test_logloss_mean\n",
    "            best_params_for_tag_index[tag_index]['params'] = params\n",
    "            print(\"Best cv result: \", cvresult.loc[cvresult.index[-1], :])\n",
    "            print(\"Best params: \", params)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "now = datetime.now()\n",
    "\n",
    "xgb_best_params_filepath = os.path.join(GENERATED_DATA, 'xgb_best_params_%s.pkl' % str(now.strftime(\"%Y-%m-%d-%H-%M\")))\n",
    "\n",
    "with open(xgb_best_params_filepath, 'wb') as handle:\n",
    "    pickle.dump(best_params_for_tag_index, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params_for_tag_index = _best_params_for_tag_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 17 binary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------\n",
      " Tag index: 0\n",
      "Best score:  0.108135\n",
      "\n",
      "----------------\n",
      " Tag index: 1\n",
      "Best score:  0.010417\n",
      "\n",
      "----------------\n",
      " Tag index: 2\n",
      "Best score:  0.166832\n",
      "\n",
      "----------------\n",
      " Tag index: 3\n",
      "Best score:  0.08168\n",
      "\n",
      "----------------\n",
      " Tag index: 4\n",
      "Best score:  0.062996\n",
      "\n",
      "----------------\n",
      " Tag index: 5\n",
      "Best score:  0.053406\n",
      "\n",
      "----------------\n",
      " Tag index: 6\n",
      "Best score:  0.022817\n",
      "\n",
      "----------------\n",
      " Tag index: 7\n",
      "Best score:  0.034226\n",
      "\n",
      "----------------\n",
      " Tag index: 8\n",
      "Best score:  0.205192\n",
      "\n",
      "----------------\n",
      " Tag index: 9\n",
      "Best score:  0.095734\n",
      "\n",
      "----------------\n",
      " Tag index: 10\n",
      "Best score:  0.084821\n",
      "\n",
      "----------------\n",
      " Tag index: 11\n",
      "Best score:  0.03588\n",
      "\n",
      "----------------\n",
      " Tag index: 12\n",
      "Best score:  0.058036\n",
      "\n",
      "----------------\n",
      " Tag index: 13\n",
      "Best score:  0.092097\n",
      "\n",
      "----------------\n",
      " Tag index: 14\n",
      "Best score:  0.076058\n",
      "\n",
      "----------------\n",
      " Tag index: 15\n",
      "Best score:  0.168485\n",
      "\n",
      "----------------\n",
      " Tag index: 16\n",
      "Best score:  0.100198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for tag_index in range(len(unique_tags)):\n",
    "    \n",
    "    print(\"\\n----------------\\n Tag index: {}\".format(tag_index))\n",
    "    train_x, val_x, train_y, val_y = train_test_split(trainval_x, trainval_y, train_size=0.85)\n",
    "    dtrain = xgb.DMatrix(train_x, train_y[:, tag_index])\n",
    "    dval = xgb.DMatrix(val_x, val_y[:, tag_index])\n",
    "    watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "    params = best_params_for_tag_index[tag_index]['params']\n",
    "    num_boost_round = 2500    \n",
    "    early_stopping_rounds = 12\n",
    "\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=False)                \n",
    "    print(\"Best score: \", gbm.best_score)\n",
    "    best_params_for_tag_index[tag_index]['gbm'] = gbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute best thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agriculture | best threshold : 0.490000 with score: 0.893838\n",
      "artisinal_mine | best threshold : 0.540000 with score: 0.800101\n",
      "bare_ground | best threshold : 0.650000 with score: 0.481097\n",
      "blooming | best threshold : 0.580000 with score: 0.348643\n",
      "blow_down | best threshold : 0.530000 with score: 0.152452\n",
      "clear | best threshold : 0.220000 with score: 0.979285\n",
      "cloudy | best threshold : 0.630000 with score: 0.916326\n",
      "conventional_mine | best threshold : 0.540000 with score: 0.325991\n",
      "cultivation | best threshold : 0.520000 with score: 0.688206\n",
      "habitation | best threshold : 0.520000 with score: 0.780279\n",
      "haze | best threshold : 0.530000 with score: 0.778034\n",
      "partly_cloudy | best threshold : 0.500000 with score: 0.949168\n",
      "primary | best threshold : 0.250000 with score: 0.990040\n",
      "road | best threshold : 0.500000 with score: 0.861935\n",
      "selective_logging | best threshold : 0.710000 with score: 0.462641\n",
      "slash_burn | best threshold : 0.540000 with score: 0.221661\n",
      "water | best threshold : 0.450000 with score: 0.823585\n"
     ]
    }
   ],
   "source": [
    "best_thresholds = {}\n",
    "\n",
    "for tag_index, tag in enumerate(unique_tags):\n",
    "        \n",
    "    dmat = xgb.DMatrix(trainval_x)\n",
    "    gbm = best_params_for_tag_index[tag_index]['gbm']\n",
    "    y_preds_ = gbm.predict(dmat, ntree_limit=gbm.best_iteration+1)        \n",
    "    \n",
    "    best_thresholds[tag], best_score = search_best_threshold(y_true[:, tag_index], y_preds_)\n",
    "    print(\"%s | best threshold : %f with score: %f\" % (tag, best_thresholds[tag], best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boost test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_csv = glob(os.path.join(OUTPUT_PATH, \"predictions_*2017-07-13-19-21.csv\"))\n",
    "\n",
    "prediction_df = pd.read_csv(predictions_csv[0]).dropna()\n",
    "for filepath in predictions_csv[1:]:\n",
    "    prediction_df = pd.concat([prediction_df, pd.read_csv(filepath).dropna()])\n",
    "prediction_df.reset_index(inplace=True)   \n",
    "prediction_df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>blooming</th>\n",
       "      <th>blow_down</th>\n",
       "      <th>clear</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>habitation</th>\n",
       "      <th>haze</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>primary</th>\n",
       "      <th>road</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_40308</td>\n",
       "      <td>0.980499</td>\n",
       "      <td>5.343570e-06</td>\n",
       "      <td>0.012761</td>\n",
       "      <td>1.083201e-06</td>\n",
       "      <td>1.659149e-05</td>\n",
       "      <td>0.026706</td>\n",
       "      <td>6.184839e-06</td>\n",
       "      <td>1.213845e-04</td>\n",
       "      <td>0.247138</td>\n",
       "      <td>0.230338</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.955976</td>\n",
       "      <td>0.994307</td>\n",
       "      <td>0.509100</td>\n",
       "      <td>6.428061e-05</td>\n",
       "      <td>5.902686e-03</td>\n",
       "      <td>0.049497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_36168</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>1.964079e-09</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>4.806151e-04</td>\n",
       "      <td>5.747763e-05</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>1.741330e-08</td>\n",
       "      <td>7.339324e-10</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>2.039154e-04</td>\n",
       "      <td>6.675383e-07</td>\n",
       "      <td>0.004990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_6070</td>\n",
       "      <td>0.998530</td>\n",
       "      <td>1.298099e-10</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>1.012986e-10</td>\n",
       "      <td>1.425290e-09</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>2.468224e-13</td>\n",
       "      <td>2.351865e-06</td>\n",
       "      <td>0.095436</td>\n",
       "      <td>0.819567</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.947903</td>\n",
       "      <td>0.991666</td>\n",
       "      <td>2.751586e-07</td>\n",
       "      <td>2.056249e-04</td>\n",
       "      <td>0.032477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_5483</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>3.214428e-09</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>3.451585e-02</td>\n",
       "      <td>1.510115e-03</td>\n",
       "      <td>0.997953</td>\n",
       "      <td>1.104697e-08</td>\n",
       "      <td>2.678857e-10</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>3.596786e-03</td>\n",
       "      <td>6.073845e-07</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_5532</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>6.949826e-08</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>1.529595e-01</td>\n",
       "      <td>6.396817e-03</td>\n",
       "      <td>0.998306</td>\n",
       "      <td>3.806774e-08</td>\n",
       "      <td>3.966572e-09</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>2.929822e-02</td>\n",
       "      <td>2.036211e-06</td>\n",
       "      <td>0.003847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_name  agriculture  artisinal_mine  bare_ground      blooming  \\\n",
       "0  test_40308     0.980499    5.343570e-06     0.012761  1.083201e-06   \n",
       "1  test_36168     0.008954    1.964079e-09     0.000126  4.806151e-04   \n",
       "2   test_6070     0.998530    1.298099e-10     0.004025  1.012986e-10   \n",
       "3   test_5483     0.003073    3.214428e-09     0.000053  3.451585e-02   \n",
       "4   test_5532     0.004007    6.949826e-08     0.000144  1.529595e-01   \n",
       "\n",
       "      blow_down     clear        cloudy  conventional_mine  cultivation  \\\n",
       "0  1.659149e-05  0.026706  6.184839e-06       1.213845e-04     0.247138   \n",
       "1  5.747763e-05  0.990458  1.741330e-08       7.339324e-10     0.002185   \n",
       "2  1.425290e-09  0.999737  2.468224e-13       2.351865e-06     0.095436   \n",
       "3  1.510115e-03  0.997953  1.104697e-08       2.678857e-10     0.001081   \n",
       "4  6.396817e-03  0.998306  3.806774e-08       3.966572e-09     0.001861   \n",
       "\n",
       "   habitation      haze  partly_cloudy   primary      road  selective_logging  \\\n",
       "0    0.230338  0.002780       0.955976  0.994307  0.509100       6.428061e-05   \n",
       "1    0.001168  0.006540       0.000672  0.999985  0.002998       2.039154e-04   \n",
       "2    0.819567  0.000283       0.000036  0.947903  0.991666       2.751586e-07   \n",
       "3    0.000312  0.000302       0.001118  0.999984  0.001043       3.596786e-03   \n",
       "4    0.000672  0.000304       0.000979  0.999972  0.002848       2.929822e-02   \n",
       "\n",
       "     slash_burn     water  \n",
       "0  5.902686e-03  0.049497  \n",
       "1  6.675383e-07  0.004990  \n",
       "2  2.056249e-04  0.032477  \n",
       "3  6.073845e-07  0.002270  \n",
       "4  2.036211e-06  0.003847  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------\n",
      " Tag index: 0\n",
      "\n",
      "----------------\n",
      " Tag index: 1\n",
      "\n",
      "----------------\n",
      " Tag index: 2\n",
      "\n",
      "----------------\n",
      " Tag index: 3\n",
      "\n",
      "----------------\n",
      " Tag index: 4\n",
      "\n",
      "----------------\n",
      " Tag index: 5\n",
      "\n",
      "----------------\n",
      " Tag index: 6\n",
      "\n",
      "----------------\n",
      " Tag index: 7\n",
      "\n",
      "----------------\n",
      " Tag index: 8\n",
      "\n",
      "----------------\n",
      " Tag index: 9\n",
      "\n",
      "----------------\n",
      " Tag index: 10\n",
      "\n",
      "----------------\n",
      " Tag index: 11\n",
      "\n",
      "----------------\n",
      " Tag index: 12\n",
      "\n",
      "----------------\n",
      " Tag index: 13\n",
      "\n",
      "----------------\n",
      " Tag index: 14\n",
      "\n",
      "----------------\n",
      " Tag index: 15\n",
      "\n",
      "----------------\n",
      " Tag index: 16\n"
     ]
    }
   ],
   "source": [
    "y_preds_init = prediction_df[unique_tags].values\n",
    "y_preds = np.zeros_like(y_preds_init)\n",
    "\n",
    "for tag_index in range(len(unique_tags)):\n",
    "    \n",
    "    print(\"\\n----------------\\n Tag index: {}\".format(tag_index))\n",
    "    dtest = xgb.DMatrix(y_preds_init)\n",
    "    gbm = best_params_for_tag_index[tag_index]['gbm']\n",
    "    y_preds_ = gbm.predict(dtest, ntree_limit=gbm.best_iteration+1)        \n",
    "    y_preds[:, tag_index] = y_preds_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = prediction_df.copy()\n",
    "df[unique_tags] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>blooming</th>\n",
       "      <th>blow_down</th>\n",
       "      <th>clear</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>habitation</th>\n",
       "      <th>haze</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>primary</th>\n",
       "      <th>road</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_40308</td>\n",
       "      <td>0.522231</td>\n",
       "      <td>0.45251</td>\n",
       "      <td>0.252149</td>\n",
       "      <td>0.389114</td>\n",
       "      <td>0.455467</td>\n",
       "      <td>0.161270</td>\n",
       "      <td>0.123053</td>\n",
       "      <td>0.455544</td>\n",
       "      <td>0.522468</td>\n",
       "      <td>0.544217</td>\n",
       "      <td>0.443230</td>\n",
       "      <td>0.866382</td>\n",
       "      <td>0.750729</td>\n",
       "      <td>0.503381</td>\n",
       "      <td>0.268825</td>\n",
       "      <td>0.499394</td>\n",
       "      <td>0.248423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_36168</td>\n",
       "      <td>0.477120</td>\n",
       "      <td>0.45251</td>\n",
       "      <td>0.159650</td>\n",
       "      <td>0.389114</td>\n",
       "      <td>0.455467</td>\n",
       "      <td>0.807806</td>\n",
       "      <td>0.122661</td>\n",
       "      <td>0.455544</td>\n",
       "      <td>0.391684</td>\n",
       "      <td>0.410128</td>\n",
       "      <td>0.443108</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.729628</td>\n",
       "      <td>0.494106</td>\n",
       "      <td>0.260546</td>\n",
       "      <td>0.451676</td>\n",
       "      <td>0.141758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_6070</td>\n",
       "      <td>0.522231</td>\n",
       "      <td>0.45251</td>\n",
       "      <td>0.222007</td>\n",
       "      <td>0.389114</td>\n",
       "      <td>0.455467</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.132560</td>\n",
       "      <td>0.455544</td>\n",
       "      <td>0.527279</td>\n",
       "      <td>0.583079</td>\n",
       "      <td>0.440586</td>\n",
       "      <td>0.190396</td>\n",
       "      <td>0.609088</td>\n",
       "      <td>0.505878</td>\n",
       "      <td>0.259275</td>\n",
       "      <td>0.451676</td>\n",
       "      <td>0.238310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_5483</td>\n",
       "      <td>0.477120</td>\n",
       "      <td>0.45251</td>\n",
       "      <td>0.158208</td>\n",
       "      <td>0.533957</td>\n",
       "      <td>0.478718</td>\n",
       "      <td>0.837238</td>\n",
       "      <td>0.122661</td>\n",
       "      <td>0.455544</td>\n",
       "      <td>0.391450</td>\n",
       "      <td>0.412522</td>\n",
       "      <td>0.435470</td>\n",
       "      <td>0.134498</td>\n",
       "      <td>0.761620</td>\n",
       "      <td>0.494106</td>\n",
       "      <td>0.327320</td>\n",
       "      <td>0.451676</td>\n",
       "      <td>0.127105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_5532</td>\n",
       "      <td>0.477120</td>\n",
       "      <td>0.45251</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>0.601405</td>\n",
       "      <td>0.455475</td>\n",
       "      <td>0.837238</td>\n",
       "      <td>0.122661</td>\n",
       "      <td>0.455544</td>\n",
       "      <td>0.404547</td>\n",
       "      <td>0.414466</td>\n",
       "      <td>0.435470</td>\n",
       "      <td>0.135214</td>\n",
       "      <td>0.761620</td>\n",
       "      <td>0.494106</td>\n",
       "      <td>0.620745</td>\n",
       "      <td>0.451676</td>\n",
       "      <td>0.132539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_name  agriculture  artisinal_mine  bare_ground  blooming  blow_down  \\\n",
       "0  test_40308     0.522231         0.45251     0.252149  0.389114   0.455467   \n",
       "1  test_36168     0.477120         0.45251     0.159650  0.389114   0.455467   \n",
       "2   test_6070     0.522231         0.45251     0.222007  0.389114   0.455467   \n",
       "3   test_5483     0.477120         0.45251     0.158208  0.533957   0.478718   \n",
       "4   test_5532     0.477120         0.45251     0.161170  0.601405   0.455475   \n",
       "\n",
       "      clear    cloudy  conventional_mine  cultivation  habitation      haze  \\\n",
       "0  0.161270  0.123053           0.455544     0.522468    0.544217  0.443230   \n",
       "1  0.807806  0.122661           0.455544     0.391684    0.410128  0.443108   \n",
       "2  0.830000  0.132560           0.455544     0.527279    0.583079  0.440586   \n",
       "3  0.837238  0.122661           0.455544     0.391450    0.412522  0.435470   \n",
       "4  0.837238  0.122661           0.455544     0.404547    0.414466  0.435470   \n",
       "\n",
       "   partly_cloudy   primary      road  selective_logging  slash_burn     water  \n",
       "0       0.866382  0.750729  0.503381           0.268825    0.499394  0.248423  \n",
       "1       0.136900  0.729628  0.494106           0.260546    0.451676  0.141758  \n",
       "2       0.190396  0.609088  0.505878           0.259275    0.451676  0.238310  \n",
       "3       0.134498  0.761620  0.494106           0.327320    0.451676  0.127105  \n",
       "4       0.135214  0.761620  0.494106           0.620745    0.451676  0.132539  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mean(df):\n",
    "    gb = df.groupby('image_name')\n",
    "    df2 = gb.agg(np.mean).reset_index()\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_df = compute_mean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61191, 183573)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_df), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission(mean_df, info=\"squeezenet21_blended_3_folds\", thresholds=best_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_best_params_for_tag_index = {\n",
    "0: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.9097441644531741,\n",
    "'eta': 0.012063976013602831,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 3,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 2.2953291651342407,\n",
    "'seed': 2027,\n",
    "'silent': 1,\n",
    "'subsample': 0.8135263419352342,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.18432560000000001},\n",
    "1: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.9247718213959808,\n",
    "'eta': 0.048774868242772856,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 119.17883755588673,\n",
    "'seed': 2045,\n",
    "'silent': 1,\n",
    "'subsample': 0.8232135887360947,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.0096606000000000018},\n",
    "2: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.8393513697801558,\n",
    "'eta': 0.04965712898037271,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 45.478386167146972,\n",
    "'seed': 2083,\n",
    "'silent': 1,\n",
    "'subsample': 0.766586509402208,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.035527999999999997},\n",
    "3: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.8393513697801558,\n",
    "'eta': 0.04965712898037271,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 117.76288659793815,\n",
    "'seed': 2083,\n",
    "'silent': 1,\n",
    "'subsample': 0.766586509402208,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.0097225999999999996},\n",
    "4: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.5079279690320685,\n",
    "'eta': 0.04557168327562415,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 404.22613065326635,\n",
    "'seed': 2108,\n",
    "'silent': 1,\n",
    "'subsample': 0.8351662492654948,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.00248},\n",
    "5: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.8393513697801558,\n",
    "'eta': 0.04965712898037271,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 0.42622167984294584,\n",
    "'seed': 2083,\n",
    "'silent': 1,\n",
    "'subsample': 0.766586509402208,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.13793419999999998},\n",
    "6: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.8393513697801558,\n",
    "'eta': 0.04965712898037271,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 18.122599004031301,\n",
    "'seed': 2083,\n",
    "'silent': 1,\n",
    "'subsample': 0.766586509402208,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.032638800000000003},\n",
    "7: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.5079279690320685,\n",
    "'eta': 0.04557168327562415,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 383.0,\n",
    "'seed': 2108,\n",
    "'silent': 1,\n",
    "'subsample': 0.8351662492654948,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.0027032000000000002},\n",
    "8: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.8393513697801558,\n",
    "'eta': 0.04965712898037271,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 8.2033782241497377,\n",
    "'seed': 2083,\n",
    "'silent': 1,\n",
    "'subsample': 0.766586509402208,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.22521079999999999},\n",
    "9: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.8393513697801558,\n",
    "'eta': 0.04965712898037271,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 10.04960263085777,\n",
    "'seed': 2083,\n",
    "'silent': 1,\n",
    "'subsample': 0.766586509402208,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.1460564},\n",
    "10: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.5079279690320685,\n",
    "'eta': 0.04557168327562415,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 13.936099277644008,\n",
    "'seed': 2108,\n",
    "'silent': 1,\n",
    "'subsample': 0.8351662492654948,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.065190800000000007},\n",
    "11: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.8393513697801558,\n",
    "'eta': 0.04965712898037271,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 4.569060773480663,\n",
    "'seed': 2083,\n",
    "'silent': 1,\n",
    "'subsample': 0.766586509402208,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.1443574},\n",
    "12: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.8393513697801558,\n",
    "'eta': 0.04965712898037271,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 0.080400326906844941,\n",
    "'seed': 2083,\n",
    "'silent': 1,\n",
    "'subsample': 0.766586509402208,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.065996799999999994},\n",
    "13: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.9097441644531741,\n",
    "'eta': 0.012063976013602831,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 3,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 4.051049170059505,\n",
    "'seed': 2027,\n",
    "'silent': 1,\n",
    "'subsample': 0.8135263419352342,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.17645080000000002},\n",
    "14: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.9247718213959808,\n",
    "'eta': 0.048774868242772856,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 124.21739130434783,\n",
    "'seed': 2045,\n",
    "'silent': 1,\n",
    "'subsample': 0.8232135887360947,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.0087554},\n",
    "15: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.8393513697801558,\n",
    "'eta': 0.04965712898037271,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 207.9119170984456,\n",
    "'seed': 2083,\n",
    "'silent': 1,\n",
    "'subsample': 0.766586509402208,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.0049351999999999998},\n",
    "16: {'params': {'booster': 'gbtree',\n",
    "'colsample_bytree': 0.8393513697801558,\n",
    "'eta': 0.04965712898037271,\n",
    "'eval_metric': 'error',\n",
    "'max_depth': 5,\n",
    "'objective': 'binary:logistic',\n",
    "'scale_pos_weight': 4.4593460158418523,\n",
    "'seed': 2083,\n",
    "'silent': 1,\n",
    "'subsample': 0.766586509402208,\n",
    "'tree_method': 'exact'},\n",
    "'test-error-mean': 0.25375720000000002}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.5813435352146873,\n",
       "   'eta': 0.12653607181296217,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2037,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.537796332804125,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.38209179999999998},\n",
       " 1: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.5813435352146873,\n",
       "   'eta': 0.12653607181296217,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2037,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.537796332804125,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.036067200000000001},\n",
       " 2: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.6334399849809398,\n",
       "   'eta': 0.15055304521905347,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 2,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2019,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.6186701247268119,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.086130599999999988},\n",
       " 3: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.5045164695165618,\n",
       "   'eta': 0.1428101678052025,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 3,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2016,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.7215305289307261,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.041870600000000001},\n",
       " 4: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.7089159774987868,\n",
       "   'eta': 0.20210354378354375,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 2,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2017,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8204967474962096,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.015638200000000001},\n",
       " 5: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.5813435352146873,\n",
       "   'eta': 0.12653607181296217,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2037,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.537796332804125,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.30505919999999997},\n",
       " 6: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.5813435352146873,\n",
       "   'eta': 0.12653607181296217,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2037,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.537796332804125,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.068178600000000006},\n",
       " 7: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.7089159774987868,\n",
       "   'eta': 0.20210354378354375,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 2,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2017,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8204967474962096,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.013706000000000001},\n",
       " 8: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.8579978891053311,\n",
       "   'eta': 0.18574545610881862,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 3,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2044,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8611335020320647,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.29456899999999997},\n",
       " 9: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.5045164695165618,\n",
       "   'eta': 0.1428101678052025,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 3,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2016,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.7215305289307261,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.20715659999999997},\n",
       " 10: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.7089159774987868,\n",
       "   'eta': 0.20210354378354375,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 2,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2016,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8204967474962096,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.1200102},\n",
       " 11: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.5813435352146873,\n",
       "   'eta': 0.12653607181296217,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2037,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.537796332804125,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.29197859999999998},\n",
       " 12: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.5813435352146873,\n",
       "   'eta': 0.12653607181296217,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2037,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.537796332804125,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.1244864},\n",
       " 13: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.5045164695165618,\n",
       "   'eta': 0.1428101678052025,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 3,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2016,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.7215305289307261,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.3228318},\n",
       " 14: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.8398837534294123,\n",
       "   'eta': 0.14522170765829945,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 2,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2022,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8734804475952236,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.041907600000000003},\n",
       " 15: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.586741114680066,\n",
       "   'eta': 0.08503519422605446,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 2,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2052,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.9395104239451562,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.027125},\n",
       " 16: {'params': {'booster': 'gbtree',\n",
       "   'colsample_bytree': 0.5813435352146873,\n",
       "   'eta': 0.12653607181296217,\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 2037,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.537796332804125,\n",
       "   'tree_method': 'exact'},\n",
       "  'test_logloss_mean': 0.38378999999999996}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_best_params_for_tag_index = {\n",
    "0: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5813435352146873,\n",
    "   'eta': 0.12653607181296217,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 4,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2037,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.537796332804125,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.38209179999999998},\n",
    " 1: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5813435352146873,\n",
    "   'eta': 0.12653607181296217,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 4,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2037,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.537796332804125,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.036067200000000001},\n",
    " 2: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.6334399849809398,\n",
    "   'eta': 0.15055304521905347,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 2,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2019,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.6186701247268119,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.086130599999999988},\n",
    " 3: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5045164695165618,\n",
    "   'eta': 0.1428101678052025,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 3,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2016,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.7215305289307261,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.041870600000000001},\n",
    " 4: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.7089159774987868,\n",
    "   'eta': 0.20210354378354375,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 2,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2017,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.8204967474962096,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.015638200000000001},\n",
    " 5: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5813435352146873,\n",
    "   'eta': 0.12653607181296217,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 4,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2037,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.537796332804125,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.30505919999999997},\n",
    " 6: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5813435352146873,\n",
    "   'eta': 0.12653607181296217,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 4,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2037,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.537796332804125,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.068178600000000006},\n",
    " 7: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.7089159774987868,\n",
    "   'eta': 0.20210354378354375,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 2,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2017,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.8204967474962096,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.013706000000000001},\n",
    " 8: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.8579978891053311,\n",
    "   'eta': 0.18574545610881862,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 3,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2044,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.8611335020320647,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.29456899999999997},\n",
    " 9: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5045164695165618,\n",
    "   'eta': 0.1428101678052025,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 3,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2016,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.7215305289307261,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.20715659999999997},\n",
    " 10: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.7089159774987868,\n",
    "   'eta': 0.20210354378354375,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 2,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2016,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.8204967474962096,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.1200102},\n",
    " 11: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5813435352146873,\n",
    "   'eta': 0.12653607181296217,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 4,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2037,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.537796332804125,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.29197859999999998},\n",
    " 12: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5813435352146873,\n",
    "   'eta': 0.12653607181296217,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 4,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2037,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.537796332804125,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.1244864},\n",
    " 13: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5045164695165618,\n",
    "   'eta': 0.1428101678052025,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 3,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2016,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.7215305289307261,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.3228318},\n",
    " 14: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.8398837534294123,\n",
    "   'eta': 0.14522170765829945,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 2,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2022,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.8734804475952236,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.041907600000000003},\n",
    " 15: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.586741114680066,\n",
    "   'eta': 0.08503519422605446,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 2,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2052,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.9395104239451562,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.027125},\n",
    " 16: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5813435352146873,\n",
    "   'eta': 0.12653607181296217,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 4,\n",
    "   'objective': 'binary:logistic',\n",
    "   'seed': 2037,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.537796332804125,\n",
    "   'tree_method': 'exact'},\n",
    "  'test_logloss_mean': 0.38378999999999996}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params_for_tag_index = {0: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5829334344789511,\n",
    "   'eta': 0.024988972967877485,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 5,\n",
    "   'objective': 'binary:logistic',\n",
    "   'scale_pos_weight': 2.2825856875356183,\n",
    "   'seed': 2038,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.7387515922133331,\n",
    "   'tree_method': 'exact'},\n",
    "  'test-logloss-mean': 0.24204939999999997},\n",
    " 1: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5151974580887335,\n",
    "   'eta': 0.02653115436725616,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 5,\n",
    "   'objective': 'binary:logistic',\n",
    "   'scale_pos_weight': 114.2,\n",
    "   'seed': 2023,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.8162897671482163,\n",
    "   'tree_method': 'exact'},\n",
    "  'test-logloss-mean': 0.017903800000000001},\n",
    " 2: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.9152266627015204,\n",
    "   'eta': 0.03617273607658269,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 5,\n",
    "   'objective': 'binary:logistic',\n",
    "   'scale_pos_weight': 43.849833147942157,\n",
    "   'seed': 2122,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.6340682509577085,\n",
    "   'tree_method': 'exact'},\n",
    "  'test-logloss-mean': 0.095588800000000002},\n",
    " 3: {'params': {'booster': 'gbtree',\n",
    "   'colsample_bytree': 0.5151974580887335,\n",
    "   'eta': 0.02653115436725616,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 5,\n",
    "   'objective': 'binary:logistic',\n",
    "   'scale_pos_weight': 124.21739130434783,\n",
    "   'seed': 2023,\n",
    "   'silent': 1,\n",
    "   'subsample': 0.8162897671482163,\n",
    "   'tree_method': 'exact'},\n",
    "  'test-logloss-mean': 0.042751600000000001}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
